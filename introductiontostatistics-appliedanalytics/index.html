<!doctype html><html lang=en>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta name=robots content="noodp">
<meta http-equiv=x-ua-compatible content="IE=edge, chrome=1">
<title>Introduction to Statistics (Applied Analytics) - Boyang Yan's Tech Blog</title><meta name=description content="This is Boyang Yan's Tech Blog"><meta property="og:title" content="Introduction to Statistics (Applied Analytics)">
<meta property="og:description" content="What is Statistics? Statistics is the science of collecting, organizing, analyzing, and interpreting data in order to make decisions.
Some informal definitions of statistics, provided by various well-known statisticians, are
 The science of learning from (or making sense out of) data (J. Kettenring). The theory and methods of extracting information from observational data for solving real-world problems (C.R. Rao). The science of uncertainty (D.J. Hand). The art of telling a story with data (L.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://yanboyang.com/introductiontostatistics-appliedanalytics/"><meta property="og:image" content="https://yanboyang.com/logo.png"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2021-03-03T06:11:32+10:00">
<meta property="article:modified_time" content="2021-12-06T06:05:25+00:00">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:image content="https://yanboyang.com/logo.png">
<meta name=twitter:title content="Introduction to Statistics (Applied Analytics)">
<meta name=twitter:description content="What is Statistics? Statistics is the science of collecting, organizing, analyzing, and interpreting data in order to make decisions.
Some informal definitions of statistics, provided by various well-known statisticians, are
 The science of learning from (or making sense out of) data (J. Kettenring). The theory and methods of extracting information from observational data for solving real-world problems (C.R. Rao). The science of uncertainty (D.J. Hand). The art of telling a story with data (L.">
<meta name=application-name content="LoveIt">
<meta name=apple-mobile-web-app-title content="LoveIt"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico>
<link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png>
<link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://yanboyang.com/introductiontostatistics-appliedanalytics/><link rel=prev href=https://yanboyang.com/bigdataarchitectures/><link rel=next href=https://yanboyang.com/rlanguage/><link rel=stylesheet href=/lib/normalize/normalize.min.css><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Introduction to Statistics (Applied Analytics)","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/yanboyang.com\/introductiontostatistics-appliedanalytics\/"},"genre":"posts","wordcount":38992,"url":"https:\/\/yanboyang.com\/introductiontostatistics-appliedanalytics\/","datePublished":"2021-03-03T06:11:32+10:00","dateModified":"2021-12-06T06:05:25+00:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Boyang Yan"},"description":""}</script></head>
<body header-desktop=fixed header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':'auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark')&&document.body.setAttribute('theme','dark')</script>
<div id=mask></div><div class=wrapper><header class=desktop id=header-desktop>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-101949995-1','auto'),ga('send','pageview'))</script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-101949995-1','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<div class=header-wrapper>
<div class=header-title>
<a href=/ title="Boyang Yan's Tech Blog"></a>
</div>
<div class=menu>
<div class=menu-inner><a class=menu-item href=/> Home </a><a class=menu-item href=/posts/> Posts </a><a class=menu-item href=/tags/> Tags </a><a class=menu-item href=/categories/> Categories </a><a class=menu-item href=/about/> About Me </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search>
<i class="fas fa-search fa-fw"></i>
</a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear>
<i class="fas fa-times-circle fa-fw"></i>
</a>
<span class="search-button search-loading" id=search-loading-desktop>
<i class="fas fa-spinner fa-fw fa-spin"></i>
</span>
</span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
</a>
</div>
</div>
</div>
</header><header class=mobile id=header-mobile>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(a,e,f,g,b,c,d){a.GoogleAnalyticsObject=b,a[b]=a[b]||function(){(a[b].q=a[b].q||[]).push(arguments)},a[b].l=1*new Date,c=e.createElement(f),d=e.getElementsByTagName(f)[0],c.async=1,c.src=g,d.parentNode.insertBefore(c,d)}(window,document,'script','https://www.google-analytics.com/analytics.js','ga'),ga('create','UA-101949995-1','auto'),ga('send','pageview'))</script>
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-101949995-1','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<div class=header-container>
<div class=header-wrapper>
<div class=header-title>
<a href=/ title="Boyang Yan's Tech Blog"></a>
</div>
<div class=menu-toggle id=menu-toggle-mobile>
<span></span><span></span><span></span>
</div>
</div>
<div class=menu id=menu-mobile><div class=search-wrapper>
<div class="search mobile" id=search-mobile>
<input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search>
<i class="fas fa-search fa-fw"></i>
</a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear>
<i class="fas fa-times-circle fa-fw"></i>
</a>
<span class="search-button search-loading" id=search-loading-mobile>
<i class="fas fa-spinner fa-fw fa-spin"></i>
</span>
</div>
<a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>
Cancel
</a>
</div><a class=menu-item href=/ title>Home</a><a class=menu-item href=/posts/ title>Posts</a><a class=menu-item href=/tags/ title>Tags</a><a class=menu-item href=/categories/ title>Categories</a><a class=menu-item href=/about/ title>About Me</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw"></i>
</a></div>
</div>
</header>
<div class="search-dropdown desktop">
<div id=search-dropdown-desktop></div>
</div>
<div class="search-dropdown mobile">
<div id=search-dropdown-mobile></div>
</div>
<main class=main>
<div class=container><div class=toc id=toc-auto>
<h2 class=toc-title>Contents</h2>
<div class=toc-content id=toc-content-auto></div>
</div><article class="page single"><h1 class="single-title animated flipInX">Introduction to Statistics (Applied Analytics)</h1><div class=post-meta>
<div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw"></i>Boyang Yan</a></span>&nbsp;<span class=post-category>included in <a href=/categories/math1324/><i class="far fa-folder fa-fw"></i>MATH1324</a></span></div>
<div class=post-meta-line><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime=2021-03-03>2021-03-03</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;38992 words&nbsp;
<i class="far fa-clock fa-fw"></i>&nbsp;184 minutes&nbsp;</div>
</div><div class="details toc" id=toc-static kept=true>
<div class="details-summary toc-title">
<span>Contents</span>
<span><i class="details-icon fas fa-angle-right"></i></span>
</div>
<div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents>
<ul>
<li><a href=#what-is-statistics>What is Statistics?</a></li>
<li><a href=#statistics-vs-mathematics>Statistics vs. Mathematics</a></li>
<li><a href=#orientation>Orientation</a></li>
<li><a href=#why-statistics-are-important>Why statistics are important?</a></li>
<li><a href=#module-one---dealing-confidently-with-uncertainty>Module One - Dealing Confidently with Uncertainty</a>
<ul>
<li><a href=#the-learning-objectives>The learning objectives:</a></li>
<li><a href=#random-variables-and-sources-of-variation>Random Variables and Sources of Variation</a></li>
<li><a href=#types-of-variables-and-levels-of-measurement>Types of Variables and Levels of Measurement</a>
<ul>
<li><a href=#major-types-of-variables>Major Types of Variables</a></li>
<li><a href=#levels-of-measurement>Levels of Measurement</a></li>
</ul>
</li>
<li><a href=#statistical-inference---the-big-idea-of-statistics>Statistical Inference - The Big Idea of Statistics</a></li>
<li><a href=#the-statistical-data-investigation-process>The Statistical Data Investigation Process</a></li>
<li><a href=#major-types-of-statistical-data-investigations>Major Types of Statistical Data Investigations</a>
<ul>
<li><a href=#surveys>Surveys</a></li>
<li><a href=#experiments>Experiments</a></li>
<li><a href=#observational-or-correlational-studies>Observational or Correlational Studies</a></li>
</ul>
</li>
<li><a href=#references>References</a></li>
<li><a href=#exercise-model-one>Exercise (Model One)</a></li>
</ul>
</li>
<li><a href=#model-two---descriptive-statistics-through-visualisation>Model Two - Descriptive Statistics through Visualisation</a>
<ul>
<li><a href=#learning-objectives>Learning Objectives</a></li>
<li><a href=#descriptive-statistics>Descriptive Statistics</a></li>
<li><a href=#qualitative-variables>Qualitative Variables</a>
<ul>
<li><a href=#frequency-distributions>Frequency Distributions</a></li>
<li><a href=#bar-charts>Bar Charts</a></li>
<li><a href=#contingency-tables-cross-tabulations>Contingency Tables (Cross-tabulations)</a></li>
<li><a href=#clustered-bar-charts>Clustered Bar Charts</a></li>
</ul>
</li>
<li><a href=#quantitative-variables>Quantitative Variables</a>
<ul>
<li><a href=#dot-plots>Dot Plots</a></li>
<li><a href=#histograms>Histograms</a></li>
<li><a href=#distribution-shapes>Distribution Shapes</a></li>
<li><a href=#measures-of-central-tendency>Measures of Central Tendency</a>
<ul>
<li><a href=#mean-and-standard-deviation>Mean and Standard Deviation</a></li>
<li><a href=#quartiles-and-the-median>Quartiles and the Median</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href=#scenario-12-4-9-8-6-5-3>Scenario 1 2, 4, 9, 8, 6, 5, 3</a></li>
<li><a href=#ordered2-3-4-5-6-8-9>Ordered 2, 3, 4, 5, 6, 8, 9</a></li>
<li><a href=#location-of-median-n12--712--4th->Location of Median $$ (n+1)/2 = (7+1)/2 = 4th $$</a></li>
<li><a href=#scenario-22-4-9-8-6-5>Scenario 2 2, 4, 9, 8, 6, 5</a></li>
<li><a href=#ordered2-4-5-6-8-9>Ordered 2, 4, 5, 6, 8, 9</a>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href=#box-plots>Box Plots</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=#min-1st-qu--median----mean-3rd-qu----max>Min. 1st Qu. Median Mean 3rd Qu. Max.</a></li>
<li><a href=#5820---6105---6205---6178---6267---6390>58.20 61.05 62.05 61.78 62.67 63.90</a>
<ul>
<li>
<ul>
<li><a href=#comparing-groups>Comparing Groups</a></li>
<li><a href=#scatter-plots>Scatter Plots</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=#module-2---exercises>Module 2 - Exercises</a></li>
</ul>
</li>
<li><a href=#model-three---probability-the-language-of-uncertainty>Model Three - Probability: The Language of Uncertainty</a>
<ul>
<li><a href=#learning-objectives-1>learning objectives</a></li>
<li><a href=#probability>Probability</a></li>
<li><a href=#dependencies-and-risk>Dependencies and risk</a></li>
<li><a href=#basic-concepts>Basic Concepts</a>
<ul>
<li><a href=#experiments-and-events>Experiments and Events</a>
<ul>
<li><a href=#experiment>Experiment</a></li>
<li><a href=#events>Events</a></li>
<li><a href=#the-probability-of-an-event>The Probability of an Event</a></li>
<li><a href=#probability-axioms>Probability axioms</a></li>
<li><a href=#conditional-probability>Conditional Probability</a>
<ul>
<li><a href=#example>Example</a></li>
</ul>
</li>
<li><a href=#multiplication-theorem>Multiplication Theorem</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=#rules>Rules</a></li>
<li><a href=#multiplication-law>Multiplication Law</a></li>
<li><a href=#addition-laws>Addition Laws</a></li>
<li><a href=#conditional-probability-1>Conditional Probability</a></li>
<li><a href=#permutations-and-combinations>Permutations and Combinations</a>
<ul>
<li><a href=#permutations-have-rangking>Permutations (have rangking)</a></li>
<li><a href=#combinations-not-ranking>Combinations (not ranking)</a></li>
</ul>
</li>
<li><a href=#exercises>Exercises</a></li>
</ul>
</li>
</ul>
<ul>
<li><a href=#probability-distributions-random-but-predictable>Probability Distributions: Random, but Predictable</a>
<ul>
<li><a href=#overview>Overview</a></li>
<li><a href=#learning-objectives-2>Learning Objectives</a></li>
<li><a href=#probability-distributions>Probability Distributions</a></li>
<li><a href=#binomial-distribution>Binomial Distribution</a>
<ul>
<li><a href=#11-what-is-the-probability-that-the-vaccine-will-work-for-10-people>1.1. What is the probability that the vaccine will work for 10 people?</a></li>
<li><a href=#12-what-is-the-probability-that-the-vaccine-will-work-for-8-or-less-people>1.2. What is the probability that the vaccine will work for 8 or less people?</a></li>
<li><a href=#13-what-is-the-probability-that-the-vaccine-will-work-in-more-than-8-random-people>1.3. What is the probability that the vaccine will work in more than 8 random people?</a></li>
<li><a href=#14-what-is-the-probability-that-the-vaccine-will-work-for-between-9-to-11-people>1.4. What is the probability that the vaccine will work for between 9 to 11 people?</a></li>
<li><a href=#15-what-is-the-expected-value-and-standard-deviation-of-the-binomial-distribution-with-n12-p085>1.5. What is the expected value and standard deviation of the binomial distribution with n=12, p=0.85?</a></li>
</ul>
</li>
<li><a href=#poisson-distribution>Poisson Distribution</a>
<ul>
<li><a href=#-ex--varx->$$ E(x) & Var(x) $$</a>
<ul>
<li><a href=#21-what-is-the-probability-the-doctor-will-see-exactly-16-patients-in-a-given-day>2.1. What is the probability the doctor will see exactly 16 patients in a given day?</a></li>
<li><a href=#22-what-is-the-probability-the-doctor-will-see-12-or-less-patients-in-a-given-day>2.2. What is the probability the doctor will see 12 or less patients in a given day?</a></li>
<li><a href=#23-what-is-the-probability-that-the-doctor-will-see-less-than-or-equal-to-100-patients-in-a-week>2.3. What is the probability that the doctor will see less than or equal to 100 patients in a week?</a></li>
<li><a href=#24-what-is-the-probability-that-the-doctor-will-see-more-than-25-patients-in-a-day>2.4. What is the probability that the doctor will see more than 25 patients in a day?</a></li>
<li><a href=#25-what-is-the-probability-that-the-doctor-will-see-between-8-to-24-patients-in-a-given-day>2.5. What is the probability that the doctor will see between 8 to 24 patients in a given day?</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=#normal-distribution>Normal Distribution</a>
<ul>
<li><a href=#1-what-is-the-probability-that-a-random-person-from-the-population-will-have-an-iq-score-less-than-80>1. What is the probability that a random person from the population will have an IQ score less than 80?</a></li>
<li><a href=#2-what-is-the-probability-that-you-will-randomly-select-a-person-from-the-population-with-an-iq-score-above-110>2. What is the probability that you will randomly select a person from the population with an IQ score above 110?</a></li>
<li><a href=#3-what-is-the-probability-that-a-randomly-selected-person-from-the-population-will-have-an-iq-score-within-one-standard-deviation-from-the-mean>3. What is the probability that a randomly selected person from the population will have an IQ score within one standard deviation from the mean?</a></li>
<li><a href=#find-x-given-percentile>Find X given percentile</a></li>
<li><a href=#find-b-given-a-and-percentile>Find b given a and percentile</a></li>
</ul>
</li>
<li><a href=#the-standard-normal-z-distribution>The Standard Normal Z-Distribution</a>
<ul>
<li><a href=#normal-distribution-visualisation-code>Normal Distribution Visualisation Code</a></li>
</ul>
</li>
<li><a href=#module-4---exercises>Module 4 - Exercises</a></li>
</ul>
</li>
<li><a href=#module-5-sampling-randomly-representative>Module 5 Sampling: Randomly Representative</a>
<ul>
<li><a href=#introduction-to-the-module>Introduction to the Module</a></li>
<li><a href=#learning-objectives-3>Learning Objectives</a></li>
<li><a href=#module-video>Module Video</a></li>
<li><a href=#populations-and-samples>Populations and Samples</a></li>
<li><a href=#sampling-methods>Sampling Methods</a>
<ul>
<li><a href=#simple-random-sampling-srs>Simple Random Sampling (SRS)</a></li>
<li><a href=#stratified-sampling>Stratified Sampling</a></li>
<li><a href=#cluster-sampling>Cluster Sampling</a></li>
<li><a href=#convenience-sampling>Convenience Sampling</a></li>
</ul>
</li>
<li><a href=#sampling-distributions>Sampling Distributions</a>
<ul>
<li><a href=#youtube-data>YouTube Data</a></li>
<li><a href=#population-distribution>Population Distribution</a></li>
<li><a href=#simulations-in-r>Simulations in R</a></li>
<li><a href=#expected-value-and-variance>Expected Value and Variance</a></li>
<li><a href=#standard-error>Standard Error</a></li>
<li><a href=#central-limit-theorem>Central Limit Theorem</a></li>
<li><a href=#what-are-sampling-distributions-used-for>What are sampling distributions used for?</a>
<ul>
<li><a href=#demonstrations-of-clt>Demonstrations of CLT</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=#exercises-1>Exercises</a></li>
</ul>
</li>
</ul>
<ul>
<li><a href=#module-6-estimating-uncertainty-confidently>Module 6 Estimating Uncertainty Confidently</a>
<ul>
<li><a href=#overview-1>Overview</a></li>
<li><a href=#learning-objectives-4>Learning Objectives</a></li>
<li><a href=#types-of-inference>Types of Inference</a></li>
<li><a href=#point-and-interval-estimation>Point and Interval Estimation</a>
<ul>
<li><a href=#definitions>Definitions</a></li>
<li><a href=#some-definitions>Some definitions</a>
<ul>
<li><a href=#properties-of-point-estimators>Properties of Point Estimators</a></li>
<li><a href=#measuring-the-goodness-of-an-estimator>Measuring the Goodness of an Estimator</a></li>
<li><a href=#the-margin-of-error>The Margin of Error</a></li>
<li><a href=#confidence-intervals>Confidence Intervals</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=#confidence-intervals-1>Confidence Intervals</a>
<ul>
<li><a href=#the-general-process>The General Process</a></li>
</ul>
</li>
<li><a href=#theory>Theory</a></li>
<li><a href=#influencing-factors>Influencing Factors</a>
<ul>
<li><a href=#sample-size>Sample Size</a></li>
<li><a href=#confidenece-level>Confidenece Level</a>
<ul>
<li><a href=#confidence-interval-for-μ-σ-known>Confidence Interval for μ (σ Known)</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=#calculating-confidence-intervals>Calculating Confidence Intervals</a>
<ul>
<li><a href=#pizza-data>Pizza Data</a></li>
<li><a href=#comparing-means>Comparing Means</a></li>
<li><a href=#mean---unknown-population-standard-deviation---t-distribution>Mean - Unknown Population Standard Deviation - t-distribution</a>
<ul>
<li><a href=#do-you-ever-truly-know-σ>Do You Ever Truly Know σ?</a></li>
<li><a href=#confidence-interval-for-μ-σ-unknown>Confidence Interval for μ (σ Unknown)</a>
<ul>
<li><a href=#degrees-of-freedom-df>Degrees of Freedom (df)</a></li>
<li><a href=#students-t-distribution>Student’s t Distribution</a></li>
<li><a href=#students-t-table>Student’s t Table</a></li>
</ul>
</li>
</ul>
</li>
<li><a href=#proportions---binomial-distribution>Proportions - binomial distribution</a></li>
<li><a href=#rates---poisson-distribution>Rates - Poisson distribution</a></li>
</ul>
</li>
<li><a href=#determining-sample-size-for-the-mean>Determining Sample Size for the Mean</a></li>
<li><a href=#example-1>Example</a></li>
</ul>
</li>
<li><a href=#module-7-testing-the-null-data-on-trial>Module 7 Testing the Null: Data on Trial</a>
<ul>
<li><a href=#overview---summary>Overview - Summary</a></li>
<li><a href=#learning-objectives-5>Learning Objectives</a></li>
<li><a href=#video>Video</a></li>
<li><a href=#hypothesis-testing---the-one-sample-t-test>Hypothesis Testing - The One-sample t-test</a>
<ul>
<li><a href=#body-temp-data>Body Temp Data</a>
<ul>
<li><a href=#hypothesis-testing---datia-on-trial>Hypothesis Testing - DatIa on Trial</a></li>
<li><a href=#a-worked-example>A Worked Example</a></li>
<li><a href=#critical-value-approach>Critical Value Approach</a></li>
<li><a href=#p--value-approach>p -value Approach</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href=#1-1680393e-07>[1] 1.680393e-07</a>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href=#confidence-interval-approach>Confidence Interval Approach</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href=#1-3673699-3687839>[1] 36.73699 36.87839</a></li>
<li><a href=#attrconflevel>attr(,&ldquo;conf.level&rdquo;)</a></li>
<li><a href=#1-095>[1] 0.95</a></li>
<li><a href=#heading></a></li>
<li><a href=#one-sample-t-test>One Sample t-test</a></li>
<li><a href=#heading-1></a></li>
<li><a href=#data--body_tempbody_temp>data: Body_temp$Body_temp</a></li>
<li><a href=#t---53818-df--129-p-value--168e-07>t = -5.3818, df = 129, p-value = 1.68e-07</a></li>
<li><a href=#alternative-hypothesis-true-mean-is-less-than-37>alternative hypothesis: true mean is less than 37</a></li>
<li><a href=#95-percent-confidence-interval>95 percent confidence interval:</a></li>
<li><a href=#-inf-3686689>-Inf 36.86689</a></li>
<li><a href=#sample-estimates>sample estimates:</a></li>
<li><a href=#mean-of-x>mean of x</a></li>
<li><a href=#3680769>36.80769</a></li>
<li><a href=#heading-2></a></li>
<li><a href=#one-sample-t-test-1>One Sample t-test</a></li>
<li><a href=#heading-3></a></li>
<li><a href=#data--body_tempbody_temp-1>data: Body_temp$Body_temp</a></li>
<li><a href=#t---53818-df--129-p-value--3361e-07>t = -5.3818, df = 129, p-value = 3.361e-07</a></li>
<li><a href=#alternative-hypothesis-true-mean-is-not-equal-to-37>alternative hypothesis: true mean is not equal to 37</a></li>
<li><a href=#95-percent-confidence-interval-1>95 percent confidence interval:</a></li>
<li><a href=#3673699-3687839>36.73699 36.87839</a></li>
<li><a href=#sample-estimates-1>sample estimates:</a></li>
<li><a href=#mean-of-x-1>mean of x</a></li>
<li><a href=#3680769-1>36.80769</a></li>
<li><a href=#heading-4></a></li>
<li><a href=#one-sample-t-test-2>One Sample t-test</a></li>
<li><a href=#heading-5></a></li>
<li><a href=#data--body_tempbody_temp-2>data: Body_temp$Body_temp</a></li>
<li><a href=#t---53818-df--129-p-value--3361e-07-1>t = -5.3818, df = 129, p-value = 3.361e-07</a></li>
<li><a href=#alternative-hypothesis-true-mean-is-not-equal-to-37-1>alternative hypothesis: true mean is not equal to 37</a></li>
<li><a href=#99-percent-confidence-interval>99 percent confidence interval:</a></li>
<li><a href=#3671427-3690111>36.71427 36.90111</a></li>
<li><a href=#sample-estimates-2>sample estimates:</a></li>
<li><a href=#mean-of-x-2>mean of x</a></li>
<li><a href=#3680769-2>36.80769</a>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href=#the-language-of-hypothesis-testing---reporting-your-results>The Language of Hypothesis Testing - Reporting Your Results</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href=#-a-tibble-2-x-10># A tibble: 2 x 10</a></li>
<li><a href=#gender---min----q1-median----q3---max--mean----sd-----n-missing>Gender Min Q1 Median Q3 Max Mean SD n Missing</a></li>
<li><a href=#fct--dbl-dbl--dbl-dbl-dbl-dbl-dbl-int---int><fct> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <int> <int></a></li>
<li><a href=#1-male----357--364---367--37----375--367-0388----65-------0>1 Male 35.7 36.4 36.7 37 37.5 36.7 0.388 65 0</a></li>
<li><a href=#2-female--358--367---369--371--382--369-0413----65-------0>2 Female 35.8 36.7 36.9 37.1 38.2 36.9 0.413 65 0</a></li>
<li><a href=#1-1-2>[1] 1 2</a></li>
<li><a href=#1-65--1>[1] 65 1</a>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href=#central-limit-theorem-1>Central Limit Theorem</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href=#levenes-test-for-homogeneity-of-variance-center--median>Levene&rsquo;s Test for Homogeneity of Variance (center = median)</a></li>
<li><a href=#df-f-value-prf>Df F value Pr(>F)</a></li>
<li><a href=#group---1--00428-08365>group 1 0.0428 0.8365</a></li>
<li><a href=#128>128</a></li>
<li><a href=#heading-6></a></li>
<li><a href=#two-sample-t-test>Two Sample t-test</a></li>
<li><a href=#heading-7></a></li>
<li><a href=#data--body_temp-by-gender>data: Body_temp by Gender</a></li>
<li><a href=#t---23204-df--128-p-value--00219>t = -2.3204, df = 128, p-value = 0.0219</a></li>
<li><a href=#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0>alternative hypothesis: true difference in means is not equal to 0</a></li>
<li><a href=#95-percent-confidence-interval-2>95 percent confidence interval:</a></li>
<li><a href=#-03021399--00240139>-0.3021399 -0.0240139</a></li>
<li><a href=#sample-estimates-3>sample estimates:</a></li>
<li><a href=#mean-in-group-male-mean-in-group-female>mean in group Male mean in group Female</a></li>
<li><a href=#3672615-------------3688923>36.72615 36.88923</a></li>
<li><a href=#1--1978671>[1] -1.978671</a></li>
<li><a href=#heading-8></a></li>
<li><a href=#welch-two-sample-t-test>Welch Two Sample t-test</a></li>
<li><a href=#heading-9></a></li>
<li><a href=#data--body_temp-by-gender-1>data: Body_temp by Gender</a></li>
<li><a href=#t---23204-df--12752-p-value--002191>t = -2.3204, df = 127.52, p-value = 0.02191</a></li>
<li><a href=#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0-1>alternative hypothesis: true difference in means is not equal to 0</a></li>
<li><a href=#95-percent-confidence-interval-3>95 percent confidence interval:</a></li>
<li><a href=#-030214491--002400893>-0.30214491 -0.02400893</a></li>
<li><a href=#sample-estimates-4>sample estimates:</a></li>
<li><a href=#mean-in-group-male-mean-in-group-female-1>mean in group Male mean in group Female</a></li>
<li><a href=#3672615-------------3688923-1>36.72615 36.88923</a>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href=#example-write-up>Example Write-up</a></li>
</ul>
</li>
<li><a href=#paired-samples-t-test>Paired Samples t-test</a>
<ul>
<li><a href=#prison-data>Prison Data</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href=#min-q1-median---q3-max-----mean-------sd--n-missing>Min Q1 Median Q3 Max Mean SD n Missing</a></li>
<li><a href=#1--12-19-----23-275--44-2393333-7487768-15-------0>1 12 19 23 27.5 44 23.93333 7.487768 15 0</a></li>
<li><a href=#min-q1-median-q3-max-mean-------sd--n-missing>Min Q1 Median Q3 Max Mean SD n Missing</a></li>
<li><a href=#1---8-14-----21-24--33---20-6907553-15-------0>1 8 14 21 24 33 20 6.907553 15 0</a></li>
<li><a href=#min-q1-median-q3-max------mean-------sd--n-missing>Min Q1 Median Q3 Max Mean SD n Missing</a></li>
<li><a href=#1--15--7------4--1---4--3933333-5675343-15-------0>1 -15 -7 -4 1 4 -3.933333 5.675343 15 0</a></li>
<li><a href=#1-13--1>[1] 13 1</a></li>
<li><a href=#heading-10></a></li>
<li><a href=#paired-t-test>Paired t-test</a></li>
<li><a href=#heading-11></a></li>
<li><a href=#data--prisonstress_sportpssafter-and-prisonstress_sportpssbefore>data: PrisonStress_sport$PSSafter and PrisonStress_sport$PSSbefore</a></li>
<li><a href=#t---26842-df--14-p-value--00178>t = -2.6842, df = 14, p-value = 0.0178</a></li>
<li><a href=#alternative-hypothesis-true-difference-in-means-is-not-equal-to-0-2>alternative hypothesis: true difference in means is not equal to 0</a></li>
<li><a href=#95-percent-confidence-interval-4>95 percent confidence interval:</a></li>
<li><a href=#-70762338--07904329>-7.0762338 -0.7904329</a></li>
<li><a href=#sample-estimates-5>sample estimates:</a></li>
<li><a href=#mean-of-the-differences>mean of the differences</a></li>
<li><a href=#-3933333>-3.933333</a></li>
<li><a href=#heading-12></a></li>
<li><a href=#one-sample-t-test-3>One Sample t-test</a></li>
<li><a href=#heading-13></a></li>
<li><a href=#data--prisonstress_sportd>data: PrisonStress_sport$d</a></li>
<li><a href=#t---26842-df--14-p-value--00178-1>t = -2.6842, df = 14, p-value = 0.0178</a></li>
<li><a href=#alternative-hypothesis-true-mean-is-not-equal-to-0>alternative hypothesis: true mean is not equal to 0</a></li>
<li><a href=#95-percent-confidence-interval-5>95 percent confidence interval:</a></li>
<li><a href=#-70762338--07904329-1>-7.0762338 -0.7904329</a></li>
<li><a href=#sample-estimates-6>sample estimates:</a></li>
<li><a href=#mean-of-x-3>mean of x</a></li>
<li><a href=#-3933333-1>-3.933333</a></li>
<li><a href=#1--2144787>[1] -2.144787</a></li>
<li><a href=#1-001794553>[1] 0.01794553</a>
<ul>
<li>
<ul>
<li>
<ul>
<li><a href=#paired-samples-t-test-visualisation>Paired Samples t-test Visualisation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href=#summary-stats>Summary Stats</a></li>
<li><a href=#n------------------15000>n 15.000</a></li>
<li><a href=#meanx------------23933>mean(x) 23.933</a></li>
<li><a href=#meany------------20000>mean(y) 20.000</a></li>
<li><a href=#meandx-y---------3933>mean(D=x-y) 3.933</a></li>
<li><a href=#sdd---------------5675>SD(D) 5.675</a></li>
<li><a href=#esd---------------0693>ES(D) 0.693</a></li>
<li><a href=#rxy--------------0692>r(x,y) 0.692</a></li>
<li><a href=#rxyd------------0111>r(x+y,d) 0.111</a></li>
<li><a href=#ll-95ci------------0790>LL 95%CI 0.790</a></li>
<li><a href=#ul-95ci------------7076>UL 95%CI 7.076</a></li>
<li><a href=#td-bar------------2684>t(D-bar) 2.684</a></li>
<li><a href=#dft---------------14000>df.t 14.000</a></li>
<li><a href=#pvalt--------------0018>pval.t 0.018</a></li>
</ul>
</nav></div>
</div><div class=content id=content><h2 id=what-is-statistics>What is Statistics?</h2>
<p>Statistics is the science of collecting, organizing, analyzing, and interpreting data in order to make decisions.</p>
<p>Some informal definitions of statistics, provided by various well-known statisticians, are</p>
<ul>
<li>The science of learning from (or making sense out of) data (J. Kettenring).</li>
<li>The theory and methods of extracting information from observational data for solving real-world problems (C.R. Rao).</li>
<li>The science of uncertainty (D.J. Hand).</li>
<li>The art of telling a story with data (L. Gaines).</li>
</ul>
<h2 id=statistics-vs-mathematics>Statistics vs. Mathematics</h2>
<p>Statistics and Mathematics differ in a number of fundamental ways:</p>
<ul>
<li>Mathematics:
<ul>
<li>Problems can exist without context</li>
<li>Measurements are assumed to be exact</li>
<li>No variability</li>
<li>Deterministic answers</li>
</ul>
</li>
<li>Statistics:
<ul>
<li>The use of context and data collection</li>
<li>Measurement decisions</li>
<li>Omnipresence of variability</li>
<li>Dealing with uncertainty</li>
</ul>
</li>
</ul>
<h2 id=orientation>Orientation</h2>
<p>This article will introduce you to fundamental statistical concepts and modern statistical practice:</p>
<ul>
<li>Study statistical data investigations, summary statistics, data visualisation and probability as a measure for uncertainty.</li>
<li>Then build upon these topics and learn about sampling, sampling distributions and confidence intervals as the basis for statistical inference.</li>
<li>The course will finish with a series of modules looking at common hypothesis testing methods for different types of data.</li>
</ul>
<h2 id=why-statistics-are-important>Why statistics are important?</h2>
<ul>
<li>
<p>Very useful to be able to estimate business value in your head – employers highly regard the ability to use stats in business logic (e.g. estimate a market size to know if a new product is feasible before investing in detailed market research)</p>
</li>
<li>
<p>Often this acts as a good error check on our own biases/misconceptions Fundamental to many analytics challenges and encompasses a wide range of stats methods from descriptive statistics to hypothesis testing and control group design (all of which we cover in this course).</p>
</li>
<li>
<p>Experience how statistics can improve the quality of your decision-making.</p>
</li>
</ul>
<p>{% youtube wV0Ks7aS7YI %}</p>
<h2 id=module-one---dealing-confidently-with-uncertainty>Module One - Dealing Confidently with Uncertainty</h2>
<h3 id=the-learning-objectives>The learning objectives:</h3>
<ul>
<li>Define and understand the omnipresence of variability by stating major sources and types of variation.</li>
<li>Define the discipline and science of statistics, and distinguish it from mathematics.</li>
<li>Define a variable, their major types, and levels of measurement.</li>
<li>Understand the basics stages of the statistical data investigation process.</li>
<li>Understand the major types of statistical data investigations, namely, surveys, observational studies and experiments.</li>
<li>Discuss the idea of statistical inference and how the use of samples give rise to uncertainty.</li>
<li>Explore the central concepts of variability in a simple statistical data investigation.</li>
</ul>
<p>{% youtube y3A0lUkpAko %}</p>
<h3 id=random-variables-and-sources-of-variation>Random Variables and Sources of Variation</h3>
<p><strong>Statistics</strong>, as defined by MacGillivray, Utts and Heckard (2014), is the “discipline and science of obtaining, understanding, modelling, interpreting, and using data in all real and complex systems and processes that involve uncertainty and variation” (p.15).</p>
<p><strong>Data</strong>, <strong>variation</strong>, and <strong>uncertainty</strong> are at the core of statistics.</p>
<ol>
<li>What is data?
Observations coded as categories or numeric values</li>
<li>What is uncertainty?
The situation resulting from randomness or some form of unpredictability</li>
<li>What is variation?
observations or measurements that are not determined and can take on more than one value.</li>
</ol>
<p>Variation leads to uncertainty and is the reason why the field of statistics emerged.</p>
<ul>
<li>
<p>Statistical data refer to <strong>variables</strong>, which are defined as any characteristic or value of a unit that can change or vary. The idea of a unit is very broad and can refer to a person, a time point, a device, or system.</p>
</li>
<li>
<p><strong>Variation</strong> is all around us. This idea is referred to as the “omnipresence of variability” and is the reason why the field of statistics emerged. There are many forms of variation that you need understand. These can be summarised into four main categories.</p>
<ul>
<li>
<p><strong>Natural or Real Variation</strong>: This refers to inherent, natural variability that is left over when all the other sources of variability are accounted for. Take, for example, a person’s height. Height varies greatly in the population, but there a many other variables that can explain why one person is taller than another. Males tend to be taller than females. Adults are taller than children. However, even if we compared males of a similar age, height will still vary. This is the natural or “real” variability that statistics seeks to measure and understand. Natural variability is what makes the world an interesting place.</p>
</li>
<li>
<p><strong>Explainable Variation</strong>: This is the variation in one variable that we can explain by considering another variable. The statistical tests and models that you will learn in this course seek to test relationships and effects that different variables have on each other. You already know heaps of examples of variables that “explain” other variables. For example, you know that height can help explain variation in weight, smoking can help us understand why some people are at a greater risk of lung cancer, gender can explain variation in the risk of heart disease, and the amount of hours spent studying can help explain exam scores.</p>
</li>
<li>
<p><strong>Sampling Error</strong>: Take a sample from a population, make a measurement and record the result. Now, repeat the process many times. The sample results will all differ to a certain degree. This type of variability is known as sampling variability. Statistical inference and hypothesis testing, to be introduced in later modules, deals with this specific form of variability and the implications it has on drawing conclusions from our studies. We will also consider this important source of variation in an interesting demonstration at the end of this module.</p>
</li>
<li>
<p><strong>Non-sampling Variation</strong>: This refers to any artificial variability induced by the research process. As researchers, you try to understand real variability, while acknowledging, accounting or controlling for induced variability. Induced variability can come from many factors. The following are some common examples:
Study statistical data investigations, summary statistics, data
visualisation and probability as a measure for uncertainty.
Then build upon these topics and learn about sampling, sampling
distributions and confidence intervals as the basis for statistical
inference.
The course will finish with a series of modules looking at common
hypothesis testing methods for different types of data.</p>
<p>(1). <strong>Measurement</strong>: Sometimes referred to as observational error, this is the variability associated with how we have measured our variables. All measures of a variable are imperfect. We need to understand the reliability and validity of our measurements to account for measurement variability. Measurement variability can come from two main sources:
1. <strong>Measures</strong>: There are usually many different ways to measure a variable. Different measures have different levels of reliability and validity. You should always use the most reliable and valid measure available. However, practical constraints may prevent this (e.g. time and money). All good measures will report their reliability and validity. If you create your own measure during the course of your research, you will need to test the reliability and validity yourself.
2. <strong>Devices</strong>: You may use the same type of measure, but use different devices to record your results. For example, using two different weighing scales to measure your samples. The problem is that different devices may introduce variability due to calibration, or natural variability between devices.
(2). <strong>Accident</strong>: This is exactly what it sounds like, just silly mistakes that can invalidate your data. As researcher, we must do everything we can to reduce such mistakes. Accidents can happen at different levels.
1. During collection: You might write down the wrong measurement, make a typo, miss a question on a questionnaire or lose participant records.
2. Processing: Errors can be made when entering and saving data, when manipulating data, and when cleaning up the data. This is very annoying and is why you should include checks when processing your data.</p>
</li>
</ul>
</li>
</ul>
<h3 id=types-of-variables-and-levels-of-measurement>Types of Variables and Levels of Measurement</h3>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952481/MATH1324/ModelOne/TypesOfVariablesAndLevelsOfMeasurement-1_hztqlq.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952481/MATH1324/ModelOne/TypesOfVariablesAndLevelsOfMeasurement-1_hztqlq.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952481/MATH1324/ModelOne/TypesOfVariablesAndLevelsOfMeasurement-1_hztqlq.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952481/MATH1324/ModelOne/TypesOfVariablesAndLevelsOfMeasurement-1_hztqlq.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952481/MATH1324/ModelOne/TypesOfVariablesAndLevelsOfMeasurement-1_hztqlq.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952481/MATH1324/ModelOne/TypesOfVariablesAndLevelsOfMeasurement-1_hztqlq.png>
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952481/MATH1324/ModelOne/TypesOfVariablesAndLevelsOfMeasurement-2_cyhvdt.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952481/MATH1324/ModelOne/TypesOfVariablesAndLevelsOfMeasurement-2_cyhvdt.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952481/MATH1324/ModelOne/TypesOfVariablesAndLevelsOfMeasurement-2_cyhvdt.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952481/MATH1324/ModelOne/TypesOfVariablesAndLevelsOfMeasurement-2_cyhvdt.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952481/MATH1324/ModelOne/TypesOfVariablesAndLevelsOfMeasurement-2_cyhvdt.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952481/MATH1324/ModelOne/TypesOfVariablesAndLevelsOfMeasurement-2_cyhvdt.png></p>
<p>A <strong>measurement</strong> occurs when a variable is actually measured or recorded. For example, you measure a person’s heart rate (measurement). Heart rate is measured on a scale, or the unit of measurement, for example, beats per minute (BPM). A set of measurement or records from a variable is called data and can come from either a sample, a sub group of a population, or the population itself. When an entire population is measured, this is referred to as a census.</p>
<h4 id=major-types-of-variables>Major Types of Variables</h4>
<p>The two major types of variables are <strong>qualitative</strong> and <strong>quantitative</strong>. The type of variables you collect and analyse have a direct bearing on the type of statistical summaries and analyses you can perform.</p>
<ul>
<li>
<p><strong>Qualitative</strong> - Qualitative variables have different qualities, characteristics or categories, e.g. hair colour (black, brown, blonde,…), disease (cancer, heart disease,…), gender (male, female), country of birth (New Zealand, Japan,…). Qualitative variables are used to categorise quantitative data into groups or to tally frequencies of categories that can be converted to proportions and percentages.</p>
</li>
<li>
<p><strong>Quantitative</strong> - Quantitative variables measure a numerical quantity on each unit. Quantitative variables can be either discrete - can only assume a finite or countable number of values, e.g. marks on a test, birthday, number of people in a lecture, or continuous - the value can assume any value corresponding to the points on a number line, e.g. time (seconds), height (cm), weight (kg), age etc.</p>
</li>
</ul>
<h4 id=levels-of-measurement>Levels of Measurement</h4>
<p>When you measure a variable, qualitative and quantitative variables can take on different scales or levels of measurement. Levels of measurement have a direct bearing on the quantitative data analysis techniques you will need to use. We need to understand the language used to describe different scales. The following short video by Nicola Petty provides a great overview.</p>
<p>{% youtube hZxnzfnt5v8 %}</p>
<ul>
<li>
<p><strong>Categorical or Nominal (Qualitative)</strong>. Categorical variables are group variables or categories if you will. There are no meaningful measurement differences such as rankings or intervals between the different categories. Categorical or nominal variables include binary variables (e.g. yes/no, male/female) and multinomial variables (e.g. religious affiliation, hair colour, ethnicity, suburb).</p>
</li>
<li>
<p><strong>Ordinal (Qualitative)</strong>. Ordinal data has a rank order by which it can be sorted but the differences between the ranks are not relative or measurable. Therefore, ordinal data is not strictly quantitative. For example, consider the 1st, 2nd and 3rd place in a race. We know who was faster or slower, but we have no idea by how much. We need to look at the race times.</p>
</li>
<li>
<p><strong>Interval (Quantitative)</strong>: An interval variable is similar to an ordinal variable except that the intervals between the values of the interval scale are equally spaced. Interval variables have an arbitrary zero point and therefore no meaningful ratios. An example is our calendar year. 1000 AD is not half of 2000 AD, and 20 degrees Celsius is not twice as “hot” as 10 degrees Celsius. This is because our calendar and Celsius scale have an arbitrary value for zero. Zero AD and zero degrees Celsius do not imply the presence of zero time or zero heat energy.</p>
</li>
</ul>
<p>Study statistical data investigations, summary statistics, data
visualisation and probability as a measure for uncertainty.
Then build upon these topics and learn about sampling, sampling
distributions and confidence intervals as the basis for statistical
inference.
The course will finish with a series of modules looking at common
hypothesis testing methods for different types of data.</p>
<ul>
<li><strong>Ratio (Quantitative)</strong>: A ratio variable is similar to an interval variable; however there is an absolute zero point and ratios are meaningful. An example is time given in seconds, length in centimeters, or heart beats per minute. A value of 0 implies the absence of a variable. We can also make statements like 30 seconds is twice the time of 15 seconds, 10 cm is half the height of 20 cm, and during exercise a person’s resting heart beat almost doubles. Zero heart rate, call 000!</li>
</ul>
<h3 id=statistical-inference---the-big-idea-of-statistics>Statistical Inference - The Big Idea of Statistics</h3>
<p>The idea of the following sections is to give you a glimpse into the big picture of this course, that is, statistical inference. What is statistical inference?</p>
<p><em><strong>“Statistical inference moves beyond the data in hand to draw conclusions about some wider universe, taking into account that variation is everywhere and the conclusions are uncertain” (Moore 2007, xxviii)</strong></em></p>
<p>As such, statistics has been referred to as the discipline involved with dealing confidently with uncertainty. Wild, Pfannkuch and Horton (2011) provided the analogy to help explain the big idea behind statistical inference.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://astral-theory-157510.appspot.com/secured/images/Wild_2011_Statistical_Inference.png data-srcset="https://astral-theory-157510.appspot.com/secured/images/Wild_2011_Statistical_Inference.png, https://astral-theory-157510.appspot.com/secured/images/Wild_2011_Statistical_Inference.png 1.5x, https://astral-theory-157510.appspot.com/secured/images/Wild_2011_Statistical_Inference.png 2x" data-sizes=auto alt=https://astral-theory-157510.appspot.com/secured/images/Wild_2011_Statistical_Inference.png title=https://astral-theory-157510.appspot.com/secured/images/Wild_2011_Statistical_Inference.png></p>
<p>Throughout this course you will develop a deeper understanding of statistical inference and the uncertainty associated with the use of samples. You will learn how samples impact data and the conclusions you draw. You will also learn how to measure and express your statistical uncertainty and confidently draw appropriate conclusions.</p>
<h3 id=the-statistical-data-investigation-process>The Statistical Data Investigation Process</h3>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952818/MATH1324/ModelOne/DataInvestigationCycle_jjljuh.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952818/MATH1324/ModelOne/DataInvestigationCycle_jjljuh.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952818/MATH1324/ModelOne/DataInvestigationCycle_jjljuh.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952818/MATH1324/ModelOne/DataInvestigationCycle_jjljuh.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952818/MATH1324/ModelOne/DataInvestigationCycle_jjljuh.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614952818/MATH1324/ModelOne/DataInvestigationCycle_jjljuh.png></p>
<p>Statistical practice is much broader than analysing data. The statistical data investigation process describes how real problems are tackled from a statistical problem solving approach. It is how statistics is applied to investigate questions in science, medicine, agriculture, business, engineering, psychology, or anywhere data are needed and the data exhibit variation.</p>
<p>As discussed previously, variation is omnipresent. At almost all levels of government, industry, and science, data are measured, quantified, and interpreted in order to understand variation. By asking statistical questions of the data, taking observations and performing experiments, data can be used by investigators to seek patterns amongst great variation.</p>
<p>The entire process of a statistical data investigation involves everything from initial thoughts, through to planning, collecting and exploring data, and reporting findings. The process is depicted and summarised in the following slideshow, along with a brief description and key considerations at each stage. Click on each stage to read more.</p>
<ol>
<li><a href=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614825208/MATH1324/ModelOne/MATH1324-ModelOne-1_hzvtqy.png target=_blank rel="noopener noreferrer"></a></li>
<li><a href=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614825208/MATH1324/ModelOne/MATH1324-ModelOne-2_ytbcc7.png target=_blank rel="noopener noreferrer"></a></li>
<li><a href=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614825208/MATH1324/ModelOne/MATH1324-ModelOne-3_wynr4p.png target=_blank rel="noopener noreferrer"></a></li>
<li><a href=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614825208/MATH1324/ModelOne/MATH1324-ModelOne-4_oe3yjb.png target=_blank rel="noopener noreferrer"></a></li>
<li><a href=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1614825208/MATH1324/ModelOne/MATH1324-ModelOne-5_sgysux.png target=_blank rel="noopener noreferrer"></a></li>
</ol>
<p>As you work through the statistical data investigation process, its useful to apply statistical habits of mind. Some useful examples proposed by <a href="https://place.fi.ncsu.edu/local/catalog/course.php?id=4" target=_blank rel="noopener noreferrer">Hollylynne Lee and Dung Tran</a> include:</p>
<ul>
<li>Always consider the context of data</li>
<li>Ensure the best measure of an attribute of interest is used</li>
<li>Anticipate, look for, and describe variation</li>
<li>Attend to sampling issues</li>
<li>Embrace uncertainty, but build confidence in interpretations</li>
<li>Use several visual and numerical representations to make sense of data</li>
<li>Be a skeptic throughout an investigation</li>
</ul>
<p>Sometimes a data investigation starts with a question, sometimes a hypothesis, sometimes a problem, and sometimes just a general situation to be explored. Statistical questions and problems are not the same as mathematical questions and problems. Don’t confuse the two. Tukey (1953), a world famous statistician, best explained this when he wrote:</p>
<p><strong>“Statistics is a science in my opinion, and it is no more a branch of mathematics than are physics, chemistry, and economics; for if its methods fail the test of experience – not the test of logic – they are discarded.”</strong></p>
<p>Furthermore, statistical questions can be differentiated based on the following:</p>
<ul>
<li>The use of context and data collection</li>
<li>Measurement decisions</li>
<li>Omnipresence of variability</li>
<li>Dealing with uncertainty</li>
</ul>
<p>In contrast, mathematics questions are characterised by the following:</p>
<ul>
<li>Problems can exist without context</li>
<li>Measurements are assumed to be exact.</li>
<li>No variability</li>
<li>Deterministic answers</li>
</ul>
<p>The following video from the Khan Academy explores how statistical questions are fundamentally different to maths questions.</p>
<p>{% youtube qyYSQDcSNlY %}</p>
<h3 id=major-types-of-statistical-data-investigations>Major Types of Statistical Data Investigations</h3>
<p>There are three major types of statistical data investigations that can be distinguished based on their aims and methods of data collection. We must understand the strengths and weaknesses of each types as these have an impact on the conclusions you draw. We will learn more about different research designs throughout the course when we look at different statistical methods.</p>
<h4 id=surveys>Surveys</h4>
<p><strong>Surveys</strong> aim to gather data from the population, in the form of responses, in order to investigate or understand some type of phenomenon. For example, you might have had experience filling out course evaluation surveys, product surveys, customer satisfaction surveys, the Australian Census, and job evaluation surveys. Surveys are typically done using samples, but may also be completed by an entire population. When this happens, this is known as a census. The Australian Census seeks to count and describe the characteristics of the Australian population in order to help Australia plan for the future. Surveys are typically administered using paper-based or online questionnaires completed by the participant, but may also involve face-to-face or telephone interviews. Surveys may seem like the easiest and most cost effective way to gather large amounts of data from a population, but that is far from the truth. Surveys have many challenges, including selecting a good sample, poor response rates, response bias, and designing good questions.</p>
<h4 id=experiments>Experiments</h4>
<p>In the simplest <strong>experimental</strong> design, participants or some other unit are randomised to a <strong>control</strong> group or a <strong>treatment</strong> group. The investigator’s manipulation of exposure to the treatment is what defines a true experiment. The treatment is referred to as an <strong>independent</strong> variable. <strong>Randomisation</strong> is used to maximise the chance of the groups being considered equivalent, in terms of their characteristics, at the start of the experiment, thus <strong>minimising systematic bias</strong> between groups. The control group does not receive the actual treatment, and may instead, receive an inert form of the treatment called a placebo. <strong>Blinding</strong> is used to prevent the results being influenced by participant expectations, by ensuring the participants are unaware of their allocated research group or the true nature behind the experiment. The investigator seeks to keep all other factors and variables constant throughout the experiment. At the end of the experiment, the investigator will measure the two groups on a dependent or outcome variable. Because of randomisation of participants and tight control, it is assumed that by the end of the experiment, any significant difference between groups on the dependent variable could ONLY be due to the treatment. Therefore, if a difference between groups is evident at the end of the experiment, its assumed to be the effect of the treatment. Thus, experiments seek to test cause and effect hypotheses. However, experiments are also the most difficult and time consuming of investigation types.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://astral-theory-157510.appspot.com/secured/images/Basic%20Experimental%20Design.png data-srcset="https://astral-theory-157510.appspot.com/secured/images/Basic%20Experimental%20Design.png, https://astral-theory-157510.appspot.com/secured/images/Basic%20Experimental%20Design.png 1.5x, https://astral-theory-157510.appspot.com/secured/images/Basic%20Experimental%20Design.png 2x" data-sizes=auto alt=https://astral-theory-157510.appspot.com/secured/images/Basic%20Experimental%20Design.png title=https://astral-theory-157510.appspot.com/secured/images/Basic%20Experimental%20Design.png></p>
<h4 id=observational-or-correlational-studies>Observational or Correlational Studies</h4>
<p>Observational or correlational research designs look for a relationship between at least two variables. Observational or correlational research do not attempt to manipulate or control an independent variable, which distinguishes it from an experiment. Therefore, these types of studies cannot test cause and effect. Instead, they are used to establish evidence of relationships, associations or correlations between variables that may suggest evidence of causal effects. Conclusions from observational and correlational investigations are always interpreted with this limitation in mind. On the plus side, these types of investigations allow researchers to study relationships between variables that cannot be manipulated in experiments. For example, ethically, you cannot randomise people to smoke cigarettes to test if it increases risk of cancer. However, you can observe and compare the incidence of cancer in people who voluntarily smoke to those who don’t.</p>
<h3 id=references>References</h3>
<p>MacGillivray, H., J. M. Utts, and R. F Heckard. 2014. Mind on statistics. 2nd ed. South Melbourne, VIC: Cengage Learning Australia.</p>
<p>Moore, D. S. 2007. The basic practice of statistics. 4th ed. New York, NY: W. H. Freeman; Company.</p>
<p>Tukey, J. W. 1953. “The growth of experimental design in a research laboratory.” In Research Operations in Industry, 303–13. New York: King’s Crown Press.</p>
<p>Wild, C., M. Pfannkuch, M. Regan, and N. J. Horton. 2011. “Towards more accessible conceptions of statistical inference.” Journal of the Royal Statistical Society 174: 247–95. <a href=https://doi.org/10.1111/j.1467-985X.2010.00678.x target=_blank rel="noopener noreferrer">https://doi.org/10.1111/j.1467-985X.2010.00678.x</a>.</p>
<h3 id=exercise-model-one>Exercise (Model One)</h3>
<ol>
<li>If two researchers gather two random samples in the same circumstances, these two samples are likely to vary. Which of the following statements best explains why?</li>
</ol>
<ul>
<li><i class="far fa-square fa-fw"></i> The researchers have not sampled correctly.</li>
<li><i class="far fa-check-square fa-fw"></i> Different samples are made up of different combinations of units from a population, and will therefore always vary to some degree.</li>
<li><i class="far fa-square fa-fw"></i> The researchers have collected their samples at different time points.</li>
<li><i class="far fa-square fa-fw"></i> Because no matter how careful they are, the researchers could not use the same method.</li>
</ul>
<ol start=2>
<li>Which of the following characteristics is unique to a statistical problem and helps differentiate it from a mathematical problem?</li>
</ol>
<ul>
<li><i class="far fa-square fa-fw"></i> Measurements are assumed to be exact.</li>
<li><i class="far fa-square fa-fw"></i> The problem can be expressed without a context.</li>
<li><i class="far fa-square fa-fw"></i> The problem has a unique answer.</li>
<li><i class="far fa-check-square fa-fw"></i> The anticipation of variation.</li>
</ul>
<ol start=3>
<li>During data collection and prior to data exploration, what should you be checking?</li>
</ol>
<ul>
<li><i class="far fa-square fa-fw"></i> Consistency of data collection</li>
<li><i class="far fa-square fa-fw"></i> Obvious error or issues</li>
<li><i class="far fa-square fa-fw"></i> Accuracy of data collection</li>
<li><i class="far fa-check-square fa-fw"></i> All of the above</li>
</ul>
<ol start=4>
<li>Variation is all around us, and this is the main reason why statistics is needed. Variation exists on many different levels. Which of the following is something that does NOT vary?</li>
</ol>
<ul>
<li><i class="far fa-square fa-fw"></i> Students' attitudes towards maths.</li>
<li><i class="far fa-square fa-fw"></i> The mean age calculated from different samples of a population.</li>
<li><i class="far fa-check-square fa-fw"></i> The ratio of a circle&rsquo;s circumference to its diameter.</li>
<li><i class="far fa-square fa-fw"></i> Measurement of an individual&rsquo;s blood pressure.</li>
</ul>
<ol start=5>
<li>Match the scale of measurement with the correct example.</li>
</ol>
<ul>
<li>Nominal - Credit card number</li>
<li>Ratio - Forced expiratory volume</li>
<li>Ordinal - Energy star ratings</li>
<li>Interval - IQ Scores</li>
</ul>
<ol start=6>
<li>Which of the following is an example of real or natural variability?</li>
</ol>
<ul>
<li><i class="far fa-square fa-fw"></i> You notice variability in your body weight measurement when using your bathroom scale and the scale in your gym.</li>
<li><i class="far fa-square fa-fw"></i> Driving to your workplace after leaving home at 10am tends to be faster than leaving at 8am.</li>
<li><i class="far fa-square fa-fw"></i> Monday train commuting times between your home station and work is around 24 minutes, but it can be as quick as 21 minutes and as long as 27.</li>
<li><i class="far fa-square fa-fw"></i> Two investigators gather a small sample of 30 adults each and measure their body mass indexes (BMI). The mean BMI for each sample is different.</li>
</ul>
<ol start=7>
<li>Which of the following is a qualitative variable?</li>
</ol>
<ul>
<li><i class="far fa-check-square fa-fw"></i> Bank account number</li>
<li><i class="far fa-square fa-fw"></i> Travel time</li>
<li><i class="far fa-square fa-fw"></i> Energy intake</li>
<li><i class="far fa-square fa-fw"></i> Wireless signal strength</li>
</ul>
<ol start=8>
<li>Which of the following is an interval level measure?</li>
</ol>
<ul>
<li><i class="far fa-square fa-fw"></i> Mass</li>
<li><i class="far fa-check-square fa-fw"></i> Degrees Fahrenheit</li>
<li><i class="far fa-square fa-fw"></i> Distance</li>
<li><i class="far fa-square fa-fw"></i> Length</li>
</ul>
<ol start=9>
<li>Statistical inference refers to:</li>
</ol>
<ul>
<li><i class="far fa-square fa-fw"></i> Measuring the population.</li>
<li><i class="far fa-square fa-fw"></i> Drawing conclusions about a sample using census data.</li>
<li><i class="far fa-check-square fa-fw"></i> Drawing conclusions about a population using sample data.</li>
<li><i class="far fa-square fa-fw"></i> Analysing your sample data.</li>
</ul>
<ol start=10>
<li>Larger random samples have less sampling error.</li>
</ol>
<ul>
<li><i class="far fa-check-square fa-fw"></i> True</li>
<li><i class="far fa-square fa-fw"></i> False</li>
</ul>
<ol start=11>
<li>
<p>Order the stages, from first to last, of the statistical data investigation process.
1 - Initial questions
2 - Issues and planning
3 - Collecting, handling and checking data
4 - Exploring, interpreting data in contect</p>
</li>
<li>
<p>Thinking statistically is required during which stages of the statistical data investigation process? Select all that apply.</p>
</li>
</ol>
<ul>
<li><i class="far fa-check-square fa-fw"></i> Initial questions</li>
<li><i class="far fa-check-square fa-fw"></i> Issues and planning</li>
<li><i class="far fa-check-square fa-fw"></i> Collecting, handling and checking data</li>
<li><i class="far fa-check-square fa-fw"></i> Exploring, interpreting data in context</li>
</ul>
<ol start=13>
<li>Which of the following is a major challenge for surveys?</li>
</ol>
<ul>
<li><i class="far fa-square fa-fw"></i> Can only be done online</li>
<li><i class="far fa-square fa-fw"></i> Unethical</li>
<li><i class="far fa-square fa-fw"></i> Expensive and time-consuming</li>
<li><i class="far fa-check-square fa-fw"></i> Response rate</li>
</ul>
<ol start=14>
<li>Why do experimental investigations use placebos?</li>
</ol>
<ul>
<li><i class="far fa-check-square fa-fw"></i> People need to think they&rsquo;re getting the treatment because peoples' beliefs and biases can impact results.</li>
<li><i class="far fa-square fa-fw"></i> Because they are cheaper than the real treatment.</li>
<li><i class="far fa-square fa-fw"></i> Because placebos are an effective treatment.</li>
<li><i class="far fa-square fa-fw"></i> So participants don&rsquo;t feel they&rsquo;re missing out.</li>
</ul>
<ol start=15>
<li>Why do experimental investigations use randomisation?</li>
</ol>
<ul>
<li><i class="far fa-square fa-fw"></i> To ensure participants are blinded to their allocated group.</li>
<li><i class="far fa-check-square fa-fw"></i> To help establish baseline equivalence between groups.</li>
<li><i class="far fa-square fa-fw"></i> To fairly allocate people to the treatment.</li>
<li><i class="far fa-square fa-fw"></i> To ensure the investigator is blinded.</li>
</ul>
<h2 id=model-two---descriptive-statistics-through-visualisation>Model Two - Descriptive Statistics through Visualisation</h2>
<h3 id=learning-objectives>Learning Objectives</h3>
<p>The learning objectives associated with this module are:</p>
<ul>
<li>
<p>Basic descriptive statistics and visualisations for qualitative variables:</p>
<ul>
<li>frequencies</li>
<li>cross-tabulations</li>
<li>bar charts</li>
<li>clustered bar charts</li>
</ul>
</li>
<li>
<p>Basic descriptive statistics and visualisations for quantitative variables:</p>
<ul>
<li>Dot plots</li>
<li>Histograms</li>
<li>Mean and standard deviation</li>
<li>Quartiles, median, and IQR</li>
<li>Box plots</li>
<li>Side-by-side box plots</li>
<li>Scatter plots to visualise the relationship between two quantitative variables</li>
</ul>
</li>
<li>
<p>Understand and apply the basic principles of producing good plots.</p>
</li>
</ul>
<h3 id=descriptive-statistics>Descriptive Statistics</h3>
<p>Descriptive statistics are methods by which complex, noisy or vast amounts of data can be converted into insightful, bite-sized, pieces of usable information. Descriptive statistics summarise characteristics of data using numbers. These include things like the mean, range, mode or percentage. Statistical visualisations are visual displays of descriptive statistics or data, most commonly graphs or plots, that summarise important features or trends. Visualisations make use of our visual sense to assist with interpreting data beyond reading tables of numbers from a page. Visualisations offer a more exciting and pleasing way to summarise data. The following sections will introduce common visualisations used in statistics to summarise difference types of variables. Often these visualisations report descriptive statistics. Therefore, these visualisations will be used to introduce common descriptive statistics.</p>
<p>This module is for the romantics. We will consider a large dataset of around 54,000 diamond prices and characteristics, you can download Diamonds dataset from <a href=https://github.com/yanboyang713/RMIT-Data-Repository/blob/main/Diamonds.csv target=_blank rel="noopener noreferrer">here</a>. Before popping the question to your significant other, ensure you know a little about diamonds…
Here’s some information about the dataset, Diamonds. The dataset includes the prices and other attributes of almost 54,000 diamonds. The variables are as follows:</p>
<ul>
<li><strong>price</strong>: price in US dollars ($326 - $18,823)</li>
<li><strong>carat</strong>: weight of the diamond (0.2 - 5.01)</li>
<li><strong>cut</strong>: quality of the cut (Fair, Good, Very Good, Premium, Ideal)</li>
<li><strong>colour</strong>: diamond colour, from J (worst) to D (best)</li>
<li><strong>clarity</strong>: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))</li>
<li><strong>x</strong>: length in mm (0–10.74)</li>
<li><strong>y</strong>: width in mm (0–58.9)</li>
<li><strong>z</strong>: depth in mm (0–31.8)</li>
<li><strong>depth</strong>: total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43–79)</li>
<li><strong>table</strong>: width of top of diamond relative to widest point (43–95)</li>
</ul>
<p>This module will also show you how to use R to summarise and plot your data. Open RStudio, load the Diamonds data (ensure you call the object Diamonds) and reproduce the R code and output below to get further practice with using R. Ensure you save your R script so you can come back to it later. Also ensure you define your factors correctly. The following code ensures that cut, colour and clarity variables are treated correctly as ordered factors.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span><span class=o>&lt;-</span> <span class=nf>factor</span><span class=p>(</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span><span class=p>,</span> <span class=n>levels</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=s>&#39;Fair&#39;</span><span class=p>,</span><span class=s>&#39;Good&#39;</span><span class=p>,</span><span class=s>&#39;Very Good&#39;</span><span class=p>,</span><span class=s>&#39;Premium&#39;</span><span class=p>,</span><span class=s>&#39;Ideal&#39;</span><span class=p>),</span> 
                      <span class=n>ordered</span><span class=o>=</span><span class=kc>TRUE</span><span class=p>)</span>

<span class=n>Diamonds</span><span class=o>$</span><span class=n>color</span><span class=o>&lt;-</span> <span class=nf>factor</span><span class=p>(</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>color</span><span class=p>,</span> <span class=n>levels</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=s>&#39;J&#39;</span><span class=p>,</span><span class=s>&#39;I&#39;</span><span class=p>,</span><span class=s>&#39;H&#39;</span><span class=p>,</span><span class=s>&#39;G&#39;</span><span class=p>,</span><span class=s>&#39;F&#39;</span><span class=p>,</span><span class=s>&#39;E&#39;</span><span class=p>,</span><span class=s>&#39;D&#39;</span><span class=p>),</span> 
                        <span class=n>ordered</span><span class=o>=</span><span class=kc>TRUE</span><span class=p>)</span>

<span class=n>Diamonds</span><span class=o>$</span><span class=n>clarity</span><span class=o>&lt;-</span> <span class=nf>factor</span><span class=p>(</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>clarity</span><span class=p>,</span> 
                          <span class=n>levels</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=s>&#39;I1&#39;</span><span class=p>,</span><span class=s>&#39;SI2&#39;</span><span class=p>,</span><span class=s>&#39;SI1&#39;</span><span class=p>,</span><span class=s>&#39;VS2&#39;</span><span class=p>,</span><span class=s>&#39;VS1&#39;</span><span class=p>,</span><span class=s>&#39;VVS2&#39;</span><span class=p>,</span><span class=s>&#39;VVS1&#39;</span><span class=p>,</span><span class=s>&#39;IF&#39;</span><span class=p>),</span> 
                           <span class=n>ordered</span><span class=o>=</span><span class=kc>TRUE</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p>54,000 is a lot of data. The only way we can get some useful information from a dataset of this size will be to use descriptive statistics. Let’s start with looking at summarising some qualitative variables.</p>
<h3 id=qualitative-variables>Qualitative Variables</h3>
<h4 id=frequency-distributions>Frequency Distributions</h4>
<p>Cut quality is a qualitative variable, measured on an ordinal scale, ranging from fair to ideal. A frequency table can be used to tally/count the number of times a particular cut quality appears in the dataset. We can use the table() function to generate a basic frequency distribution.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>library</span><span class=p>(</span><span class=n>dplyr</span><span class=p>)</span> <span class=c1># Required for data management and pipes</span>

<span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span> <span class=o>%&gt;%</span> <span class=nf>table</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## .</span>
<span class=gp>#</span><span class=c1>##      Fair      Good Very Good   Premium     Ideal </span>
<span class=gp>#</span><span class=c1>##      1610      4906     12082     13791     21551</span>
</code></pre></td></tr></table>
</div>
</div><p>Reading the output, we find the “ideal”, 21,551, cut is the most frequently occurring value. The most frequently occurring qualitative value for a variable is called the <strong>mode</strong>. There, we just covered two types of descriptive statistics in no time.</p>
<p>Counts or tallies don’t allow comparison between different datasets. For example, what if we wanted to compare the counts of the Diamonds variable to another smaller dataset? We need to use proportions, f/n, where f = the count or frequency or a value, and n = sample size. We can also readily convert proportions to percentages using f/n * 100. I’ll assume we’re all intimately familiar with percentages. You only have to walk into any shopping centre to be bombarded…</p>
<p>In R, we can report the proportions for cuts using:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span> <span class=o>%&gt;%</span> <span class=nf>table</span><span class=p>()</span> <span class=o>%&gt;%</span> <span class=nf>prop.table</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## .</span>
<span class=gp>#</span><span class=c1>##       Fair       Good  Very Good    Premium      Ideal </span>
<span class=gp>#</span><span class=c1>## 0.02984798 0.09095291 0.22398962 0.25567297 0.39953652</span>
</code></pre></td></tr></table>
</div>
</div><p>or, percentages:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span> <span class=o>%&gt;%</span> <span class=nf>table</span><span class=p>()</span> <span class=o>%&gt;%</span> <span class=nf>prop.table</span><span class=p>()</span><span class=o>*</span><span class=m>100</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## .</span>
<span class=gp>#</span><span class=c1>##      Fair      Good Very Good   Premium     Ideal </span>
<span class=gp>#</span><span class=c1>##  2.984798  9.095291 22.398962 25.567297 39.953652</span>
</code></pre></td></tr></table>
</div>
</div><h4 id=bar-charts>Bar Charts</h4>
<p>A simple and effective visualisation of qualitative data is the humble bar chart. Here’s how to get one in R. First we assign the table object name. Let’ asign the percentages to an object named perc.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>perc</span> <span class=o>&lt;-</span> <span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span> <span class=o>%&gt;%</span> <span class=nf>table</span><span class=p>()</span> <span class=o>%&gt;%</span> <span class=nf>prop.table</span><span class=p>()</span><span class=o>*</span><span class=m>100</span>
</code></pre></td></tr></table>
</div>
</div><p>Now, call the bar plot using the following function. Note how the code defines a title, x axis label and sets the height of the y axis:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>perc</span> <span class=o>%&gt;%</span> <span class=nf>barplot</span><span class=p>(</span><span class=n>main</span> <span class=o>=</span> <span class=s>&#34;Diamond Cut Quality - Percentage&#34;</span><span class=p>,</span><span class=n>ylab</span><span class=o>=</span><span class=s>&#34;Percent&#34;</span><span class=p>,</span> <span class=n>ylim</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=m>50</span><span class=p>))</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615222237/MATH1324/ModelTwo/barCharts_hrjir0.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615222237/MATH1324/ModelTwo/barCharts_hrjir0.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615222237/MATH1324/ModelTwo/barCharts_hrjir0.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615222237/MATH1324/ModelTwo/barCharts_hrjir0.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615222237/MATH1324/ModelTwo/barCharts_hrjir0.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615222237/MATH1324/ModelTwo/barCharts_hrjir0.png></p>
<p>The height of each bar represents the percentage of cut quality in the data set. This is much quicker to interpret than written tallies. Bars can also represent raw counts/tallies or proportions. Ensure you label your axes correctly to help the reader interpret your scales. It’s also a good idea to start your y-axis at 0, so as not to distort the scale and to allow relative comparisons across levels.</p>
<p><strong>Note One:</strong> If you want to draw color bar chart, please, set the col, there is a example at the below.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>barplot</span><span class=p>(</span><span class=n>freq</span><span class=p>,</span> <span class=n>main</span> <span class=o>=</span> <span class=s>&#34;Diamond Cut Quality - Percentage&#34;</span><span class=p>,</span> 
        <span class=n>ylab</span><span class=o>=</span><span class=s>&#34;Percent&#34;</span><span class=p>,</span> <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Colour&#34;</span><span class=p>,</span> <span class=n>col</span><span class=o>=</span><span class=s>&#34;deepskyblue&#34;</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><strong>Note Two:</strong> If you want to <strong>Order by frequency</strong>, there is a example at the below.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>barplot</span><span class=p>(</span><span class=n>freq</span><span class=nf>[order</span><span class=p>(</span><span class=n>freq</span><span class=p>,</span> <span class=n>decreasing</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>)</span><span class=n>]</span><span class=p>,</span> <span class=n>main</span> <span class=o>=</span> <span class=s>&#34;Diamond Cut Quality - Percentage&#34;</span><span class=p>,</span> 
        <span class=n>ylab</span><span class=o>=</span><span class=s>&#34;Percent&#34;</span><span class=p>,</span> <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Colour&#34;</span><span class=p>,</span> <span class=n>col</span><span class=o>=</span><span class=s>&#34;deepskyblue&#34;</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><h4 id=contingency-tables-cross-tabulations>Contingency Tables (Cross-tabulations)</h4>
<p>When we need to explore the relationship between two categorical variables, we can create contingency tables, also known as cross-tabulations. These tables present one categorical variable as the rows and the other categorical variable as the columns. These tables make it easy for us to calculate conditional probabilities or percentages, which makes it easier for us to explore potential associations between variables. In the following example, we will consider the relationship between the cut of a diamond and its clarity. To get the contingency table for raw counts, we use:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>table</span><span class=p>(</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span><span class=p>,</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>clarity</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##            </span>
<span class=gp>#</span><span class=c1>##               I1  SI2  SI1  VS2  VS1 VVS2 VVS1   IF</span>
<span class=gp>#</span><span class=c1>##   Fair       210  466  408  261  170   69   17    9</span>
<span class=gp>#</span><span class=c1>##   Good        96 1081 1560  978  648  286  186   71</span>
<span class=gp>#</span><span class=c1>##   Very Good   84 2100 3240 2591 1775 1235  789  268</span>
<span class=gp>#</span><span class=c1>##   Premium    205 2949 3575 3357 1989  870  616  230</span>
<span class=gp>#</span><span class=c1>##   Ideal      146 2598 4282 5071 3589 2606 2047 1212</span>
</code></pre></td></tr></table>
</div>
</div><p>However, because there are differences between the row and column totals for each category, it makes looking at trends difficult. We can calculate the conditional column percentages using the following code. Notice how the round() function has been included to reduce the size of the probabilities in the table cells. Otherwise, R will round to six decimal places and the table will be too large.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>table</span><span class=p>(</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span><span class=p>,</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>clarity</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>prop.table</span><span class=p>(</span><span class=n>margin</span> <span class=o>=</span> <span class=m>2</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>round</span><span class=p>(</span><span class=m>3</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##            </span>
<span class=gp>#</span><span class=c1>##                I1   SI2   SI1   VS2   VS1  VVS2  VVS1    IF</span>
<span class=gp>#</span><span class=c1>##   Fair      0.283 0.051 0.031 0.021 0.021 0.014 0.005 0.005</span>
<span class=gp>#</span><span class=c1>##   Good      0.130 0.118 0.119 0.080 0.079 0.056 0.051 0.040</span>
<span class=gp>#</span><span class=c1>##   Very Good 0.113 0.228 0.248 0.211 0.217 0.244 0.216 0.150</span>
<span class=gp>#</span><span class=c1>##   Premium   0.277 0.321 0.274 0.274 0.243 0.172 0.169 0.128</span>
<span class=gp>#</span><span class=c1>##   Ideal     0.197 0.283 0.328 0.414 0.439 0.514 0.560 0.677</span>
</code></pre></td></tr></table>
</div>
</div><p>These are conditional column probabilities, determined by margin = 2, because if we add all the probabilities for a column together, they will equal 1, e.g. sum(0.283, 0.130, 0.113, 0.227, 0.197) = 1.00. Let me prove it:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>tbl</span> <span class=o>&lt;-</span> <span class=nf>table</span><span class=p>(</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span><span class=p>,</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>clarity</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>prop.table</span><span class=p>(</span><span class=n>margin</span> <span class=o>=</span> <span class=m>2</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>round</span><span class=p>(</span><span class=m>3</span><span class=p>)</span>
<span class=n>tbl[</span><span class=p>,</span><span class=m>1</span><span class=n>]</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##      Fair      Good Very Good   Premium     Ideal </span>
<span class=gp>#</span><span class=c1>##     0.283     0.130     0.113     0.277     0.197</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>tbl[</span><span class=p>,</span><span class=m>1</span><span class=n>]</span> <span class=o>%&gt;%</span> <span class=nf>sum</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 1</span>
</code></pre></td></tr></table>
</div>
</div><p>If we had set margin = 1 we would get row proportions:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>table</span><span class=p>(</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span><span class=p>,</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>clarity</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>prop.table</span><span class=p>(</span><span class=n>margin</span> <span class=o>=</span> <span class=m>1</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>round</span><span class=p>(</span><span class=m>3</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##            </span>
<span class=gp>#</span><span class=c1>##                I1   SI2   SI1   VS2   VS1  VVS2  VVS1    IF</span>
<span class=gp>#</span><span class=c1>##   Fair      0.130 0.289 0.253 0.162 0.106 0.043 0.011 0.006</span>
<span class=gp>#</span><span class=c1>##   Good      0.020 0.220 0.318 0.199 0.132 0.058 0.038 0.014</span>
<span class=gp>#</span><span class=c1>##   Very Good 0.007 0.174 0.268 0.214 0.147 0.102 0.065 0.022</span>
<span class=gp>#</span><span class=c1>##   Premium   0.015 0.214 0.259 0.243 0.144 0.063 0.045 0.017</span>
<span class=gp>#</span><span class=c1>##   Ideal     0.007 0.121 0.199 0.235 0.167 0.121 0.095 0.056</span>
</code></pre></td></tr></table>
</div>
</div><p>If we had left margin blank, we would get cell proportions:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>table</span><span class=p>(</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span><span class=p>,</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>clarity</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>prop.table</span><span class=p>()</span> <span class=o>%&gt;%</span> <span class=nf>round</span><span class=p>(</span><span class=m>3</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##            </span>
<span class=gp>#</span><span class=c1>##                I1   SI2   SI1   VS2   VS1  VVS2  VVS1    IF</span>
<span class=gp>#</span><span class=c1>##   Fair      0.004 0.009 0.008 0.005 0.003 0.001 0.000 0.000</span>
<span class=gp>#</span><span class=c1>##   Good      0.002 0.020 0.029 0.018 0.012 0.005 0.003 0.001</span>
<span class=gp>#</span><span class=c1>##   Very Good 0.002 0.039 0.060 0.048 0.033 0.023 0.015 0.005</span>
<span class=gp>#</span><span class=c1>##   Premium   0.004 0.055 0.066 0.062 0.037 0.016 0.011 0.004</span>
<span class=gp>#</span><span class=c1>##   Ideal     0.003 0.048 0.079 0.094 0.067 0.048 0.038 0.022</span>
</code></pre></td></tr></table>
</div>
</div><p>Summing all the cells together would now equal 1. We will spend more time in Module 3 looking at the interpretation of large contingency tables. Now, let’s interpret the column probabilities. Recall:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>table</span><span class=p>(</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span><span class=p>,</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>clarity</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>prop.table</span><span class=p>(</span><span class=n>margin</span> <span class=o>=</span> <span class=m>2</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>round</span><span class=p>(</span><span class=m>3</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##            </span>
<span class=gp>#</span><span class=c1>##                I1   SI2   SI1   VS2   VS1  VVS2  VVS1    IF</span>
<span class=gp>#</span><span class=c1>##   Fair      0.283 0.051 0.031 0.021 0.021 0.014 0.005 0.005</span>
<span class=gp>#</span><span class=c1>##   Good      0.130 0.118 0.119 0.080 0.079 0.056 0.051 0.040</span>
<span class=gp>#</span><span class=c1>##   Very Good 0.113 0.228 0.248 0.211 0.217 0.244 0.216 0.150</span>
<span class=gp>#</span><span class=c1>##   Premium   0.277 0.321 0.274 0.274 0.243 0.172 0.169 0.128</span>
<span class=gp>#</span><span class=c1>##   Ideal     0.197 0.283 0.328 0.414 0.439 0.514 0.560 0.677</span>
</code></pre></td></tr></table>
</div>
</div><p>Let’s contrast the worst clarity I1 with the best, IF (Flawless). For I1, we find that the probability for a fair, good, very good, premium and ideal cut are 0.283, 0.130, 0.113, 0.227, and 0.197 respectively. However, for IF, the same probabilities are 0.005, 0.040, 0.150, 0.128 and 0.677 respectively. We can see that IF diamonds are far more likely to have superior cuts, which makes perfect sense. You don’t give the best diamonds to the cutting apprentice!</p>
<p>Interpreting associations and trends from large contingency tables such as this can take a considerable amount of brain power. We can make this process easier and more enjoyable using a visualisation. We can use an extension of the bar chart for this purpose.</p>
<h4 id=clustered-bar-charts>Clustered Bar Charts</h4>
<p>Clustered bar charts are a great way to visualise two qualitative variables. Let’s plot the conditional column proportions of the cut by clarity contingency table using R. First, we need to save the conditional proportions in an object called <strong>table_1</strong>. This will make it easy for us to create the clustered bar chart.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>table_1</span> <span class=o>&lt;-</span> <span class=nf>table</span><span class=p>(</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>cut</span><span class=p>,</span><span class=n>Diamonds</span><span class=o>$</span><span class=n>clarity</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>prop.table</span><span class=p>(</span><span class=n>margin</span> <span class=o>=</span> <span class=m>2</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p>Next we can plot the probabilities. Note the various options used to change the plot title, y axis label, y axis range, legend and x axis label.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>table_1</span> <span class=o>%&gt;%</span> <span class=nf>barplot</span><span class=p>(</span><span class=n>main</span> <span class=o>=</span> <span class=s>&#34;Diamond Cut Quality by Clarity&#34;</span><span class=p>,</span> <span class=n>ylab</span><span class=o>=</span><span class=s>&#34;Proportion within Clarity&#34;</span><span class=p>,</span>
                    <span class=n>ylim</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=m>.8</span><span class=p>),</span> <span class=n>legend</span><span class=o>=</span><span class=nf>rownames</span><span class=p>(</span><span class=n>table_1</span><span class=p>),</span> <span class=n>beside</span><span class=o>=</span><span class=kc>TRUE</span><span class=p>,</span>
                    <span class=n>args.legend</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=n>x</span> <span class=o>=</span> <span class=s>&#34;top&#34;</span><span class=p>,</span> <span class=n>horiz</span><span class=o>=</span><span class=kc>TRUE</span><span class=p>,</span> <span class=n>title</span><span class=o>=</span><span class=s>&#34;Cut&#34;</span><span class=p>),</span>
                    <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Clarity&#34;</span><span class=p>)</span>
<span class=nf>grid</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615224038/MATH1324/ModelTwo/ClusteredBarCharts_s2auq4.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615224038/MATH1324/ModelTwo/ClusteredBarCharts_s2auq4.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615224038/MATH1324/ModelTwo/ClusteredBarCharts_s2auq4.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615224038/MATH1324/ModelTwo/ClusteredBarCharts_s2auq4.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615224038/MATH1324/ModelTwo/ClusteredBarCharts_s2auq4.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615224038/MATH1324/ModelTwo/ClusteredBarCharts_s2auq4.png></p>
<p>Notice how grid() was added after the plot was produced in R. Grid lines can help the viewer quickly read off and compare values on the plot axes.
Looking at this clustered bar chart, it becomes quickly apparent that as the clarity of a diamond increases, the quality of the cut also tends to increase. Perfect! See how simple statistics can be. You just interpreted your first categorical association. We will dig deeper into categorical associations again in Module 3 and 8.</p>
<p><strong>NOTE One:</strong> If you have NOT set <strong>beside=TRUE</strong>, the bar chart will looks like a &ldquo;stack&rdquo;. There is a example at the below.
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615312286/MATH1324/ModelTwo/ClusteredBarChartStack_qrjnrj.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615312286/MATH1324/ModelTwo/ClusteredBarChartStack_qrjnrj.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615312286/MATH1324/ModelTwo/ClusteredBarChartStack_qrjnrj.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615312286/MATH1324/ModelTwo/ClusteredBarChartStack_qrjnrj.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615312286/MATH1324/ModelTwo/ClusteredBarChartStack_qrjnrj.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615312286/MATH1324/ModelTwo/ClusteredBarChartStack_qrjnrj.png></p>
<p><strong>NOTE Two:</strong> If the legend overlaps the bars! Let’s adjust the y-axis to increase the white space in the top of the plot, using the ylim option.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>barplot</span><span class=p>(</span><span class=n>color_cut</span><span class=p>,</span> <span class=n>main</span> <span class=o>=</span> <span class=s>&#34;Diamond Colour by Cut Quality&#34;</span><span class=p>,</span><span class=n>ylab</span><span class=o>=</span><span class=s>&#34;Proportion within Cut&#34;</span><span class=p>,</span>
        <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Cut&#34;</span><span class=p>,</span> <span class=n>beside</span><span class=o>=</span><span class=kc>TRUE</span><span class=p>,</span> <span class=n>legend</span><span class=o>=</span><span class=nf>rownames</span><span class=p>(</span><span class=n>color_cut</span><span class=p>),</span> 
        <span class=n>args.legend</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=n>x</span> <span class=o>=</span> <span class=s>&#34;top&#34;</span><span class=p>,</span><span class=n>horiz</span><span class=o>=</span><span class=kc>TRUE</span><span class=p>,</span><span class=n>title</span><span class=o>=</span><span class=s>&#34;Cut&#34;</span><span class=p>),</span> <span class=n>ylim</span> <span class=o>=</span> <span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=m>.30</span><span class=p>))</span>
<span class=nf>grid</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615312779/MATH1324/ModelTwo/ClusteredBarChartWithYlim_n65lln.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615312779/MATH1324/ModelTwo/ClusteredBarChartWithYlim_n65lln.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615312779/MATH1324/ModelTwo/ClusteredBarChartWithYlim_n65lln.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615312779/MATH1324/ModelTwo/ClusteredBarChartWithYlim_n65lln.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615312779/MATH1324/ModelTwo/ClusteredBarChartWithYlim_n65lln.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615312779/MATH1324/ModelTwo/ClusteredBarChartWithYlim_n65lln.png></p>
<p><strong>NOTE Three:</strong> Better, but it’s hard to differentiate between the grey colours! Let’s use some more discernible colours. We can use a colour Brewer palette from the RColorBrewer package (ensure you install this package first). For example, we can set a diverging blue-red palette using col=brewer.pal(n = 7, name = &ldquo;RdBu&rdquo;).</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>library</span><span class=p>(</span><span class=n>RColorBrewer</span><span class=p>)</span>
<span class=nf>barplot</span><span class=p>(</span><span class=n>color_cut</span><span class=p>,</span> <span class=n>main</span> <span class=o>=</span> <span class=s>&#34;Diamond Colour by Cut Quality&#34;</span><span class=p>,</span><span class=n>ylab</span><span class=o>=</span><span class=s>&#34;Proportion within Cut&#34;</span><span class=p>,</span>
        <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Cut&#34;</span><span class=p>,</span> <span class=n>beside</span><span class=o>=</span><span class=kc>TRUE</span><span class=p>,</span> 
        <span class=n>legend</span><span class=o>=</span><span class=nf>rownames</span><span class=p>(</span><span class=n>color_cut</span><span class=p>),</span> 
        <span class=n>args.legend</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=n>x</span> <span class=o>=</span> <span class=s>&#34;top&#34;</span><span class=p>,</span><span class=n>horiz</span><span class=o>=</span><span class=kc>TRUE</span><span class=p>,</span><span class=n>title</span><span class=o>=</span><span class=s>&#34;Color&#34;</span><span class=p>),</span>
        <span class=n>ylim</span> <span class=o>=</span> <span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=m>.30</span><span class=p>),</span>
        <span class=n>col</span><span class=o>=</span><span class=nf>brewer.pal</span><span class=p>(</span><span class=m>7</span><span class=p>,</span> <span class=n>name</span> <span class=o>=</span> <span class=s>&#34;RdBu&#34;</span><span class=p>))</span>
<span class=nf>grid</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615313079/MATH1324/ModelTwo/ClusteredBarChartWithColor_djetpm.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615313079/MATH1324/ModelTwo/ClusteredBarChartWithColor_djetpm.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615313079/MATH1324/ModelTwo/ClusteredBarChartWithColor_djetpm.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615313079/MATH1324/ModelTwo/ClusteredBarChartWithColor_djetpm.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615313079/MATH1324/ModelTwo/ClusteredBarChartWithColor_djetpm.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615313079/MATH1324/ModelTwo/ClusteredBarChartWithColor_djetpm.png></p>
<h3 id=quantitative-variables>Quantitative Variables</h3>
<p>Quantitative variables require different types of statistical summaries and visualisations. Let’s start with a small sample of the diamond data to make the calculations manageable, and then we will scale-up to the full 54,000 for some awesome plotting later in the module.</p>
<p>The <a href=https://github.com/yanboyang713/RMIT-Data-Repository/blob/main/Diamonds_sample.csv target=_blank rel="noopener noreferrer">Diamonds_sample.csv</a> dataset contains a small random sample of 30 diamonds’ mass measured in carats.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds_sample</span> <span class=o>&lt;-</span> <span class=nf>read.csv</span><span class=p>(</span><span class=s>&#34;data/Diamonds_sample.csv&#34;</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><h4 id=dot-plots>Dot Plots</h4>
<p>Dot plots are a nice visual representation of small quantitative datasets. Each dot is arranged into bins on the x-axis and stacked on top of each other to report the frequency. Dot plots represent the distribution of a quantitative variable, and granularity of the small sample. We can use dot plots to quickly see where values are clustering and tending towards, as well as unusual cases known as outliers. To get a dot plot in R, you first must install and load the ggplot2 package.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>install.packages</span><span class=p>(</span><span class=s>&#34;ggplot2&#34;</span><span class=p>)</span>
<span class=nf>library</span><span class=p>(</span><span class=n>ggplot2</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p>We can use a <strong>ggplot2</strong> quick plot function to produce the dot plot.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds_sample</span> <span class=o>%&gt;%</span> <span class=nf>qplot</span><span class=p>(</span><span class=n>data</span> <span class=o>=</span> <span class=n>.,</span> <span class=n>x</span> <span class=o>=</span> <span class=n>depth</span><span class=p>,</span> <span class=n>geom</span> <span class=o>=</span> <span class=s>&#34;dotplot&#34;</span><span class=p>,</span> <span class=n>binwidth</span> <span class=o>=</span> <span class=m>.25</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots1_obcrjt.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots1_obcrjt.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots1_obcrjt.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots1_obcrjt.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots1_obcrjt.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots1_obcrjt.png></p>
<p>The dot plot of 30 random diamond depths are arranged into bins with widths of .25 mm. For example, three values were between 63.75 mm and 64mm, five values between 61 and 61.25, etc. It’s a little hard to tell, which is where we encounter some of the issues with dot plots. The main drawback of dot plots is that they don’t show the actual values. So, we can’t tell exactly what they are. They are also sensitive to the number of bins or internals used in the plot. Setting the right bin widths is tricky.</p>
<p>Let’s set a larger number of intervals, or bins, in the plot, by making the intervals smaller.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds_sample</span> <span class=o>%&gt;%</span> <span class=nf>qplot</span><span class=p>(</span><span class=n>data</span> <span class=o>=</span> <span class=n>.,</span> <span class=n>x</span> <span class=o>=</span> <span class=n>depth</span><span class=p>,</span> <span class=n>geom</span> <span class=o>=</span> <span class=s>&#34;dotplot&#34;</span><span class=p>,</span> <span class=n>binwidth</span> <span class=o>=</span> <span class=m>.1</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots2_ohnqjl.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots2_ohnqjl.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots2_ohnqjl.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots2_ohnqjl.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots2_ohnqjl.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots2_ohnqjl.png></p>
<p>By increasing the number of internals or bins to nint=10, the dot plot drastically changes appearance. This is a drawback to visualising small samples. Often the choice of parameters used in the plot can change interpretations. Be mindful.</p>
<p>They are also problematic for large datasets…</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span> <span class=o>%&gt;%</span> <span class=nf>qplot</span><span class=p>(</span><span class=n>data</span> <span class=o>=</span> <span class=n>.,</span> <span class=n>x</span> <span class=o>=</span> <span class=n>depth</span><span class=p>,</span> <span class=n>geom</span> <span class=o>=</span> <span class=s>&#34;dotplot&#34;</span><span class=p>,</span> <span class=n>binwidth</span> <span class=o>=</span> <span class=m>.25</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots3_j6sdnf.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots3_j6sdnf.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots3_j6sdnf.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots3_j6sdnf.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots3_j6sdnf.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615226573/MATH1324/ModelTwo/DotPlots3_j6sdnf.png></p>
<h4 id=histograms>Histograms</h4>
<p>When dealing with large amounts of quantitative data, we can use histograms to explore the distributions of interval and ratio data. Let’s use R to create some histograms of diamond prices:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span><span class=o>$</span><span class=n>price</span> <span class=o>%&gt;%</span>  <span class=nf>hist</span><span class=p>(</span><span class=n>col</span><span class=o>=</span><span class=s>&#34;grey&#34;</span><span class=p>,</span><span class=n>xlim</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=m>20000</span><span class=p>),</span>
                         <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Diamond Price&#34;</span><span class=p>,</span>
                         <span class=n>main</span><span class=o>=</span><span class=s>&#34;Histogram of Diamond Prices&#34;</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms1_jkc0zk.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms1_jkc0zk.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms1_jkc0zk.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms1_jkc0zk.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms1_jkc0zk.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms1_jkc0zk.png></p>
<p>Take note of how the code limits the x axis to values between $0 and $20,000, we have also set the colour of the bars to grey and a plot title.</p>
<p>Histograms break the data into bins, or intervals, depicted using bars, where the height of the bar typically refers to the frequency. Due to the large amount of data, the bars are joined together to form a continuous wall. This is the drawback of using histograms for small samples. The continue wall of bars can give the viewer a false sense of the data’s density. Dot plots are much better for small samples as each dot depicts the granularity of the data. The histogram of prices is interesting. We can quickly lean the following:</p>
<ul>
<li>Prices range goes all the way up to $19,000 U.S.</li>
<li>Most diamond prices are below $5,000</li>
<li>The most common diamond prices are between 0 to $1,000.</li>
</ul>
<p>The price distribution is an example of what we would call a positively, or right skewed, distribution. You will see examples of other distributions shortly.</p>
<p>We can use R to find the bin intervals used to construct the plot:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>bins</span> <span class=o>&lt;-</span> <span class=n>Diamonds</span><span class=o>$</span><span class=n>price</span> <span class=o>%&gt;%</span> <span class=nf>hist</span><span class=p>()</span>
<span class=n>bins</span><span class=o>$</span><span class=n>breaks</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##  [1]     0  1000  2000  3000  4000  5000  6000  7000  8000  9000 10000 11000</span>
<span class=gp>#</span><span class=c1>## [13] 12000 13000 14000 15000 16000 17000 18000 19000</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>bins</span><span class=o>$</span><span class=n>counts</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##  [1] 14524  9683  6129  4225  4665  3163  2278  1668  1307  1076   934   825</span>
<span class=gp>#</span><span class=c1>## [13]   701   603   504   513   425   405   312</span>
</code></pre></td></tr></table>
</div>
</div><p>Using this information, we can create the table to the below which explains how the data were plotted in the histogram above.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>binstable</span> <span class=o>&lt;-</span> <span class=nf>data.frame</span><span class=p>(</span><span class=n>Breaks</span> <span class=o>=</span> <span class=n>bins</span><span class=o>$</span><span class=n>breaks</span><span class=p>,</span> <span class=n>Counts</span> <span class=o>=</span> <span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=n>bins</span><span class=o>$</span><span class=n>counts</span><span class=p>))</span>
<span class=n>binstable</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##    Breaks Counts</span>
<span class=gp>#</span><span class=c1>## 1       0      0</span>
<span class=gp>#</span><span class=c1>## 2    1000  14524</span>
<span class=gp>#</span><span class=c1>## 3    2000   9683</span>
<span class=gp>#</span><span class=c1>## 4    3000   6129</span>
<span class=gp>#</span><span class=c1>## 5    4000   4225</span>
<span class=gp>#</span><span class=c1>## 6    5000   4665</span>
<span class=gp>#</span><span class=c1>## 7    6000   3163</span>
<span class=gp>#</span><span class=c1>## 8    7000   2278</span>
<span class=gp>#</span><span class=c1>## 9    8000   1668</span>
<span class=gp>#</span><span class=c1>## 10   9000   1307</span>
<span class=gp>#</span><span class=c1>## 11  10000   1076</span>
<span class=gp>#</span><span class=c1>## 12  11000    934</span>
<span class=gp>#</span><span class=c1>## 13  12000    825</span>
<span class=gp>#</span><span class=c1>## 14  13000    701</span>
<span class=gp>#</span><span class=c1>## 15  14000    603</span>
<span class=gp>#</span><span class=c1>## 16  15000    504</span>
<span class=gp>#</span><span class=c1>## 17  16000    513</span>
<span class=gp>#</span><span class=c1>## 18  17000    425</span>
<span class=gp>#</span><span class=c1>## 19  18000    405</span>
<span class=gp>#</span><span class=c1>## 20  19000    312</span>
</code></pre></td></tr></table>
</div>
</div><p>Even with histograms and large data, we must be careful with how the choice of bins can change the appearance of a histogram. Consider the following histogram to see how much change can occur when reducing or increasing the number of bins from the default values.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span><span class=o>$</span><span class=n>price</span> <span class=o>%&gt;%</span> <span class=nf>hist</span><span class=p>(</span><span class=n>col</span><span class=o>=</span><span class=s>&#34;grey&#34;</span><span class=p>,</span> <span class=n>xlim</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=m>20000</span><span class=p>),</span> <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Diamond Price&#34;</span><span class=p>,</span> 
                        <span class=n>main</span><span class=o>=</span><span class=s>&#34;Histogram of Diamond Prices&#34;</span><span class=p>,</span> <span class=n>breaks</span><span class=o>=</span><span class=m>10</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms2_mmgkwt.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms2_mmgkwt.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms2_mmgkwt.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms2_mmgkwt.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms2_mmgkwt.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms2_mmgkwt.png></p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span><span class=o>$</span><span class=n>price</span> <span class=o>%&gt;%</span> <span class=nf>hist</span><span class=p>(</span><span class=n>col</span><span class=o>=</span><span class=s>&#34;grey&#34;</span><span class=p>,</span> <span class=n>xlim</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=m>20000</span><span class=p>),</span> <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Diamond Price&#34;</span><span class=p>,</span>
                        <span class=n>main</span><span class=o>=</span><span class=s>&#34;Histogram of Diamond Prices&#34;</span><span class=p>,</span> <span class=n>breaks</span><span class=o>=</span><span class=m>50</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms3_cwybcp.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms3_cwybcp.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms3_cwybcp.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms3_cwybcp.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms3_cwybcp.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227098/MATH1324/ModelTwo/Histograms3_cwybcp.png></p>
<p>Histograms are a great way to compare different distributions. We can panel a series of histograms together on a common scale to help comparisons. The following code panels together histograms of diamond prices across different cuts.</p>
<p>We have to use a slightly different <strong>histogram()</strong> function from the lattice package:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>library</span><span class=p>(</span><span class=n>lattice</span><span class=p>)</span>
<span class=n>Diamonds</span> <span class=o>%&gt;%</span> <span class=nf>histogram</span><span class=p>(</span><span class=o>~</span> <span class=n>price</span><span class=o>|</span><span class=n>cut</span><span class=p>,</span> <span class=n>col</span><span class=o>=</span><span class=s>&#34;dodgerblue3&#34;</span><span class=p>,</span>
                       <span class=n>layout</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=m>1</span><span class=p>,</span><span class=m>5</span><span class=p>),</span> <span class=n>data</span><span class=o>=</span><span class=n>.,</span> <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Price&#34;</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227099/MATH1324/ModelTwo/Histograms4_peokcx.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227099/MATH1324/ModelTwo/Histograms4_peokcx.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227099/MATH1324/ModelTwo/Histograms4_peokcx.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227099/MATH1324/ModelTwo/Histograms4_peokcx.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227099/MATH1324/ModelTwo/Histograms4_peokcx.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615227099/MATH1324/ModelTwo/Histograms4_peokcx.png></p>
<p>As you can see, the histograms look largely the same and it’s difficult to see a distinct relationship between cut and price. Cut, alone, is probably not a good indicator of price.</p>
<h4 id=distribution-shapes>Distribution Shapes</h4>
<p>Statisticians have an entire language dedicated to articulating the shape of quantitative variables’ distributions. The following info-graphic introduces some of the common terms. These are important terms to understand, as the shape of a distribution often determines our choice of descriptive statistics and statistical tests. You will learn more as the course goes on.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615228664/MATH1324/ModelTwo/DistributionShapes_at3gjf.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615228664/MATH1324/ModelTwo/DistributionShapes_at3gjf.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615228664/MATH1324/ModelTwo/DistributionShapes_at3gjf.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615228664/MATH1324/ModelTwo/DistributionShapes_at3gjf.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615228664/MATH1324/ModelTwo/DistributionShapes_at3gjf.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615228664/MATH1324/ModelTwo/DistributionShapes_at3gjf.png></p>
<h4 id=measures-of-central-tendency>Measures of Central Tendency</h4>
<p>We’ve looked at dot plots and histograms for visualising quantitative variables. Now we will consider some basic descriptive statistics used to summarise the essential features of data distributions, including both measures of central tendency and variation. We will focus our attention on the mean and standard deviation.</p>
<h5 id=mean-and-standard-deviation>Mean and Standard Deviation</h5>
<p>Let’s step back to the small sample of diamond data, Diamonds_sample, to calculate the mean depth of the data depicted in the dot plot. The mean of a dataset, x¯ is calculated as:</p>
<p>$$x¯ = \frac{\sum_{n}^{i=1} x_i }{n}$$</p>
<p>where $$x_i$$ is a sample value and n is the sample size. The formula is simply the sum of all the data points divided by the sample size. In R, we could code:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>sum</span><span class=p>(</span><span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span><span class=p>)</span><span class=o>/</span><span class=nf>length</span><span class=p>(</span><span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 61.77667</span>
</code></pre></td></tr></table>
</div>
</div><p>Fortunately, R has statistical functions that make this easier.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span> <span class=o>%&gt;%</span> <span class=nf>mean</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 61.77667</span>
</code></pre></td></tr></table>
</div>
</div><p>The mean is a measure of central tendency that can be used to describe the average or typical value for a dataset. It takes all values into account and is therefore sensitive to all values in a dataset. This can create problems in <strong>skewed distributions</strong> or <strong>distributions with unusual or outlying values</strong>.</p>
<p>The mean is also a single measure of centre. It tells us nothing about spread or variation. Variation is the essence of statistics, so we need summary statistics that can convey variation. A crude measure of variation includes the <strong>range</strong>:</p>
<p>$$Range = Max - Min$$</p>
<p>The range is simply the maximum value of a dataset, minus the minimum value. Using R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>max</span><span class=p>(</span><span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span><span class=p>)</span><span class=o>-</span><span class=nf>min</span><span class=p>(</span><span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 5.7</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>range</span><span class=p>(</span><span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 58.2 63.9</span>
</code></pre></td></tr></table>
</div>
</div><p>The <strong>range</strong> is not very useful. It is based on only two data points and misses all the interesting stuff happening in between. A better indicator of variation is the sample variance, $$s^2$$ and sample standard deviation, <strong>s</strong>. The sample variance is calculated using the following formula:</p>
<p>$$s^2 = (1/(n−1() /sum_{i=1}^n (x_i − \bar{x})^2$$</p>
<p>You may also wonder why the equation divides by n−1 and not just n. This is known as <a href=https://en.wikipedia.org/wiki/Bessel%27s_correction target=_blank rel="noopener noreferrer">Bessel’s correction</a>. A sample’s variance is known to underestimate the population variance, σ2. Dividing by n−1 corrects for this bias.</p>
<p>The standard deviation is simply the square-root of the variance:</p>
<p>$$ s = sqrt{s^2} $$</p>
<p>To calculate this, we can use the var() and sd() functions:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span> <span class=o>%&gt;%</span> <span class=nf>var</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 2.106678</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span> <span class=o>%&gt;%</span> <span class=nf>sd</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 1.45144</span>
</code></pre></td></tr></table>
</div>
</div><p>The following code walks through the computational steps of these two formulae. First we compute the variance, var().</p>
<p>Calculate the deviations x_i − bat{x}</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>dev</span> <span class=o>&lt;-</span> <span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span> <span class=o>-</span> <span class=nf>mean</span><span class=p>(</span><span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span><span class=p>)</span>
<span class=n>sd.table</span> <span class=o>&lt;-</span> <span class=nf>data.frame</span><span class=p>(</span><span class=n>Depth</span> <span class=o>=</span> <span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span><span class=p>,</span> 
                       <span class=n>Mean</span> <span class=o>=</span> <span class=nf>mean</span><span class=p>(</span><span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span><span class=p>),</span> <span class=n>Deviation</span> <span class=o>=</span> <span class=n>dev</span><span class=p>)</span>
<span class=n>sd.table</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##    Depth     Mean   Deviation</span>
<span class=gp>#</span><span class=c1>## 1   61.9 61.77667  0.12333333</span>
<span class=gp>#</span><span class=c1>## 2   59.3 61.77667 -2.47666667</span>
<span class=gp>#</span><span class=c1>## 3   59.6 61.77667 -2.17666667</span>
<span class=gp>#</span><span class=c1>## 4   59.5 61.77667 -2.27666667</span>
<span class=gp>#</span><span class=c1>## 5   61.6 61.77667 -0.17666667</span>
<span class=gp>#</span><span class=c1>## 6   62.2 61.77667  0.42333333</span>
<span class=gp>#</span><span class=c1>## 7   61.6 61.77667 -0.17666667</span>
<span class=gp>#</span><span class=c1>## 8   62.5 61.77667  0.72333333</span>
<span class=gp>#</span><span class=c1>## 9   63.4 61.77667  1.62333333</span>
<span class=gp>#</span><span class=c1>## 10  63.4 61.77667  1.62333333</span>
<span class=gp>#</span><span class=c1>## 11  60.6 61.77667 -1.17666667</span>
<span class=gp>#</span><span class=c1>## 12  63.9 61.77667  2.12333333</span>
<span class=gp>#</span><span class=c1>## 13  61.2 61.77667 -0.57666667</span>
<span class=gp>#</span><span class=c1>## 14  62.5 61.77667  0.72333333</span>
<span class=gp>#</span><span class=c1>## 15  62.2 61.77667  0.42333333</span>
<span class=gp>#</span><span class=c1>## 16  59.8 61.77667 -1.97666667</span>
<span class=gp>#</span><span class=c1>## 17  61.8 61.77667  0.02333333</span>
<span class=gp>#</span><span class=c1>## 18  58.2 61.77667 -3.57666667</span>
<span class=gp>#</span><span class=c1>## 19  63.7 61.77667  1.92333333</span>
<span class=gp>#</span><span class=c1>## 20  62.7 61.77667  0.92333333</span>
<span class=gp>#</span><span class=c1>## 21  61.2 61.77667 -0.57666667</span>
<span class=gp>#</span><span class=c1>## 22  63.8 61.77667  2.02333333</span>
<span class=gp>#</span><span class=c1>## 23  62.5 61.77667  0.72333333</span>
<span class=gp>#</span><span class=c1>## 24  61.0 61.77667 -0.77666667</span>
<span class=gp>#</span><span class=c1>## 25  62.8 61.77667  1.02333333</span>
<span class=gp>#</span><span class=c1>## 26  61.0 61.77667 -0.77666667</span>
<span class=gp>#</span><span class=c1>## 27  62.3 61.77667  0.52333333</span>
<span class=gp>#</span><span class=c1>## 28  62.6 61.77667  0.82333333</span>
<span class=gp>#</span><span class=c1>## 29  61.2 61.77667 -0.57666667</span>
<span class=gp>#</span><span class=c1>## 30  63.3 61.77667  1.52333333</span>
</code></pre></td></tr></table>
</div>
</div><p>Now square the deviations, $$ (x_i − bar{x}) ^ 2:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>dev2</span> <span class=o>&lt;-</span> <span class=n>dev^2</span>
<span class=n>sd.table</span><span class=o>$</span><span class=n>DevSq</span> <span class=o>&lt;-</span> <span class=n>dev2</span>
<span class=n>sd.table</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##    Depth     Mean   Deviation        DevSq</span>
<span class=gp>#</span><span class=c1>## 1   61.9 61.77667  0.12333333 1.521111e-02</span>
<span class=gp>#</span><span class=c1>## 2   59.3 61.77667 -2.47666667 6.133878e+00</span>
<span class=gp>#</span><span class=c1>## 3   59.6 61.77667 -2.17666667 4.737878e+00</span>
<span class=gp>#</span><span class=c1>## 4   59.5 61.77667 -2.27666667 5.183211e+00</span>
<span class=gp>#</span><span class=c1>## 5   61.6 61.77667 -0.17666667 3.121111e-02</span>
<span class=gp>#</span><span class=c1>## 6   62.2 61.77667  0.42333333 1.792111e-01</span>
<span class=gp>#</span><span class=c1>## 7   61.6 61.77667 -0.17666667 3.121111e-02</span>
<span class=gp>#</span><span class=c1>## 8   62.5 61.77667  0.72333333 5.232111e-01</span>
<span class=gp>#</span><span class=c1>## 9   63.4 61.77667  1.62333333 2.635211e+00</span>
<span class=gp>#</span><span class=c1>## 10  63.4 61.77667  1.62333333 2.635211e+00</span>
<span class=gp>#</span><span class=c1>## 11  60.6 61.77667 -1.17666667 1.384544e+00</span>
<span class=gp>#</span><span class=c1>## 12  63.9 61.77667  2.12333333 4.508544e+00</span>
<span class=gp>#</span><span class=c1>## 13  61.2 61.77667 -0.57666667 3.325444e-01</span>
<span class=gp>#</span><span class=c1>## 14  62.5 61.77667  0.72333333 5.232111e-01</span>
<span class=gp>#</span><span class=c1>## 15  62.2 61.77667  0.42333333 1.792111e-01</span>
<span class=gp>#</span><span class=c1>## 16  59.8 61.77667 -1.97666667 3.907211e+00</span>
<span class=gp>#</span><span class=c1>## 17  61.8 61.77667  0.02333333 5.444444e-04</span>
<span class=gp>#</span><span class=c1>## 18  58.2 61.77667 -3.57666667 1.279254e+01</span>
<span class=gp>#</span><span class=c1>## 19  63.7 61.77667  1.92333333 3.699211e+00</span>
<span class=gp>#</span><span class=c1>## 20  62.7 61.77667  0.92333333 8.525444e-01</span>
<span class=gp>#</span><span class=c1>## 21  61.2 61.77667 -0.57666667 3.325444e-01</span>
<span class=gp>#</span><span class=c1>## 22  63.8 61.77667  2.02333333 4.093878e+00</span>
<span class=gp>#</span><span class=c1>## 23  62.5 61.77667  0.72333333 5.232111e-01</span>
<span class=gp>#</span><span class=c1>## 24  61.0 61.77667 -0.77666667 6.032111e-01</span>
<span class=gp>#</span><span class=c1>## 25  62.8 61.77667  1.02333333 1.047211e+00</span>
<span class=gp>#</span><span class=c1>## 26  61.0 61.77667 -0.77666667 6.032111e-01</span>
<span class=gp>#</span><span class=c1>## 27  62.3 61.77667  0.52333333 2.738778e-01</span>
<span class=gp>#</span><span class=c1>## 28  62.6 61.77667  0.82333333 6.778778e-01</span>
<span class=gp>#</span><span class=c1>## 29  61.2 61.77667 -0.57666667 3.325444e-01</span>
<span class=gp>#</span><span class=c1>## 30  63.3 61.77667  1.52333333 2.320544e+00</span>
</code></pre></td></tr></table>
</div>
</div><p>Now sum the squared deviations, $$ \sum_{i = 1}^{n} (x_i − bar{x})^2 $$</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>sumdev2</span> <span class=o>&lt;-</span> <span class=n>sd.table</span><span class=o>$</span><span class=n>DevSq</span> <span class=o>%&gt;%</span> <span class=nf>sum</span><span class=p>()</span>
<span class=n>sumdev2</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 61.09367</span>
</code></pre></td></tr></table>
</div>
</div><p>Now divide by n−1 (Bessel’s correction):</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>variance</span> <span class=o>&lt;-</span> <span class=n>sumdev2</span><span class=o>/</span><span class=p>(</span><span class=nf>length</span><span class=p>(</span><span class=n>Diamonds_sample</span><span class=o>$</span><span class=n>depth</span><span class=p>)</span><span class=m>-1</span><span class=p>)</span>
<span class=n>variance</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 2.106678</span>
</code></pre></td></tr></table>
</div>
</div><p>Correct! Square root the variance, $$\sqrt{s^2} $$ to get the sample standard deviation, s:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>variance</span> <span class=o>%&gt;%</span> <span class=nf>sqrt</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 1.45144</span>
</code></pre></td></tr></table>
</div>
</div><p>Correct again! The variance for the depth data was 1.45. As the variance represents an averaged squared value, it is unit-less. The standard deviation corrects this by taking the square root of the variance in order to convert it back to its original scale. The standard deviation uses all the values in a dataset and is therefore a much more useful indicator of variability. The standard deviation represents the average deviation from the mean. For example, we could state that diamond depth percentages variaed by 1.45% on average. In other words, very littl variation. The mean of the depth data was calculated to be 61.78. The following info-graphic depicts the mean, range and standard deviation for diamond depth data according to a dot plot.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615278855/MATH1324/ModelTwo/StandardDeviation_wzd4as.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615278855/MATH1324/ModelTwo/StandardDeviation_wzd4as.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615278855/MATH1324/ModelTwo/StandardDeviation_wzd4as.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615278855/MATH1324/ModelTwo/StandardDeviation_wzd4as.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615278855/MATH1324/ModelTwo/StandardDeviation_wzd4as.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615278855/MATH1324/ModelTwo/StandardDeviation_wzd4as.png></p>
<p>Now let’s calculate the mean and standard deviation for price in the complete Diamond dataset. We will short cut this using the <strong>summary()</strong> function.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span><span class=o>$</span><span class=n>price</span> <span class=o>%&gt;%</span> <span class=nf>summary</span><span class=p>()</span> 
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span>
<span class=gp>#</span><span class=c1>##     326     950    2401    3933    5324   18823</span>
</code></pre></td></tr></table>
</div>
</div><p>This is missing the standard deviation. We can use the summarise() function from the dplyr package to produce a similar summary. There are many other packages that make this easier, however, I believe learning to use dplyr to build these tables gives you far more flexibility and prevents the need to install another package. I’ll prove this shortly. Let’s have a look at a basic summarised table.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span> <span class=o>%&gt;%</span> <span class=nf>summarise</span><span class=p>(</span><span class=n>Mean</span> <span class=o>=</span> <span class=nf>mean</span><span class=p>(</span><span class=n>price</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                             <span class=n>SD</span> <span class=o>=</span> <span class=nf>sd</span><span class=p>(</span><span class=n>price</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>))</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##     Mean      SD</span>
<span class=gp>#</span><span class=c1>## 1 3932.8 3989.44</span>
</code></pre></td></tr></table>
</div>
</div><p>Note how we include <strong>na.rm = TRUE</strong> to remove missing values from the computations.</p>
<p>We quickly find the mean price equals 3932.8 and the standard deviation equals 3989.4. The very high standard deviation, which is higher than the mean itself, suggests great variability in diamond prices. We can plot the mean on the histogram to get a better sense of the value:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span><span class=o>$</span><span class=n>price</span> <span class=o>%&gt;%</span> <span class=nf>hist</span><span class=p>(,</span><span class=n>col</span><span class=o>=</span><span class=s>&#34;grey&#34;</span><span class=p>,</span><span class=n>xlim</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=m>20000</span><span class=p>),</span><span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Diamond Price&#34;</span><span class=p>,</span>
                        <span class=n>main</span><span class=o>=</span><span class=s>&#34;Histogram of Diamond Prices&#34;</span><span class=p>)</span>
<span class=n>Diamonds</span><span class=o>$</span><span class=n>price</span> <span class=o>%&gt;%</span> <span class=nf>mean</span><span class=p>()</span> <span class=o>%&gt;%</span> <span class=nf>abline</span><span class=p>(</span><span class=n>v</span><span class=o>=</span><span class=n>.,col</span><span class=o>=</span><span class=s>&#39;red&#39;</span><span class=p>,</span><span class=n>lw</span><span class=o>=</span><span class=m>2</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615279193/MATH1324/ModelTwo/HistogramOfDiamondPricesWithMean_mj5gbe.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615279193/MATH1324/ModelTwo/HistogramOfDiamondPricesWithMean_mj5gbe.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615279193/MATH1324/ModelTwo/HistogramOfDiamondPricesWithMean_mj5gbe.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615279193/MATH1324/ModelTwo/HistogramOfDiamondPricesWithMean_mj5gbe.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615279193/MATH1324/ModelTwo/HistogramOfDiamondPricesWithMean_mj5gbe.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615279193/MATH1324/ModelTwo/HistogramOfDiamondPricesWithMean_mj5gbe.png></p>
<p>I’ve added a red line showing the mean. As the mean is influenced by all values in the dataset, the histogram above suggests that the mean is being pulled towards higher values. This is what we refer to as positive skew. The mean might not be the best indicator of central tendency for such a highly skewed distribution. Fortunately, when we performed the <strong>summary()</strong> function, we also obtained some very useful values called quartiles.</p>
<h5 id=quartiles-and-the-median>Quartiles and the Median</h5>
<p>Quartiles are values that break a distribution into four parts, so that 25% of the data values fall within each interval. We refer to these values as Q1, Q2 and Q3. Q2 is also referred to as the median. Data can also be broken into percentages. So, we could call Q1 the 25th percentile, Q2 the 50% percentile and Q3 as the 75th percentile.</p>
<p>The median, Q2 or the 50% percentile, is a measure of central tendency. The median splits an ordered dataset in half, with 50% of values above and below the median.</p>
<p>The calculation of the median depends on whether there are an even or odd number of data points. Consider the two following datasets. Scenario 1 has 7 measurements and scenario 2 has 6 measurements:</p>
<h2 id=scenario-12-4-9-8-6-5-3>Scenario 1 2, 4, 9, 8, 6, 5, 3</h2>
<h2 id=ordered2-3-4-5-6-8-9>Ordered 2, 3, 4, 5, 6, 8, 9</h2>
<h2 id=location-of-median-n12--712--4th->Location of Median $$ (n+1)/2 = (7+1)/2 = 4th $$</h2>
<p>Therefore, the median is the 4th ordered value, Median =5. In R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>x</span> <span class=o>&lt;-</span> <span class=nf>c</span><span class=p>(</span><span class=m>2</span><span class=p>,</span> <span class=m>3</span><span class=p>,</span> <span class=m>4</span><span class=p>,</span> <span class=m>5</span><span class=p>,</span> <span class=m>6</span><span class=p>,</span> <span class=m>8</span><span class=p>,</span> <span class=m>9</span><span class=p>)</span>
<span class=n>x</span> <span class=o>%&gt;%</span> <span class=nf>summary</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span>
<span class=gp>#</span><span class=c1>##   2.000   3.500   5.000   5.286   7.000   9.000</span>
</code></pre></td></tr></table>
</div>
</div><h2 id=scenario-22-4-9-8-6-5>Scenario 2 2, 4, 9, 8, 6, 5</h2>
<h2 id=ordered2-4-5-6-8-9>Ordered 2, 4, 5, 6, 8, 9</h2>
<p>Location of Median Average of the <strong>(n/2)</strong> and $$(n/2) + 1 $$ observations, so the average of the 3rd and 4th</p>
<p>The median is the average of the 3rd and 4th ordered observation so, $$ Median = (5 + 6) /2 = 5.5 $$. In R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>y</span> <span class=o>&lt;-</span> <span class=nf>c</span><span class=p>(</span><span class=m>2</span><span class=p>,</span> <span class=m>4</span><span class=p>,</span> <span class=m>9</span><span class=p>,</span> <span class=m>8</span><span class=p>,</span> <span class=m>6</span><span class=p>,</span> <span class=m>5</span><span class=p>)</span>
<span class=n>y</span> <span class=o>%&gt;%</span> <span class=nf>summary</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span>
<span class=gp>#</span><span class=c1>##   2.000   4.250   5.500   5.667   7.500   9.000</span>
</code></pre></td></tr></table>
</div>
</div><p>Q1 and Q3 are calculated in a similar fashion after the dataset is split at the median, top and bottom 50%. Q1 is the median of the bottom 50% (i.e. 25th percentile) and Q3 is median of the top 50% (i.e. 75th percentile).</p>
<ul>
<li>Q1 and Q3 when n = odd (take median value)</li>
</ul>
<p>Q1 = Median of bottom 50%: For example, Median of 2, 3, 4, 5 = average of 2nd and 3rd value = (3+4)/2 = 3.5</p>
<p>Q3 = Median of top 50%: For example, Median of 5, 6, 8, 9 = average of 2nd and 3rd value = (6+8)/2 = 7</p>
<p>Note how the median is included in both halves.</p>
<ul>
<li>Q1 and Q3 when n = even</li>
</ul>
<p>Q1 = Median of bottom 50%: For example, Median of 2, 4, 5 = 2nd value = 4</p>
<p>Q3 = Median of top 50%: For example, Median of 6, 8, 9 = 2nd value = 8.</p>
<p>Note how the median is not included because the median is not an actual data point.</p>
<p>Note also that R does not use this method, which I have included as a simple instructional example. R has 9 different methods to calculate quartiles. We will stick to the default method produced by R. You just need to know conceptually what it represents.</p>
<p><strong>NOTE One:</strong></p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span><span class=o>$</span><span class=n>carat</span> <span class=o>%&gt;%</span> <span class=nf>quantile</span><span class=p>()</span> <span class=c1>#Quartiles</span>
</code></pre></td></tr></table>
</div>
</div><p><strong>NOTE Two:</strong></p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span><span class=o>$</span><span class=n>carat</span> <span class=o>%&gt;%</span> <span class=nf>median</span><span class=p>()</span> <span class=c1># Median</span>
</code></pre></td></tr></table>
</div>
</div><h5 id=box-plots>Box Plots</h5>
<p>Box Plots are used to depict the quartiles of distribution. The following info-graphic puts all the concepts of quartiles, medians and percentiles together. Let’s first dissect a box plot of diamond depth from the small sample:</p>
<p>Here are the quartiles:</p>
<p>Diamonds_sample$depth %>% summary()</p>
<h3 id=min-1st-qu--median----mean-3rd-qu----max>Min. 1st Qu. Median Mean 3rd Qu. Max.</h3>
<h3 id=5820---6105---6205---6178---6267---6390>58.20 61.05 62.05 61.78 62.67 63.90</h3>
<p>Now let’s discuss the anatomy of the basic box plot below.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615283364/MATH1324/ModelTwo/BoxPlot_fw5x1f.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615283364/MATH1324/ModelTwo/BoxPlot_fw5x1f.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615283364/MATH1324/ModelTwo/BoxPlot_fw5x1f.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615283364/MATH1324/ModelTwo/BoxPlot_fw5x1f.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615283364/MATH1324/ModelTwo/BoxPlot_fw5x1f.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615283364/MATH1324/ModelTwo/BoxPlot_fw5x1f.png></p>
<p>The <strong>interquartile range (IQR)</strong> is the middle 50% of data and is depicted as the “box” in the box plot. The IQR is also a measure of variation.</p>
<p>$$ IQR = Q3 − Q1 $$</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span><span class=o>$</span><span class=n>carat</span> <span class=o>%&gt;%</span> <span class=nf>IQR</span><span class=p>()</span> <span class=c1>#Interquartile range</span>
</code></pre></td></tr></table>
</div>
</div><p>Box plots also include suspected <strong>outliers</strong>, depicted using an “o” or a similar symbol. Outliers are values that fall beyond the <strong>outlier fences</strong>. The outlier fences are defined as the following:</p>
<p>$$ Lower outlier &lt; Q1 − 1.5 ∗ IQR $$
$$ Upper outlier > Q3 + 1.5 ∗ IQR $$</p>
<p>Using the depth data summary, we find:</p>
<p>$$ IQR = 62.675 − 61.05 = 1.625 $$
$$ Lower outlier &lt; 61.05 − (1.5 ∗ 1.625) = 58.6125 $$
$$ Upper outlier > 62.675 + (1.5 ∗ 1.625) = 65.1125 $$</p>
<p>Outliers are unusual cases that should be investigated by the researcher. Don’t automatically remove outliers until you have a good reason to do so. For example, an outlier might be a data entry error or a measurement that should have been excluded from the investigation. Removing outliers because they don’t look “nice” is not appropriate. When you remove outliers for any reason, this should be made clear when you report your results.</p>
<p>Now let’s put histograms, box plots, and measures of central tendency together:</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615285599/MATH1324/ModelTwo/HistogramWithBoxPlot_inexyr.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615285599/MATH1324/ModelTwo/HistogramWithBoxPlot_inexyr.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615285599/MATH1324/ModelTwo/HistogramWithBoxPlot_inexyr.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615285599/MATH1324/ModelTwo/HistogramWithBoxPlot_inexyr.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615285599/MATH1324/ModelTwo/HistogramWithBoxPlot_inexyr.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615285599/MATH1324/ModelTwo/HistogramWithBoxPlot_inexyr.png></p>
<p>The mean and median will be the same when the data have a symmetrical distribution. The median is said to be more robust (less sensitive to unusual cases) than the mean. Therefore, the median is often preferred when a variable’s distribution is skewed or has many outliers present. This is the case for the highly skewed diamond price data. <strong>The median appears to give a better account of the central tendency of the data, while the mean seems unduly influenced by the long tail</strong>. The following info-graphic summarises the effect of skewness on the mean and median. The mean is the <strong>solid red line</strong>, and the median is the <strong>dashed red line</strong>. The tail of a skewed distribution always draws the mean towards it, because the mean takes all values into account.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615309561/MATH1324/ModelTwo/TheEffectOfSkewnessOnTheMeanAndMedian_fss672.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615309561/MATH1324/ModelTwo/TheEffectOfSkewnessOnTheMeanAndMedian_fss672.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615309561/MATH1324/ModelTwo/TheEffectOfSkewnessOnTheMeanAndMedian_fss672.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615309561/MATH1324/ModelTwo/TheEffectOfSkewnessOnTheMeanAndMedian_fss672.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615309561/MATH1324/ModelTwo/TheEffectOfSkewnessOnTheMeanAndMedian_fss672.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615309561/MATH1324/ModelTwo/TheEffectOfSkewnessOnTheMeanAndMedian_fss672.png></p>
<p>Note that these effects are generally true for large datasets. In small datasets, skewness is often poorly estimated, so the relationship among the mean, median and skewness can behave in unusual ways.</p>
<h5 id=comparing-groups>Comparing Groups</h5>
<p>Descriptive statistics and visualisations are often used to compare groups. The following examples show how the basic descriptive R functions and plots can be quickly extended to assist with comparing the distributions of a quantitative variable across qualitative groupings. The example will consider comparing diamond price distributions across colour. First, lets get a descriptive statistics table using the <strong>summarise()</strong> function from the <strong>dplyr</strong> package.</p>
<p>The table will include min, Q1, median, Q3, max, mean, standard deviation, n and missing value count. I’ve included quite a few descriptive statistics so you can get a sense of how to customise the table. Essentially, the table can incorporate any descriptive functions in R provided the function results in a single value. Take note how we have to include the option <strong>na.rm = TRUE</strong> to most of these functions. If we didn’t, and missing values were present, the function would fail.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span> <span class=o>%&gt;%</span> <span class=nf>group_by</span><span class=p>(</span><span class=n>cut</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>summarise</span><span class=p>(</span><span class=n>Min</span> <span class=o>=</span> <span class=nf>min</span><span class=p>(</span><span class=n>price</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Q1</span> <span class=o>=</span> <span class=nf>quantile</span><span class=p>(</span><span class=n>price</span><span class=p>,</span><span class=n>probs</span> <span class=o>=</span> <span class=m>.25</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Median</span> <span class=o>=</span> <span class=nf>median</span><span class=p>(</span><span class=n>price</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Q3</span> <span class=o>=</span> <span class=nf>quantile</span><span class=p>(</span><span class=n>price</span><span class=p>,</span><span class=n>probs</span> <span class=o>=</span> <span class=m>.75</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Max</span> <span class=o>=</span> <span class=nf>max</span><span class=p>(</span><span class=n>price</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Mean</span> <span class=o>=</span> <span class=nf>mean</span><span class=p>(</span><span class=n>price</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>SD</span> <span class=o>=</span> <span class=nf>sd</span><span class=p>(</span><span class=n>price</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>n</span> <span class=o>=</span> <span class=nf>n</span><span class=p>(),</span>
                                         <span class=n>Missing</span> <span class=o>=</span> <span class=nf>sum</span><span class=p>(</span><span class=nf>is.na</span><span class=p>(</span><span class=n>price</span><span class=p>)))</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## # A tibble: 5 x 10</span>
<span class=gp>#</span><span class=c1>##   cut         Min    Q1 Median    Q3   Max  Mean    SD     n Missing</span>
<span class=gp>#</span><span class=c1>##   &lt;ord&gt;     &lt;int&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;int&gt;</span>
<span class=gp>#</span><span class=c1>## 1 Fair        337 2050.  3282  5206. 18574 4359. 3560.  1610       0</span>
<span class=gp>#</span><span class=c1>## 2 Good        327 1145   3050. 5028  18788 3929. 3682.  4906       0</span>
<span class=gp>#</span><span class=c1>## 3 Very Good   336  912   2648  5373. 18818 3982. 3936. 12082       0</span>
<span class=gp>#</span><span class=c1>## 4 Premium     326 1046   3185  6296  18823 4584. 4349. 13791       0</span>
<span class=gp>#</span><span class=c1>## 5 Ideal       326  878   1810  4678. 18806 3458. 3808. 21551       0</span>
</code></pre></td></tr></table>
</div>
</div><p>Next, let’s create a side-by-side box plot.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span> <span class=o>%&gt;%</span> <span class=nf>boxplot</span><span class=p>(</span><span class=n>price</span> <span class=o>~</span> <span class=n>cut</span><span class=p>,</span><span class=n>data</span> <span class=o>=</span> <span class=n>.,</span> <span class=n>main</span><span class=o>=</span><span class=s>&#34;Box Plot of Diamond Price by Cut&#34;</span><span class=p>,</span> 
                     <span class=n>ylab</span><span class=o>=</span><span class=s>&#34;Cut&#34;</span><span class=p>,</span> <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Price&#34;</span><span class=p>,</span><span class=n>horizontal</span><span class=o>=</span><span class=kc>TRUE</span><span class=p>,</span> <span class=n>col</span> <span class=o>=</span> <span class=s>&#34;skyblue&#34;</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310007/MATH1324/ModelTwo/ComparingGroups_ydb8ia.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310007/MATH1324/ModelTwo/ComparingGroups_ydb8ia.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310007/MATH1324/ModelTwo/ComparingGroups_ydb8ia.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310007/MATH1324/ModelTwo/ComparingGroups_ydb8ia.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310007/MATH1324/ModelTwo/ComparingGroups_ydb8ia.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310007/MATH1324/ModelTwo/ComparingGroups_ydb8ia.png></p>
<p>Using this plot, confirm the following features:</p>
<ul>
<li>Ideal has the smallest median price</li>
<li>Premium has the highest IQR</li>
<li>All price distributions are positively skewed</li>
<li>All price distributions have many suspected outliers</li>
<li>Fair has the highest Q1</li>
<li>Premium has the highest Q3</li>
</ul>
<h5 id=scatter-plots>Scatter Plots</h5>
<p>Scatter plots are used to visualise the relationship between two quantitative variables. One variable is plotted on the x axis and one variable on the y. The bivariate, or paired data, are indicated on the plot using a point. Let’s look at some examples. Let’s first consider the relationship between diamond price and carat. Here’s an excerpt from the data showing 10 sets of bivariate data, x,y.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##    ID Carat Price</span>
<span class=gp>#</span><span class=c1>## 1   1  0.23   326</span>
<span class=gp>#</span><span class=c1>## 2   2  0.21   326</span>
<span class=gp>#</span><span class=c1>## 3   3  0.23   327</span>
<span class=gp>#</span><span class=c1>## 4   4  0.29   334</span>
<span class=gp>#</span><span class=c1>## 5   5  0.31   335</span>
<span class=gp>#</span><span class=c1>## 6   6  0.24   336</span>
<span class=gp>#</span><span class=c1>## 7   7  0.24   336</span>
<span class=gp>#</span><span class=c1>## 8   8  0.26   337</span>
<span class=gp>#</span><span class=c1>## 9   9  0.22   337</span>
<span class=gp>#</span><span class=c1>## 10 10  0.23   338</span>
</code></pre></td></tr></table>
</div>
</div><p>A point is plotted at the intersection between the x and y value for each data point. For example, for ID = 1, a point is plotted where carat = 0.23 intersects with a price value of 326. This is repeated for all 54,000 data points. Fortunately, you don’t have to do this by hand. Using R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span> <span class=o>%&gt;%</span> <span class=nf>plot</span><span class=p>(</span><span class=n>price</span> <span class=o>~</span> <span class=n>carat</span><span class=p>,</span> <span class=n>data</span> <span class=o>=</span> <span class=n>.,ylab</span><span class=o>=</span><span class=s>&#34;Price&#34;</span><span class=p>,</span> <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Carat&#34;</span><span class=p>,</span>
                  <span class=n>col</span><span class=o>=</span><span class=s>&#34;blue&#34;</span><span class=p>,</span><span class=n>main</span><span class=o>=</span><span class=s>&#34;Price by Carat&#34;</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310410/MATH1324/ModelTwo/ScatterPlotsByCarat_tst3ld.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310410/MATH1324/ModelTwo/ScatterPlotsByCarat_tst3ld.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310410/MATH1324/ModelTwo/ScatterPlotsByCarat_tst3ld.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310410/MATH1324/ModelTwo/ScatterPlotsByCarat_tst3ld.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310410/MATH1324/ModelTwo/ScatterPlotsByCarat_tst3ld.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310410/MATH1324/ModelTwo/ScatterPlotsByCarat_tst3ld.png></p>
<p>The scatter plot for price by carat suggests that as carat increases, price also tends to increase. However, there is still lots of variability that other diamond characteristics may help explain. Weight is not everything. Let’s have a look at a few more examples:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span> <span class=o>%&gt;%</span> <span class=nf>plot</span><span class=p>(</span><span class=n>price</span> <span class=o>~</span> <span class=n>x</span><span class=p>,</span> <span class=n>data</span> <span class=o>=</span> <span class=n>.,</span> <span class=n>ylab</span><span class=o>=</span><span class=s>&#34;Price&#34;</span><span class=p>,</span> <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Length (mm)&#34;</span><span class=p>,</span>
                  <span class=n>col</span><span class=o>=</span><span class=s>&#34;blue&#34;</span><span class=p>,</span><span class=n>main</span><span class=o>=</span><span class=s>&#34;Price by Length (mm)&#34;</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310522/MATH1324/ModelTwo/ScatterPlotsLength_yar4kr.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310522/MATH1324/ModelTwo/ScatterPlotsLength_yar4kr.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310522/MATH1324/ModelTwo/ScatterPlotsLength_yar4kr.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310522/MATH1324/ModelTwo/ScatterPlotsLength_yar4kr.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310522/MATH1324/ModelTwo/ScatterPlotsLength_yar4kr.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310522/MATH1324/ModelTwo/ScatterPlotsLength_yar4kr.png></p>
<p>Notice the 0 values. Scatter plots are a great way to explore your data to find possible irregularities.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Diamonds</span> <span class=o>%&gt;%</span> <span class=nf>plot</span><span class=p>(</span><span class=n>price</span> <span class=o>~</span> <span class=n>y</span><span class=p>,</span> <span class=n>data</span> <span class=o>=</span> <span class=n>.,</span> <span class=n>ylab</span><span class=o>=</span><span class=s>&#34;Price&#34;</span><span class=p>,</span> <span class=n>xlab</span><span class=o>=</span><span class=s>&#34;Width (mm)&#34;</span><span class=p>,</span>
                  <span class=n>col</span><span class=o>=</span><span class=s>&#34;blue&#34;</span><span class=p>,</span><span class=n>main</span><span class=o>=</span><span class=s>&#34;Price by Width (mm)&#34;</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310632/MATH1324/ModelTwo/ScatterPlotsWidth_sewyvg.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310632/MATH1324/ModelTwo/ScatterPlotsWidth_sewyvg.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310632/MATH1324/ModelTwo/ScatterPlotsWidth_sewyvg.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310632/MATH1324/ModelTwo/ScatterPlotsWidth_sewyvg.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310632/MATH1324/ModelTwo/ScatterPlotsWidth_sewyvg.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615310632/MATH1324/ModelTwo/ScatterPlotsWidth_sewyvg.png></p>
<p>Once again, there appears to be some outliers that need following up.</p>
<h3 id=module-2---exercises>Module 2 - Exercises</h3>
<p>Data from:
Download the Cars.csv dataset from <a href=https://raw.githubusercontent.com/yanboyang713/RMIT-Data-Repository/main/Cars.csv target=_blank rel="noopener noreferrer">here</a>.</p>
<p>This dataset contains data from over 400 vehicles from 2003.</p>
<p>The following variables, along with their coding, are included:</p>
<ul>
<li><strong>Vehicle_name</strong>: Model Name</li>
<li><strong>Sports</strong>: Sports car? (1 = ‘yes’, 0 =‘no’)</li>
<li><strong>Sport_utility</strong>: Sports utility vehicle? (1 = ‘yes’, 0 =‘no’)</li>
<li><strong>Wagon</strong>: Wagon? (1 = ‘yes’, 0 =‘no’)</li>
<li><strong>Minivan</strong>: Minivan? (1 = ‘yes’, 0 =‘no’)</li>
<li><strong>Pickup</strong>: Pickup? (1 = ‘yes’, 0 =‘no’)</li>
<li><strong>All_wheel_drive</strong>: All wheel drive? (1 = ‘yes’, 0 =‘no’)</li>
<li><strong>Rear_wheel_drive</strong>: Rear wheel drive? (1 = ‘yes’, 0 =‘no’)</li>
<li><strong>Retail_price</strong>: The recommended retail price ($)</li>
<li><strong>Dealer_cost</strong>: The cost price for a car dealer ($)</li>
<li><strong>Engine_size</strong>: Engine size in litres</li>
<li><strong>Cylinders</strong>: Number of cylinders (-1 = Rotary engine)</li>
<li><strong>Kilowatts</strong>: Power of the engine in kilowatts.</li>
<li><strong>Economy_city</strong>: Kilometres per litre for city driving</li>
<li><strong>Economy_highway</strong>: Kilometres per litre for highway driving</li>
<li><strong>Weight</strong>: Curb weight of car (kg)</li>
<li><strong>Wheel_base</strong>: Wheel base of car (cm)</li>
<li><strong>Length</strong>: Length of car (cm)</li>
<li><strong>Width</strong>: Width of car (cm)</li>
</ul>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>library(dplyr)
library(ggplot2)
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback># the url for the online csv file
url &lt;- &#34;https://raw.githubusercontent.com/yanboyang713/RMIT-Data-Repository/main/Cars.csv&#34;
Cars &lt;- read.csv(url)

# When you doing plot. No order was specified when you created the factor (by default), so, when R tried to plot it, it just placed the levels in alphabetical order. If you using **ordered=TRUE**, there will create a order to ratings, and your plots should reflect that!

Cars$Sports&lt;- Cars$Sports %&gt;% factor(levels=c(0,1), labels=c(&#39;No&#39;,&#39;Yes&#39;), ordered=TRUE)

Cars$Sport_utility&lt;- Cars$Sport_utility %&gt;% factor(levels=c(0,1), labels=c(&#39;No&#39;,&#39;Yes&#39;), ordered=TRUE)

Cars$Wagon&lt;-Cars$Wagon %&gt;% factor(levels=c(0,1), labels=c(&#39;No&#39;,&#39;Yes&#39;), ordered=TRUE)

Cars$Minivan&lt;- Cars$Minivan %&gt;% factor(levels=c(0,1), labels=c(&#39;No&#39;,&#39;Yes&#39;), ordered=TRUE)

Cars$Pickup&lt;-Cars$Pickup %&gt;% factor(levels=c(0,1), labels=c(&#39;No&#39;,&#39;Yes&#39;), ordered=TRUE)

Cars$All_wheel_drive &lt;- Cars$All_wheel_drive %&gt;% factor(levels=c(0,1), labels=c(&#39;No&#39;,&#39;Yes&#39;), ordered=TRUE)

Cars$Rear_wheel_drive &lt;- Cars$Rear_wheel_drive %&gt;% factor(levels=c(0,1), labels=c(&#39;No&#39;,&#39;Yes&#39;), ordered=TRUE)

</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>str(Cars)
</code></pre></td></tr></table>
</div>
</div><ol>
<li>Exercise 1</li>
</ol>
<p>What is the sample size?</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>length(Cars$Vehicle_name)
</code></pre></td></tr></table>
</div>
</div><ol start=2>
<li>Exercise 2
Obtain a frequency distribution for the cylinder variable. How many cars had 4 cylinders?</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>Cars$Cylinders %&gt;% table()
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>Cars %&gt;% filter(Cylinders == 4) %&gt;% count()
</code></pre></td></tr></table>
</div>
</div><ol start=3>
<li>Exercise 3</li>
</ol>
<p>What percentage of cars had 6 cylinders? (Round response to two decimal places)</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>library(magrittr)

Cars$Cylinders %&gt;% table() %&gt;% prop.table() %&gt;% multiply_by(100) %&gt;% round (2)

data &lt;- Cars$Cylinders %&gt;% table() %&gt;% prop.table() %&gt;% multiply_by(100) %&gt;% round (2) %&gt;% paste0(., &#34;%&#34;)


CylindersType &lt;- Cars$Cylinders %&gt;% table() %&gt;% prop.table() %&gt;% multiply_by(100) %&gt;% round (2) %&gt;% rownames ()

df &lt;- data.frame(CylindersType, data)

df
</code></pre></td></tr></table>
</div>
</div><ol start=4>
<li>Exercise 4
What proportion of cars had all wheel drive? (Round response to two decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>allWheelDrive &lt;- table(Cars$All_wheel_drive) %&gt;% prop.table() %&gt;% round (2)
allWheelDrive
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>allWheelDrive[&#34;Yes&#34;] %&gt;% multiply_by(100) %&gt;% paste0(., &#34;%&#34;)
</code></pre></td></tr></table>
</div>
</div><ol start=5>
<li>Exercise 5</li>
</ol>
<p>How many sports cars were in the sample?</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>table(Cars$Sports)[&#34;Yes&#34;]
</code></pre></td></tr></table>
</div>
</div><ol start=6>
<li>Exercise 6
Create a bar chart showing the distribution of the proportion of different total car cylinders in the sample. Save the bar chart as an image and upload it to this exercise.</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>table(Cars$Cylinders) %&gt;% prop.table() %&gt;%
barplot(main=&#34;Distribution of Car Cylinders&#34;,xlab = &#34;Cylinders&#34;,
ylab=&#34;Proportion&#34;,col=&#39;grey&#39;)

Cars$Cylinders %&gt;% table() %&gt;% prop.table() %&gt;% multiply_by(100) %&gt;% barplot(main = &#34;Car Cylinders - Percentage&#34;,ylab=&#34;Percent&#34;, ylim=c(0,50))
</code></pre></td></tr></table>
</div>
</div><ol start=7>
<li>Exercise 7
Create a contingency table showing the column proportions of cylinders by sports car. What proportion of sports cars have six or more cylinders? (Round answer to two decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>tbl &lt;- table(Cars$Cylinders,Cars$Sports) %&gt;% prop.table(margin = 2)
tbl
class(tbl)

tbl[5:8,2] %&gt;% sum() %&gt;% round(2)
</code></pre></td></tr></table>
</div>
</div><ol start=8>
<li>Exercise 8
What proportion of non-sports cars have six or more cylinders? (Round answer to two decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>tbl[5:8, 1] %&gt;% sum() %&gt;% round(2)
</code></pre></td></tr></table>
</div>
</div><ol start=9>
<li>Exercise 9
Are sports cars more likely to have 6 or more cylinders than non-sports cars?</li>
</ol>
<p><strong>Answer</strong>: Yes! The reason is 0.73 > 0.65</p>
<ol start=10>
<li>Exercise 10</li>
</ol>
<p>Create a clustered bar chart comparing the proportion of sports and non-sports car cylinder numbers. Save the plot and upload it to this exercise.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>table(Cars$Cylinders, Cars$Sports, dnn = c(&#34;Cylinders&#34;,&#34;Sports&#34;)) %&gt;% prop.table(margin = 2) %&gt;%
barplot(main = &#34;Distribution of Cylinders by Sports vs Non-sports Car&#34;,
ylab=&#34;Proportion within Car Type&#34;,
ylim=c(0,.8),legend=rownames(.),beside=TRUE,
args.legend=c(x = &#34;top&#34;,horiz=TRUE,title=&#34;Cyclinders&#34;),
xlab=&#34;Sports Car&#34;)
</code></pre></td></tr></table>
</div>
</div><ol start=11>
<li>Exercise 11</li>
</ol>
<p>What is the modal cylinder number for non-sports cars?</p>
<p>A: 6</p>
<ol start=12>
<li>
<p>Exercise 12
What is the modal cylinder number for sports cars?
A: 6</p>
</li>
<li>
<p>Exercise 13
Produce a dot plot of car kilowatts. Save the plot and upload to this question.</p>
</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>qplot(data = Cars, x = Kilowatts, geom = &#34;dotplot&#34;, dotsize = .35, binwidth = 10)
</code></pre></td></tr></table>
</div>
</div><ol start=14>
<li>Exercise 14
How would you describe the shape of the kilowatts variable depicted in the dot plot?</li>
</ol>
<ul>
<li><i class="far fa-square fa-fw"></i> Symmetric</li>
<li><i class="far fa-check-square fa-fw"></i> Skewed to the right</li>
<li><i class="far fa-square fa-fw"></i> Skewed to the left</li>
<li><i class="far fa-square fa-fw"></i> Multi-modal</li>
</ul>
<ol start=15>
<li>Exercise 15</li>
</ol>
<p>Produce a histogram of city fuel economy with 18 breaks. Save the plot and upload it to this exercise</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>hist(Cars$Economy_city,col=&#34;grey&#34;,xlab=&#34;Kilowatts&#34;,main=&#34;Histogram of City Fuel Economy (km/L)&#34;, breaks=18)
</code></pre></td></tr></table>
</div>
</div><ol start=16>
<li>Exercise 16
How would you describe the distribution shape of the city fuel economy depicted in the histogram?</li>
</ol>
<ul>
<li><i class="far fa-square fa-fw"></i> Skewed to the left</li>
<li><i class="far fa-square fa-fw"></i> Multi-modal</li>
<li><i class="far fa-square fa-fw"></i> Symmetric</li>
<li><i class="far fa-check-square fa-fw"></i> Skewed to the right</li>
</ul>
<ol start=17>
<li>Exercise 17
For city fuel economy, would you expect the mean or median to be higher based on the shape of the distribution?</li>
</ol>
<ul>
<li>About the same</li>
<li>Median would be higher</li>
<li>Mean would be higher</li>
<li>Impossible to say
A: Mean would be higher (right skew)</li>
</ul>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>mean(Cars$Economy_city, na.rm = TRUE) &gt; median(Cars$Economy_city, na.rm = TRUE)
</code></pre></td></tr></table>
</div>
</div><ol start=18>
<li>Exercise 18</li>
</ol>
<p>Produce a histogram of car length with 18 bins. Save the plot and upload it to this exercise.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>hist(Cars$Length,col=&#34;grey&#34;,xlab=&#34;Length (cm)&#34;,main=&#34;Histogram of Car Length (cm)&#34;, breaks=18)
</code></pre></td></tr></table>
</div>
</div><ol start=19>
<li>Exercise 19
How would you describe the distribution shape of car length depicted in the histogram?</li>
</ol>
<ul>
<li>Skewed to the left</li>
<li>Multi-modal</li>
<li>Symmetric</li>
<li>Skewed to the right</li>
</ul>
<p>A: Symmetric</p>
<ol start=20>
<li>Exercise 20</li>
</ol>
<p>Create a filtered dataset called Cars_filtered, with only 4 and 6 cylinder cars selected. Produce a side-by-side box plot of 4 and 6 cylinder cars on highway fuel economy. Save the plot and upload it to this exercise.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>Cars_filt &lt;- Cars %&gt;% filter(Cylinders == 4 | Cylinders == 6)

boxplot(Economy_highway ~ Cylinders,data=Cars_filt, xlab = &#34;Cylinders&#34;, ylab=&#34;Highway Fuel Economy km/L&#34;)
</code></pre></td></tr></table>
</div>
</div><ol start=21>
<li>Exercise 21
How many suggested outliers are present for the four cylinder cars?</li>
</ol>
<p>A: 3</p>
<ol start=22>
<li>Exercise 22
Which cylinder, 4 or 6, has the higher IQR for highway fuel economy?</li>
</ol>
<p>A: 4</p>
<ol start=23>
<li>Exercise 23
What is the median highway fuel economy for 4 cylinder cars?</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>Cars %&gt;% group_by(Cylinders) %&gt;% summarise(Median = median(Economy_highway, na.rm = TRUE))
</code></pre></td></tr></table>
</div>
</div><ol start=24>
<li>Exercise 24</li>
</ol>
<p>What is the mean highway fuel economy for 4 cylinder cars? (Round answer to two decimal places)</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>Cars %&gt;% group_by(Cylinders) %&gt;% summarise(Median = median(Economy_highway, na.rm = TRUE), Mean = mean(Economy_highway, na.rm = TRUE)  %&gt;% round(2))
</code></pre></td></tr></table>
</div>
</div><ol start=25>
<li>Exercise 25
What is the standard deviation for highway fuel economy for 4 cylinder cars? (Round answer to two decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>Cars %&gt;% group_by(Cylinders) %&gt;% summarise(Median = median(Economy_highway, na.rm = TRUE), Mean = mean(Economy_highway, na.rm = TRUE) %&gt;% round(2), Std.Dv = sd(Economy_highway, na.rm = TRUE) %&gt;% round(2))
</code></pre></td></tr></table>
</div>
</div><ol start=26>
<li>Exercise 26
What is the IQR for highway fuel economy for the 6 cylinder cars?</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>Cars %&gt;% group_by(Cylinders) %&gt;% summarise(Median = median(Economy_highway, na.rm = TRUE), Mean = mean(Economy_highway, na.rm = TRUE) %&gt;% round(2), Std.Dv = sd(Economy_highway, na.rm = TRUE) %&gt;% round(2), IQR = IQR(Economy_highway,na.rm = TRUE))
</code></pre></td></tr></table>
</div>
</div><ol start=27>
<li>Exercise 27
What is the upper fence for an outlier on highway fuel economy in the 4 cylinder cars?</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>Cars %&gt;% filter(Cylinders == 4) %&gt;% select(Economy_highway) %&gt;% summary()
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>#Upper fence
55 + (1.5*(55-45))
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>#Lower fence
45 - (1.5*(55-45))
</code></pre></td></tr></table>
</div>
</div><ol start=28>
<li>Exercise 28
What is the range of highway fuel economy for 6 cylinder cars?</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>Cars %&gt;% filter(Cylinders == 6) %&gt;% select(Economy_highway) %&gt;% range()
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>#Range
52 - 27
</code></pre></td></tr></table>
</div>
</div><ol start=29>
<li>Exercise 29
Produce a scatter plot of city fuel economy by highway fuel economy. Save the plot and upload it to
this exercise.</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>plot(Economy_city ~ Economy_highway, data = Cars, ylab=&#34;City Fuel Economy km/L&#34;, xlab=&#34;Highway Fuel Economy km/L&#34;, col=&#34;blue&#34;,main=&#34;City vs. Highway Fuel Economy&#34;)
</code></pre></td></tr></table>
</div>
</div><ol start=30>
<li>Exercise 30
Which of the following statements best explains the relationship between city and highway fuel economy?</li>
</ol>
<ul>
<li><i class="far fa-check-square fa-fw"></i> As highway fuel economy increases, city fuel economy tends to increase.</li>
<li><i class="far fa-square fa-fw"></i> As highway fuel economy increases, city fuel economy tends to decrease.</li>
<li><i class="far fa-square fa-fw"></i> As there are a few outliers present, it’s difficult to determine the nature of the relationship between city and highway fuel economy.</li>
<li><i class="far fa-square fa-fw"></i> There is no relationship between city and highway fuel economy</li>
</ul>
<h2 id=model-three---probability-the-language-of-uncertainty>Model Three - Probability: The Language of Uncertainty</h2>
<h3 id=learning-objectives-1>learning objectives</h3>
<p>The learning objectives associated with this module are:</p>
<ul>
<li>List the basic principles of probability.</li>
<li>Express uncertainty using probability.</li>
<li>Define common probability terms.</li>
<li>Solve basic probability problems.</li>
<li>Solve problems involving permutations and combinations.</li>
</ul>
<h3 id=probability>Probability</h3>
<p><strong>Probability</strong> is defined as the proportion of times a random event occurs in a very large number of trials. Probability must always be a value between 0 and 1. What we define as an “event” and a “trial” depends on the context. In statistics, we estimate the probability of an event using a sample and note its relative frequency, f/n, where f is the frequency or number of times an event occurs and n is the total sample size. As the sample size n increases, the sample will begin to approximate the true population probability.</p>
<ul>
<li>In Statistics, we need to infer characteristics concerning a population from a sample (data) selected from the population.</li>
<li>Notice that the process of selecting the sample involves an element of variability and the theory of probability, which is the formal study of the law of chance, is just the thing we need to assess this variability.</li>
<li>Since nothing in life is certain, probability is widely used in all branches of science, engineering and economics.</li>
</ul>
<p>There are many applications of probability in society. For example, we need to use probability theory to</p>
<ul>
<li>design and analyse experiments in almost any field of science and social science.</li>
<li>assign values to financial derivatives.</li>
<li>design, dimension and control telecommunications systems, and</li>
<li>understand the process of evolution of gene sequences.</li>
</ul>
<h3 id=dependencies-and-risk>Dependencies and risk</h3>
<p>Modelling dependencies is an important and widespread issue in risk analysis:</p>
<ul>
<li>Bank loans:
<ul>
<li>Dependency between defaults on loans</li>
<li>Correlation of default: what is the likelihood that if one company defaults, another will default soon after?</li>
<li>Dependency between stocks (e.g. CAC40 & DAX)</li>
<li>Amount of money for an insurance company which is needed to reimburse all claims.</li>
</ul>
</li>
<li>Hydrology: Dependency between annual peak of a river and volume</li>
<li>Civil engineering: Reliability analysis of highway bridges</li>
<li>Risk management: 1% or 5% quantile of an investment portfolio return</li>
<li>Insurance industry: Estimating exposure to systemic risks</li>
<li>Correlation of deaths for life insurance companies:
<ul>
<li>Marginal distributions: Probabilities of time until death for each spouse</li>
<li>Joint distribution: Shows the probability of spouses dying in close succession</li>
<li>Aim (actuarial studies): Estimate the conditional probability when one spouse dies, that the succeeding spouse will die shortly afterwards</li>
</ul>
</li>
</ul>
<h3 id=basic-concepts>Basic Concepts</h3>
<ul>
<li>Why probability?
<ul>
<li>It forms the mathematical foundation for statistical models and procedures.</li>
</ul>
</li>
<li>Basic Concepts:
<ul>
<li>An <strong>experiment</strong> is the process by which an observation (or measurement) is obtained.</li>
<li>An <strong>event</strong> is a set of possible outcomes of an experiment, that is a subset of Ω, usually denoted by a capital letter.</li>
</ul>
</li>
<li>The outcome space or sample space Ω is the set of all possible outcomes of an experiment, survey or
other observation</li>
</ul>
<p>The <strong>sample space</strong> is the set of all possible outcomes of an experiment. We use the term “experiment” very loosely here to refer to any activity where an outcome can vary. The most common “experiment” in statistics is taking a sample from the population.</p>
<p>For examples,</p>
<ul>
<li>Toss of a coin.
Ω = {H, T } where H = “head up” T = “tail up”</li>
<li>Spin of a roulette wheel. Ω = {0, 1, . . . , 36} (There are 37 numbers on an Australian roulette wheel.)</li>
</ul>
<h4 id=experiments-and-events>Experiments and Events</h4>
<h5 id=experiment>Experiment</h5>
<ul>
<li>Experiment: Record an age
<ul>
<li>A: person is 30 years old</li>
<li>B: person is older than 65</li>
</ul>
</li>
<li>Experiment: Toss a die
<ul>
<li>A: observe an odd number</li>
<li>B: observe a number greater than 2</li>
</ul>
</li>
<li>Measurement of the number of phone calls passing through a telephone exchange in a fixed time period.</li>
<li>A record of the proportion of people in a survey who approve of the prime minister.</li>
</ul>
<h5 id=events>Events</h5>
<ul>
<li>An event that cannot be decomposed is called a <strong>simple event</strong>.</li>
<li>Denoted by E with a subscript.</li>
<li>Each simple event will be assigned a probability, measuring “how often” it occurs.</li>
<li>The set of all simple events of an experiment is called the sample space, S.
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615786366/MATH1324/ModelThree/event_gregwk.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615786366/MATH1324/ModelThree/event_gregwk.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615786366/MATH1324/ModelThree/event_gregwk.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615786366/MATH1324/ModelThree/event_gregwk.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615786366/MATH1324/ModelThree/event_gregwk.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615786366/MATH1324/ModelThree/event_gregwk.png></li>
</ul>
<p>Events are sets and so they are subject to the normal set operations. Thus</p>
<ul>
<li>The event A ∪ B is the event that A or B or both occur.</li>
<li>The event A ∩ B is the event that A and B both occur.</li>
<li>The event A^c or \bar{A} is the event that A does not occur.</li>
<li>We write ω ∈ A to say that the outcome ω is in the event A.</li>
<li>We write A ⊆ B to say that A is a subset of B. This includes the possibility that A = B.</li>
<li>If A is finite (which will often not be the case), we write #A for the number of elements of A.</li>
</ul>
<p>For illustrative purposes, and to gain intuition, the relationship between events is often depicted using a Venn diagram.</p>
<p>Two events A_{1} , A_{2} which have no outcomes in common (A1 ∩ A2 = ∅) are called mutually exclusive or disjoint events.</p>
<p>Similarly, events A1 , A2 , . . . are disjoint if no two have outcomes in common, that is
A_{i} ∩ A_{j} = ∅ ∀ i 6 != j.</p>
<p>Set operations satisfy the <strong>distributive laws</strong></p>
<ul>
<li>A ∩ (B ∪ C) = (A ∩ B) ∪ (A ∩ C)</li>
<li>A ∪ (B ∩ C) = (A ∪ B) ∩ (A ∪ C)</li>
</ul>
<p>and <strong>De Morgan’s laws</strong></p>
<ul>
<li>(A ∪ B)^c = A^c ∩ B^c</li>
<li>(A ∩ B)^c = A^c ∪ B^c</li>
</ul>
<p>What do we mean when we say “The probability that a toss of a coin will result in ‘heads’ is 1/2”?
An interpretation that is accepted by most people for practical purposes, that such statements are made based upon some information about relative frequencies.</p>
<table>
<thead>
<tr>
<th>People</th>
<th>#trials</th>
<th>#heads</th>
<th>frequency of heads</th>
</tr>
</thead>
<tbody>
<tr>
<td>Buffon</td>
<td>4040</td>
<td>2048</td>
<td>0.5069</td>
</tr>
<tr>
<td>DeMorgan</td>
<td>4092</td>
<td>2048</td>
<td>0.5005</td>
</tr>
<tr>
<td>Feller</td>
<td>10000</td>
<td>4979</td>
<td>0.4979</td>
</tr>
<tr>
<td>Pearson</td>
<td>12000</td>
<td>6019</td>
<td>0.5016</td>
</tr>
<tr>
<td>Pearson</td>
<td>24000</td>
<td>12012</td>
<td>0.5005</td>
</tr>
</tbody>
</table>
<p>Similar statements can be made about tossing dice, spinning roulette wheels, arrivals of phone calls in a given time period, etc.</p>
<h5 id=the-probability-of-an-event>The Probability of an Event</h5>
<ul>
<li>The probability of an event A measures “how often” we think A will occur. We write P(A).</li>
<li>Suppose that an experiment is performed n times. The relative frequency for an event A is</li>
</ul>
<p>$$ Number of timesA occurs / n = f / n $$</p>
<ul>
<li>If we let n get infinitely large, $$ p(A) = \lim_{n \to \infty} f/n $$</li>
</ul>
<p>Examples:
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615836762/MATH1324/ModelThree/probabilityExampleOne_i2zjpg.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615836762/MATH1324/ModelThree/probabilityExampleOne_i2zjpg.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615836762/MATH1324/ModelThree/probabilityExampleOne_i2zjpg.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615836762/MATH1324/ModelThree/probabilityExampleOne_i2zjpg.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615836762/MATH1324/ModelThree/probabilityExampleOne_i2zjpg.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615836762/MATH1324/ModelThree/probabilityExampleOne_i2zjpg.png></p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615836762/MATH1324/ModelThree/probabilityExampleTwo_hsusvv.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615836762/MATH1324/ModelThree/probabilityExampleTwo_hsusvv.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615836762/MATH1324/ModelThree/probabilityExampleTwo_hsusvv.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615836762/MATH1324/ModelThree/probabilityExampleTwo_hsusvv.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615836762/MATH1324/ModelThree/probabilityExampleTwo_hsusvv.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615836762/MATH1324/ModelThree/probabilityExampleTwo_hsusvv.png></p>
<h5 id=probability-axioms>Probability axioms</h5>
<p>These considerations lead to the following <strong>axioms</strong>:</p>
<ol>
<li>P(A) ≥ 0, for all events A</li>
<li>P(Ω) = 1
3∗. (Finite additivity) For a set of mutually exclusive events {A1 , A2 , A3 , . . . , An }
$$ P ( \cup_{i=1}^{n} A_i ) = \sum_{i=1}^n P(A_i) $$</li>
</ol>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615837364/MATH1324/ModelThree/ProbabilityAxioms_e6uq46.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615837364/MATH1324/ModelThree/ProbabilityAxioms_e6uq46.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615837364/MATH1324/ModelThree/ProbabilityAxioms_e6uq46.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615837364/MATH1324/ModelThree/ProbabilityAxioms_e6uq46.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615837364/MATH1324/ModelThree/ProbabilityAxioms_e6uq46.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615837364/MATH1324/ModelThree/ProbabilityAxioms_e6uq46.png></p>
<p>In fact, it turns out that we need a slightly stronger version of Axiom 3 . Specifically, it has to hold for infinite sequences of mutually exclusive events. Thus, we use
3. (Countable additivity)
$$ P ( \cup_{i=1}^{\infty} A_i ) = \sum_{i=1}^{\infty} P(A_i) $$</p>
<p>where {A1 , A2 , A3 , . . .} is any sequence of mutually exclusive events.</p>
<p>We use countable, rather than finite, additivity because we sometimes need to calculate probabilities for countable unions.</p>
<p>For example, the event that a 6 eventually occurs when tossing a die can be expressed as $\cup_{i=1}^{\infty} A_i , where A_i is the event that the 6 occurs for the first time on the ith toss.</p>
<p>From the axioms, we can deduce the following properties of the probability function:
4. P(∅) = 0, since ∅ ∪ ∅ ∪ · · · = ∅
5. Finite additivity
6. P(A^c ) = 1 − P(A), since A ∪ A^c = Ω
7. A ⊆ B ⇒ P(A) ≤ P(B), since A ∪ (A^c ∩ B) = B
8. P(A) ≤ 1, since A ⊂ Ω
9. Addition theorem: P(A ∪ B) = P(A) + P(B) − P(A ∩ B)</p>
<p>The simplest case</p>
<p>When the outcome space is finite #(Ω) = N and there is no difference between outcomes so make them equally likely, then it follows easily from the axioms that</p>
<p>$$ P({ω}) = 1/N for all ω ∈ Ω $$</p>
<p>Further,</p>
<p>$$ P(A) = #(A)/N $$</p>
<h5 id=conditional-probability>Conditional Probability</h5>
<p>If A and H are two events, and it is known that event H has occurred, what effect does this information have on the probability of occurrence of A?</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615838187/MATH1324/ModelThree/ConditionalProbability_blhf9r.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615838187/MATH1324/ModelThree/ConditionalProbability_blhf9r.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615838187/MATH1324/ModelThree/ConditionalProbability_blhf9r.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615838187/MATH1324/ModelThree/ConditionalProbability_blhf9r.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615838187/MATH1324/ModelThree/ConditionalProbability_blhf9r.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615838187/MATH1324/ModelThree/ConditionalProbability_blhf9r.png></p>
<h6 id=example>Example</h6>
<p>Toss two fair dice. If we know that the first die is a 3, what is the probability that the sum of the two dice is 8?</p>
<p>The original sample space Ω has 36 outcomes {(1, 1), (1, 2), . . . , (6, 6)}. Given the first die is a 3 there are six outcomes of interest, {(3, 1), (3, 2), . . . , (3, 6)}. Since the dice are fair, each of these outcomes has the same probability of occurring. Hence, given that the first die is a 3, the probability of the sum being 8 is</p>
<p>If A denotes “sum of the dice is 8” and H denotes “first die is a 3” the probability we have calculated is called the <strong>conditional probability</strong> of A given H and is denoted P(A|H).</p>
<p>Hence the probability of A given H should be defined as the probability of A ∩ H relative to the probability of H:</p>
<p>$$ P(A|H) = P(A ∩ H) / P(H) if P(H) > 0 $$</p>
<h5 id=multiplication-theorem>Multiplication Theorem</h5>
<p>Sometimes we know P(H) and P(A|H) but not P(A ∩ H). If this is the case we can use the definition of conditional probability to express the probability of A ∩ H, that is</p>
<p>$$ P(A ∩ H) = P(H)P(A|H) $$</p>
<p>Let’s consider an example estimating the probability of randomly selecting people from the Australian population who have different levels of daily fruit consumption.</p>
<p>If we sampled random Australians we could categorise them into “&lt; 1 serve”, “1 serve”, “2 serves” or “3 serves or more”. These outcomes or categories make up the sample space and the process of the sampling from the population is our “experiment”. An event is an outcome of the experiment, e.g. that someone we sample consumes &lt; 1 serve of fruits per day. The probability of an event measures “how often” we expect the event to occur in the long run and is estimated using f/n. A probability estimated using a sample is an example of a statistic.</p>
<p>There is a entire abstract language used to express the laws of probability. We will look at the conventions here and relate these to real world examples. Once we have the basics down, we will concentrate on using these principles for practical purposes. Consider the following table adapted from Table 10 of the Australian Bureau of Statistics 2011 - 2012 National Health Survey. The table shows the estimated persons (reported in hundreds of thousands, ’000) that occupy the different levels of fruit intake. These estimates were taken from self-reports of a representative sample of approximately 18,400 households. The table splits these estimates across age and gender. We will use this table to explain the language of probability in a meaningful way and learn to solve problems that you will face in this course and later modules.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615772339/MATH1324/ModelThree/FruitIntake_ivsh5k.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615772339/MATH1324/ModelThree/FruitIntake_ivsh5k.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615772339/MATH1324/ModelThree/FruitIntake_ivsh5k.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615772339/MATH1324/ModelThree/FruitIntake_ivsh5k.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615772339/MATH1324/ModelThree/FruitIntake_ivsh5k.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615772339/MATH1324/ModelThree/FruitIntake_ivsh5k.png></p>
<h3 id=rules>Rules</h3>
<p>We denote probability using Pr(A), where A refers to an event of interest, e.g. Pr(2 serves). Let’s run an experiment by randomly selecting an Australian adult from the population. We will use the ABS data table as the probabilities of different events occurring. We use the relative frequency formula, f/n, to estimate this basic probability. First, we find the trial size, which is the estimated population size of Australians over the age of 18 as of 2012, 17,042, which equates to 17,042,000 people (the table is reported in ’000). Next, we find the frequency of people who eat two serves of fruit a day, 4984. Using the f/n formula, we write…</p>
<p>$$Pr(2 serves)=4984/17042=0.292$$</p>
<p>Therefore, the probability of randomly selecting an Australian adult who consumes two serves of fruits a day is .292. The probability of any event, Pr(A), must be between 0 and 1. If event A can never occur, Pr(A)=0. If event A always occurs when the experiment is performed, then Pr(A)=1. The sum of all probabilities of all possible events must equal 1:</p>
<p>$$Pr(&lt; 1 serve)+Pr(1serve)+Pr(2 serves)+Pr(3 serves or more)=1$$
$$(3368+5445+4984+3244)/17042 = 17042 / 17042 = 1$$</p>
<p>Two events are said to be <strong>mutually exclusive</strong> if, when one event occurs, the other cannot and vice versa. Mutually exclusive sets have no intersection: Pr(A∩B)=0. We use ∩ to denote an intersection. The levels of fruit consumption are mutually exclusive. A person cannot occupy more than one category at a particular time.</p>
<p>%%Pr(1 serve ∩ 2 serves) = 0%%</p>
<p>If two events can occur simultaneously, the events are not mutually exclusive and an intersection is possible, e.g. Pr(&lt; 1 serve ∩ Male). Note that the probability of an intersection can still be 0 even though an intersection is possible. For example, what if all Australian males had their favourite fruit prepared and delivered to them daily? Then, Pr(&lt; 1 serve ∩ Male) would probably be close to 0.</p>
<p>When we talk about intersections, the term “and” is often used. For example, what is the probability that a randomly sampled Australian adult is in the “&lt; 1 serve” interval AND male? You need to become comfortable with the language of probability. However, don’t worry, its a lot easier than you think when we apply the rules to real world examples. Using the Fruit Intake table, we can find this probability to be:</p>
<p>$$Pr(&lt; 1 serve ∩ Male) = 2036 / 17042 = .119$$</p>
<p>The <strong>union</strong> of two events A or B, is an event when either A or B, or A and B occur. We write a union using the ∪ symbol. The word “or” is used to refer to a union. For example, consider Pr(1 serve ∪ &lt; 1 serve), or in words, “What is the probability that a randomly sampled Australian will consume 1 serve of fruit OR less?”</p>
<p>$$Pr(1 serve ∪ &lt; 1 serve) = (3368 + 5445) / 17042 = .517$$</p>
<p>The <strong>complement</strong> of an event consists of all outcomes of the experiment that do not result in an event. For example, $$Pr(\bar{&lt; 1 serve}) = Pr(1 serve) + Pr(2 serves) + Pr(3 serves or more)$$. The complement of an event usually has a bar over the top of the event which is read as “not”. For example:</p>
<p>$$Pr(\bar{&lt; 1 serve}) = Pr(1 serve) + Pr(2 serves) + Pr(3 serves or more) = (5445 + 4984 + 3244) / 17042 = .802$$</p>
<p>or</p>
<p>$$ Pr(\bar{&lt; 1 serve}) = 1 − Pr(&lt; 1 serve) = 1 − 3368/17042 = .802 $$</p>
<p>The figure below provides a notational overview of the basic probability concepts.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615773549/MATH1324/ModelThree/robabilityConcepts_fuflbf.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615773549/MATH1324/ModelThree/robabilityConcepts_fuflbf.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615773549/MATH1324/ModelThree/robabilityConcepts_fuflbf.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615773549/MATH1324/ModelThree/robabilityConcepts_fuflbf.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615773549/MATH1324/ModelThree/robabilityConcepts_fuflbf.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1615773549/MATH1324/ModelThree/robabilityConcepts_fuflbf.png></p>
<h3 id=multiplication-law>Multiplication Law</h3>
<p>If two events are <strong>independent</strong> (i.e. the probability of the first event does not impact the probability of the second event), then the intersection is equal to the probability of the first event multiplied by the second event, Pr(A∩B)=Pr(A)×Pr(B). However, if independence does not hold, the two events are said to be <strong>dependent</strong>.</p>
<p>For example, if the consumption of fruit was independent of gender, then Pr(&lt; 1 serve ∩ Male) = Pr(&lt; 1 serve) × Pr(Male). However, is the assumption of independence safe for fruit consumption and gender? It’s often believed that adult males tend to consume less fruits than females. Therefore, the assumption of independence is not safe and the multiplication rule will not hold. Let’s check this assumption using the multiplication rule.</p>
<p>Recall…</p>
<p>$$ Pr(&lt; 1 serve ∩ Male) = 2036 / 17042 = .119 $$</p>
<p>Now, according to the multiplication rule for independent events:</p>
<p>$$ Pr(&lt; 1 serve ∩ Male) = Pr(&lt; 1 serve) × Pr(Male) = 3368 \ 17042 × 8406 \ 17042 = .097 $$</p>
<p>The two probabilities are not the same, therefore, as suspected, fruit consumption and gender are not independent. Males are more likely to be in the “&lt; 1 serve” category. The take home message is that <strong>the multiplication rule does not apply when events are dependent</strong>.</p>
<h3 id=addition-laws>Addition Laws</h3>
<p>Finding the probability of a union depends on whether or not the events are <strong>mutually exclusive</strong>. If the events are mutually exclusive, we simply add the events. Recall…</p>
<p>$$ Pr(1 serve ∪ &lt; 1 serve) = (3368 + 5445) / 17042 = .517 $$</p>
<p>If the events are not mutually exclusive, we need to subtract the intersection from the addition law. For example:</p>
<p>$$ Pr(&lt; 1 serve ∪ Male) = Pr(&lt; 1 serve) + Pr(Male) − Pr(&lt; 1 serve ∩ Male) = 3368 / 17042 + 8406 / 17042 − 2036 / 17042 = .571 $$</p>
<h3 id=conditional-probability-1>Conditional Probability</h3>
<p>The probability that an event, <strong>B, will occur</strong> given that another event, <strong>A, has already occurred</strong> is called the <strong>conditional probability</strong> of B given A. The “|” symbol, read as “given” is used to denote a condition. Conditional probability can be written as follows:</p>
<p>Pr(B|A) = Pr(A ∩ B) / Pr(A)</p>
<p>Using an example…</p>
<p>$$ Pr(&lt; 1 serve|Male) = Pr(Male ∩ &lt; 1 serve) / Pr(Male) = (2036 / 17042) / (8406 / 17042) = .242 $$</p>
<p>We can also use conditional probability to check independence. The two events A and B are independent if and only if Pr(A|B) = Pr(A) or Pr(B|A)=Pr(B). Otherwise, the events are dependent. Let’s use this rule to reconfirm that gender and fruit consumption are dependent.</p>
<p>Pr(&lt; 1 serve | Male) = .242
Pr(&lt; 1 serve) = 3368 / 17042 = .198</p>
<p>We find Pr(B|A) ≠ Pr(A). The probabilities are not equal, therefore, dependency is present. Given that you’re male, you are more likely to be consuming less than 1 serve of fruit per day than females. Males need to eat more fruit!</p>
<p><strong>NOTE:</strong> conditional probability and Multiplication Law to check independence.</p>
<h3 id=permutations-and-combinations>Permutations and Combinations</h3>
<h4 id=permutations-have-rangking>Permutations (have rangking)</h4>
<p>Let’s assume you are voting in a local council election. There are six candidates. You need to vote for the top three. How many possible ways can you assign your votes, 1st, 2nd and 3rd preference? This is an example of a permutation problem. Permutations refers to all the possible ways of selecting something where order matters. Here are three possible permutations for the voting example:</p>
<table>
<thead>
<tr>
<th>Veronica Paskett</th>
<th>Milagros Depaolo</th>
<th>Loraine Muntz</th>
<th>Thuy Silverberg</th>
<th>Myriam Hakes</th>
<th>Maude Dimery</th>
</tr>
</thead>
<tbody>
<tr>
<td>1st</td>
<td>2nd</td>
<td>3rd</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>-</td>
<td>1st</td>
<td>2nd</td>
<td>3rd</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>-</td>
<td>2nd</td>
<td>1st</td>
<td>-</td>
<td>3rd</td>
<td>-</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<p>As you can see, there are many more possible ways to assign your votes. To quickly calculate all the possible permutations, we can use the following formula:</p>
<p>$$P(n,k)=n! / (n−k)!$$</p>
<p>The ! symbol refers to the factorial of a number. For example, 6!=6×5×4×4×3×2×1=720. In R, we can use factorial():</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>factorial</span><span class=p>(</span><span class=m>6</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 720</span>
</code></pre></td></tr></table>
</div>
</div><p>k is the number to choose, in this example, 3.</p>
<p>Solving the voting problem:</p>
<p>P(6,3) = 6! / (6−3)! =6! / 3! = 7206</p>
<p>Using R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>factorial</span><span class=p>(</span><span class=m>6</span><span class=p>)</span> <span class=o>/</span> <span class=nf>factorial</span><span class=p>(</span><span class=m>6-3</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 120</span>
</code></pre></td></tr></table>
</div>
</div><h4 id=combinations-not-ranking>Combinations (not ranking)</h4>
<p>Now let’s change the problem. You have four spare tickets for a sport grand final. You have ten friends that you know would like to go. You need to weigh up the social impact of inviting different combinations of friends. First you need to know how many possible combinations of selecting four out of ten friends need to be considered. <strong>Combinations</strong> refer to all the possible ways of selecting a certain number of things from a larger group. Here are three possible combinations:</p>
<table>
<thead>
<tr>
<th>Leah</th>
<th>Rosalie</th>
<th>Marlena</th>
<th>Tarra</th>
<th>Graham</th>
<th>Gilberto</th>
<th>Marcos</th>
<th>Gladis</th>
<th>Otha</th>
<th>Jeremiah</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ticket</td>
<td>-</td>
<td>Ticket</td>
<td>-</td>
<td>Ticket</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>Ticket</td>
</tr>
<tr>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>Ticket</td>
<td>Ticket</td>
<td>Ticket</td>
<td>Ticket</td>
</tr>
<tr>
<td>-</td>
<td>Ticket</td>
<td>-</td>
<td>Ticket</td>
<td>-</td>
<td>Ticket</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>Ticket</td>
</tr>
</tbody>
</table>
<p>Notice with combinations that order does not matter. Leah, Marlena, Graham and Jeremiah is the same combination as Marlena, Leah, Jeremiah and Graham. All four friends will go to the game and will be your best friends forever, regardless of the order by which they’re selected.</p>
<p>The formula for combinations is as follows:</p>
<p>C(n,k) = n! / ((n−k)!k!)</p>
<p>This is known as the “choose”" formula or the binomial coefficient (we will revisit this in Module 4). Solving, we find:</p>
<p>C(n,k) = n! / ((n−k)!k!) = 10! / (10−4)!4! = 10! / (6)!4! = 3628800 / 17280 = 210</p>
<p>Using R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>choose</span><span class=p>(</span><span class=m>10</span><span class=p>,</span><span class=m>4</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 210</span>
</code></pre></td></tr></table>
</div>
</div><p>That’s incredible. There are 210 different combinations of friends that you could end up taking to the final. Considering the social ramifications of each combination will take weeks of deliberation, leave it to chance. Use a raffle instead. That way no one can claim favouritism… Who said statistics wasn’t useful!</p>
<h3 id=exercises>Exercises</h3>
<h1 id=data>Data</h1>
<p>The table below was adapted from Table 11.1 of the Australian Health Survey: First Results, 2011-12
s<a href=http://www.abs.gov.au/ausstats/abs@.nsf/mf/4364.0.55.001 target=_blank rel="noopener noreferrer">cat.no.4364.0.55.001</a>.
Table 11.1 presents the estimates of persons (reported in 100,000s) from the 2011-2013 Australian Health
Survey relating to Australians’ levels of exercise. The values are in 100,000s. Estimates were derived
from surveys of approximately 9500 Australian households.</p>
<table>
<thead>
<tr>
<th>Age group</th>
<th>15–17</th>
<th>18–24</th>
<th>25–34</th>
<th>35–44</th>
<th>45–54</th>
<th>55–64</th>
<th>65–74</th>
<th>75+</th>
<th>Total 100’000</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Males</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Sedentary</td>
<td>63.3</td>
<td>307.1</td>
<td>440.3</td>
<td>527.4</td>
<td>518.4</td>
<td>477.3</td>
<td>320.2</td>
<td>253.9</td>
<td>2,907.90</td>
</tr>
<tr>
<td>Low</td>
<td>109.8</td>
<td>230.6</td>
<td>446.2</td>
<td>466.6</td>
<td>473</td>
<td>373.9</td>
<td>245.7</td>
<td>165.2</td>
<td>2,511.00</td>
</tr>
<tr>
<td>Moderate</td>
<td>125.8</td>
<td>278.8</td>
<td>377.9</td>
<td>305.8</td>
<td>295.4</td>
<td>318</td>
<td>np</td>
<td>np</td>
<td>1,701.70</td>
</tr>
<tr>
<td>High</td>
<td>136.6</td>
<td>303.3</td>
<td>341.8</td>
<td>249.4</td>
<td>202.3</td>
<td>96.1</td>
<td>np</td>
<td>np</td>
<td>1,329.50</td>
</tr>
<tr>
<td>Total(b)</td>
<td>435.5</td>
<td>1,119.80</td>
<td>1,606.20</td>
<td>1,549.20</td>
<td>1,489.10</td>
<td>1,265.30</td>
<td>565.9</td>
<td>419.1</td>
<td>8,450.10</td>
</tr>
<tr>
<td><strong>Females</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Sedentary</td>
<td>119.6</td>
<td>336.5</td>
<td>558.6</td>
<td>549.1</td>
<td>570.9</td>
<td>475.7</td>
<td>357</td>
<td>451.2</td>
<td>3,418.60</td>
</tr>
<tr>
<td>Low</td>
<td>154.1</td>
<td>426.9</td>
<td>552.2</td>
<td>562.2</td>
<td>516.3</td>
<td>486.2</td>
<td>276.3</td>
<td>154.7</td>
<td>3,128.90</td>
</tr>
<tr>
<td>Moderate</td>
<td>93.3</td>
<td>193.9</td>
<td>294.9</td>
<td>319.3</td>
<td>307.6</td>
<td>272.1</td>
<td>np</td>
<td>np</td>
<td>1,481.10</td>
</tr>
<tr>
<td>High</td>
<td>49.1</td>
<td>112.2</td>
<td>192.6</td>
<td>156.1</td>
<td>137.7</td>
<td>63.8</td>
<td>np</td>
<td>np</td>
<td>711.5</td>
</tr>
<tr>
<td>Total(b)</td>
<td>416.1</td>
<td>1,069.50</td>
<td>1,598.30</td>
<td>1,586.70</td>
<td>1,532.50</td>
<td>1,297.80</td>
<td>633.3</td>
<td>605.9</td>
<td>8,740.10</td>
</tr>
<tr>
<td><strong>Persons</strong></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Sedentary</td>
<td>182.9</td>
<td>643.6</td>
<td>998.9</td>
<td>1,076.50</td>
<td>1,089.30</td>
<td>953</td>
<td>677.2</td>
<td>705.1</td>
<td>6,326.50</td>
</tr>
<tr>
<td>Low</td>
<td>263.9</td>
<td>657.5</td>
<td>998.4</td>
<td>1,028.80</td>
<td>989.3</td>
<td>860.1</td>
<td>522</td>
<td>319.9</td>
<td>5,639.90</td>
</tr>
<tr>
<td>Moderate</td>
<td>219.1</td>
<td>472.7</td>
<td>672.8</td>
<td>625.1</td>
<td>603</td>
<td>590.1</td>
<td>np</td>
<td>np</td>
<td>3,182.80</td>
</tr>
<tr>
<td>High</td>
<td>185.7</td>
<td>415.5</td>
<td>534.4</td>
<td>405.5</td>
<td>340</td>
<td>159.9</td>
<td>np</td>
<td>np</td>
<td>2,041.00</td>
</tr>
<tr>
<td>Total(b)</td>
<td>851.6</td>
<td>2,189.30</td>
<td>3,204.50</td>
<td>3,135.90</td>
<td>3,021.60</td>
<td>2,563.10</td>
<td>1,199.20</td>
<td>1,025.00</td>
<td>17,190.20</td>
</tr>
</tbody>
</table>
<p>Note. np = not estimated.
Use this table to answer the following questions:</p>
<ol>
<li>Exercise 1
According to Table 11.1, gender is mutually exclusive. True or false?</li>
</ol>
<p>A: TRUE</p>
<ol start=2>
<li>Exercise 2
Being male and sedentary is mutually exclusive. True or false?</li>
</ol>
<p>A: FALSE</p>
<ol start=3>
<li>Exercise 3
Substitute T the correct probability C symbol with the statement.</li>
<li>∪</li>
<li>A|B</li>
<li>Ā</li>
<li>∩</li>
</ol>
<p>a. A or B = A __ B
b. A and B = A __ B
c. Not A = __
d. A given B = A __ B</p>
<p>A: a = 1, b = 4, c = 3, d = 2</p>
<ol start=4>
<li>Exercise 4
What is the probability of an Australian being sedentary? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=p>(</span><span class=m>6326.5</span> <span class=o>/</span> <span class=m>17190.2</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>round</span><span class=p>(</span><span class=m>3</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><ol start=5>
<li>Exercise 5
According to Table 11.1, what is the probability of being male? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=p>(</span><span class=m>8450.1</span><span class=o>/</span><span class=m>17190.2</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>round</span><span class=p>(</span><span class=m>3</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><ol start=6>
<li>Exercise 6
According to Table 11.1, what is the probability of being female? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=m>1</span> <span class=o>-</span> <span class=p>(</span><span class=m>8450.1</span><span class=o>/</span><span class=m>17190.2</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>round</span><span class=p>(</span><span class=m>3</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>(8740.1 / 17190.2) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=7>
<li>Exercise 7
What is the probability of being a male and sedentary? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>(2907.90 / 17190.2) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=8>
<li>Exercise 8
What is the probability of being female and sedentary? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>(3418.60 / 17190.2) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=9>
<li>Exercise 9
In the previous question, you calculated the probability of being female and sedentary. Determine if
being sedentary is independent of being female. Ensure you can show your reasoning.</li>
</ol>
<ul>
<li>Being female is independent from being sedentary.</li>
<li>Being sedentary depends on being female.</li>
<li>Being female and sedentary are independent because both events are mutually exclusive.</li>
<li>Only being male depends on being sedentary.</li>
</ul>
<p>A: Being sedentary depends on being female.</p>
<p>From the previous question you should have found that Pr(Female ∩ Sedentary) = 0.199. If these two events are independent, then Pr(Female ∩ Sedentary) = Pr(Female)*Pr(Sedentary).
Using Table 11.1:</p>
<p>Pr(Female) =</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>8740.1/17190.2
</code></pre></td></tr></table>
</div>
</div><p>Pr(Sedentary) =</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>6326.5/17190.2
</code></pre></td></tr></table>
</div>
</div><p>Pr(Female)*Pr(Sedentary) =</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>(8740.1/17190.2) * (6326.5/17190.2)
</code></pre></td></tr></table>
</div>
</div><p>This is not equal s to 0.199 calculated from Table 11.1, therefore being sederntary and female is dependent.</p>
<ol start=10>
<li>Exercise 10
What is the probability of being male, aged 25 - 34 and high in exercise level? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>(341.8/17190.2) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=11>
<li>Exercise 11
What is the probability of being female, aged 25 - 34 and high in exercise level? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>(192.6/17190.2) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=12>
<li>Exercise 12
What is the probability of being aged between 35-44? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>(3135.9/17190.2) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=13>
<li>Exercise 13
What is the probability of being aged 75 years and over? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>(1025/17190.2) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=14>
<li>Exercise 14
What is the probability of being a male or female? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>((8450.1 + 8740.1)/17190.2) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=15>
<li>Exercise 15
What is the probability of being aged between 25 - 34 or 35 - 44? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>((3204.5 + 3135.9)/17190.2) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=16>
<li>Exercise 16
What is the probability of having a high level of exercise given that a person is male? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>(1329.5/8450.1) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=17>
<li>Exercise 17
What is the probability of having a high level of exercise given that a person is female? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>(711.5/8740.1) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=18>
<li>Exercise 18
Comparing the two conditional probabilities calculated in Questions 16 and 17, which of the following statements is true?</li>
</ol>
<ul>
<li>Males are nearly twice as likely than females to be engaged in high levels of exercise.</li>
<li>The proportion of males and females involved in high levels of exercise is approximately the
same.</li>
<li>Females are more likely than males to be involved in high levels of exercise.</li>
<li>Men enjoy exercise more than women</li>
</ul>
<p>A: Males are nearly twice as likely than females to be engaged in high levels of exercise.</p>
<ol start=19>
<li>Exercise 19
What is the probability that a person is sedentary given they are aged 45 years or above? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>((1089.3 + 953 + 677.2 + 705.1)/(3021.6 + 2563.1 + 1199.2 + 1025)) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=20>
<li>Exercise 20
What is the probability that a person is sedentary given they are aged under 45 years? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>((182.9 + 643.6 + 998.9 + 1076.5)/(851.6 + 2189.3 + 3204.5 + 3135.9)) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=21>
<li>Exercise 21
Comparing the two conditional probabilities calculated in Questions 19 and 20, which of the following statements is true?</li>
</ol>
<ul>
<li>Age is independent of being sedentary.</li>
<li>Young people under the age of 45 are more likely than people over the age of 45 to be sedentary.</li>
<li>Old people get lazy.</li>
<li>People over the age of 45 are more likely to be sedentary than people under the age of 45.</li>
</ul>
<p>A: People over the age of 45 are more likely to be sedentary than people under the age of 45.</p>
<ol start=22>
<li>Exercise 22
What is the probability that a person is NOT sedentary given they are aged 45 years or above? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>1 - ((1089.3 + 953 + 677.2 + 705.1)/(3021.6 + 2563.1 + 1199.2 + 1025)) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=23>
<li>Exercise 23
You’ve forgotten your four digit pin number for your VISA card. The only thing you can remember is that your pin had no repeated numbers. How many possible pin numbers would you need to consider to break the pin using brute force (trying every possible pin)?</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>factorial(10)/factorial(10-4)
</code></pre></td></tr></table>
</div>
</div><h1 id=exercise-24>Exercise 24</h1>
<p>You have to rank your top three movies of all time. You’ve narrowed your list to 20 titles, but need to rank only the top i three. How many possible ways could you assign the top three, 1st ,2nd and 3rd?</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>factorial(20)/factorial(20-3)
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>#install if necessary
#install.packages(&#39;gtools&#39;)
#load library
library(gtools)
#urn with 3 balls
x &lt;- c(1:20)

#get all permutations
#permutations(n=20,r=3,v=x,repeats.allowed=F)

#number of permutations
nrow(permutations(n=20,r=3,v=x,repeats.allowed=F))
</code></pre></td></tr></table>
</div>
</div><ol start=25>
<li>Exercise 25
You’ve performed an experiment with four groups, Group A, B, C and D. You want to compare the means of each group to every other group. These are known as pairwise comparisons. For example, Group A vs. B, Group B vs. C etc. How many possible combinations of pairwise comparions do you need to consider?</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>choose(4,2)
</code></pre></td></tr></table>
</div>
</div><ol start=26>
<li>Exercise 26
You go to a sandwich bar. You count there are 30 different ingredients (e.g. meat, lettuce, tomatoes). You can pick five ingredients to make a $5 sandwich. How many possible combinations of five ingredients could you choose?</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>choose(30,5)
</code></pre></td></tr></table>
</div>
</div><h2 id=probability-distributions-random-but-predictable>Probability Distributions: Random, but Predictable</h2>
<h3 id=overview>Overview</h3>
<p>Despite the omnipresence of variability, many variables follow predicable patterns. That’s not to say we can reliably predict an individual observation with great certainty, but over the course of many repeated observations of a variable, we can predict many informative outcomes. This module introduces two discrete probability distributions and one continuous probability distribution which are know to model the behaviour of many random processes.</p>
<h3 id=learning-objectives-2>Learning Objectives</h3>
<p>The learning objectives associated with this module are:</p>
<ul>
<li>Define and distinguish between random variables, discrete random variables, and continuous random variables.</li>
<li>Define the properties of the Binomial and Poisson distributions.</li>
<li>Correctly apply and work with the Binomial and Poisson distributions to solve Binomial and Poisson-based problems.</li>
<li>Define the properties of the normal distribution and identify where it can be applied.</li>
<li>Work with the normal distribution to solve normal-based problems.</li>
<li>Define the standard normal z-distribution.</li>
<li>Standardise random variables to standard normal variables, and vice-versa.</li>
<li>Compare empirical distributions to theoretical probability distributions</li>
</ul>
<h3 id=probability-distributions>Probability Distributions</h3>
<p>This module will introduce you to the first set of fundamental probability distributions used by statisticians to model random processes. Probability distributions are based on the central concept of statistics that, while an individual random event is almost impossible to predict, the behaviour of random processes in the long run can be very well understood. This module introduces discrete and continuous probability distributions. These distributions are used to model quantitative variables that can only take on discrete values (1, 2, 3…) and continuous values (1.45, 5.43, 2.39). These probability distributions can be used to model many random variables including guessing on a multiple choice exam, the number of heads flipped from five tosses of a coin, the number of goals scored in a football match, the infection rate of a disease or the number of people lining up in a queue at your local cafe. Let’s start with the binomial distribution.</p>
<h3 id=binomial-distribution>Binomial Distribution</h3>
<p>The binomial distribution is used to model the number of successes/failures in n independent trials where the probability of success at each trial is fixed as p. The probability of failure is 1−p. For example, let’s say a cancer vaccine is effective 85% of the time, p = .85. If we randomly select 12 vaccinated people from the population, n = 12, and expose them to the virus that causes the cancer, what is the probability that the vaccine will be successful for all 12 people? Before we answer this question, let’s take a look at some theory.</p>
<p>The binomial distribution has the following mathematical form:</p>
<p>$$Pr(X = k) = \binom{n}{k}p^k(1-p)^{n-k}$$</p>
<p>where k = successes, n = no. of trials and p = probability of success. This formula is known as a probability mass function or PMF.</p>
<p>The mean, or expected value, E(x), variance and standard deviation for a binomial distribution are as follows:</p>
<p>$$\text{Mean} = E(x) = np$$</p>
<p>$$\text{Variance} = np(1 - p)$$</p>
<p>$$\text{Standard deviation} = \sqrt{np(1-p)}$$</p>
<p>However, there is no need to remember these formulae. We will learn to use R to do the hard work for us. We will demonstrate R’s binomial function to solve the following questions related to the vaccine scenario. We will assume p = .85 and n = 12.</p>
<h4 id=11-what-is-the-probability-that-the-vaccine-will-work-for-10-people>1.1. What is the probability that the vaccine will work for 10 people?</h4>
<p>$$Pr(X = k)$$</p>
<p>The key to solving these types of problems is to understand the question. Let’s write it out. The question is asking $Pr(X=10)$ , assuming 12 trials and the vaccine to be effective 85% of the time. X is a short way to refer to the number of successes. We can visualise this in the following plot (the code will be introduced later). The height of each point line refers to the binomial probability of observing 0 to 12 successes in 12 trials assuming, p = 0.85. Each probability was calculated using the binomial PMF formula above. We can see 0 - 7 success all have probabilities below 0.05, while 10 and 11 successes have probabilities approximately 0.30. This makes sense as the expected, or mean value = np = 12*.85 = 10.2. If we added all the probabilities for each point line together, they would sum to 1. This is known as the total probability law. The Pr(X=10) has been coloured as a red line in the plot. We can quickly see Pr(X=10) will be about .30.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617966932/MATH1324/ModelFour/BinomialDistribution_npw3ty.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617966932/MATH1324/ModelFour/BinomialDistribution_npw3ty.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617966932/MATH1324/ModelFour/BinomialDistribution_npw3ty.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617966932/MATH1324/ModelFour/BinomialDistribution_npw3ty.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617966932/MATH1324/ModelFour/BinomialDistribution_npw3ty.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617966932/MATH1324/ModelFour/BinomialDistribution_npw3ty.png></p>
<p>Now we could use the formula given above to calculate the exact probability…</p>
<p>$$Pr(X = 10) = \binom{12}{10}.85^{10}(1-.85)^{12-10}$$</p>
<p>However, using an R function will do this a lot quicker and far more accurately. In R, we use the dbinom(x, size, prob) function. This function has three arguments:</p>
<ul>
<li>x : The value for k, or number of successes</li>
<li>size : The number of trials for each experiment</li>
<li>prob : The probability of success (p)</li>
</ul>
<p>For Question 1. We type the following command into R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>dbinom</span><span class=p>(</span><span class=n>x</span> <span class=o>=</span> <span class=m>10</span><span class=p>,</span> <span class=n>size</span> <span class=o>=</span> <span class=m>12</span><span class=p>,</span> <span class=n>prob</span> <span class=o>=</span> <span class=m>0.85</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 0.2923585</span>
</code></pre></td></tr></table>
</div>
</div><p>The answer is found to be $Pr(X = 10) = 0.29$. Given that the vaccine is 85% effective, it would be relatively common to find 10 successes in 12 randomly sampled people. In other words, there is a 29% chance that the vaccine will work for exactly 10/12 people.</p>
<p>If you’re interested in reproducing the plot above, you can use the following R code. Its a little lengthy, but it should mostly make sense.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=c1>## Set binomial parameters.</span>

<span class=n>n</span> <span class=o>&lt;-</span> <span class=m>12</span>
<span class=n>p</span> <span class=o>=</span> <span class=m>.85</span>

<span class=c1>## Define PMF to highlight - Pr(X &lt; x), Pr(X &gt; x), or Pr(a &lt; x &lt; b)</span>
<span class=c1>## Leave blank &#34;&#34; for no highlights</span>
<span class=n>x</span> <span class=o>&lt;-</span> <span class=m>10</span>
<span class=n>a</span> <span class=o>&lt;-</span> <span class=s>&#34;&#34;</span>
<span class=n>b</span> <span class=o>&lt;-</span> <span class=s>&#34;&#34;</span>


<span class=c1>## Set sequence of x values to plot</span>
<span class=n>Successes</span> <span class=o>&lt;-</span> <span class=nf>seq</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=n>n</span><span class=p>)</span>

<span class=c1>## Calculate PMF</span>
<span class=n>PMF</span> <span class=o>&lt;-</span> <span class=nf>dbinom</span><span class=p>(</span><span class=n>x</span> <span class=o>=</span> <span class=n>Successes</span><span class=p>,</span> <span class=n>size</span> <span class=o>=</span> <span class=n>n</span><span class=p>,</span> <span class=n>prob</span> <span class=o>=</span> <span class=n>p</span><span class=p>)</span>

<span class=c1>## Define points to highlight in plot</span>

<span class=n>highlight</span> <span class=o>&lt;-</span> <span class=nf>ifelse</span><span class=p>(</span><span class=n>Successes</span> <span class=o>&lt;=</span> <span class=n>b</span> <span class=o>&amp;</span> 
                      <span class=n>Successes</span> <span class=o>&gt;=</span> <span class=n>a</span> <span class=o>|</span>
                      <span class=n>Successes</span> <span class=o>==</span> <span class=n>x</span><span class=p>,</span> <span class=s>&#34;red&#34;</span><span class=p>,</span> <span class=s>&#34;blue&#34;</span><span class=p>)</span>

<span class=c1>## Plot PMF</span>
<span class=nf>plot</span><span class=p>(</span><span class=n>Successes</span><span class=p>,</span> <span class=n>PMF</span><span class=p>,</span> <span class=n>type</span> <span class=o>=</span> <span class=s>&#34;p&#34;</span><span class=p>,</span>
     <span class=n>main</span> <span class=o>=</span> <span class=nf>paste</span><span class=p>(</span><span class=s>&#34;Binomial Distribution, n = &#34;</span><span class=p>,</span><span class=n>n</span><span class=p>,</span><span class=s>&#34;, p = &#34;</span><span class=p>,</span><span class=n>p</span><span class=p>),</span> <span class=n>col</span> <span class=o>=</span> <span class=n>highlight</span><span class=p>)</span>
<span class=nf>lines</span><span class=p>(</span><span class=n>Successes</span><span class=p>,</span><span class=n>PMF</span><span class=p>,</span> <span class=n>type</span> <span class=o>=</span> <span class=s>&#34;h&#34;</span><span class=p>,</span> <span class=n>col</span> <span class=o>=</span> <span class=n>highlight</span><span class=p>)</span>
<span class=nf>grid</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><h4 id=12-what-is-the-probability-that-the-vaccine-will-work-for-8-or-less-people>1.2. What is the probability that the vaccine will work for 8 or less people?</h4>
<p>$$Pr(X \leq k)$$</p>
<p>This is a slightly different question. We are asked to find $Pr(X = 0) + Pr(X = 1) + &mldr; + Pr(X = 8)$, or simply $Pr(X ≤ 8)$. This is known as a cumulative probability. Visually, this question looks like the following plot. The red shaded point lines refer to $Pr(X≤8)$. If we add the probabilities of each of these point lines, we can solve the problem.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617967904/MATH1324/ModelFour/BinomialDistribution2_emgy8i.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617967904/MATH1324/ModelFour/BinomialDistribution2_emgy8i.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617967904/MATH1324/ModelFour/BinomialDistribution2_emgy8i.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617967904/MATH1324/ModelFour/BinomialDistribution2_emgy8i.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617967904/MATH1324/ModelFour/BinomialDistribution2_emgy8i.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617967904/MATH1324/ModelFour/BinomialDistribution2_emgy8i.png></p>
<p>Using the dbinom() function:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>dbinom(x = 0:8, size = 12, prob = .85) %&gt;% sum()
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.09220633</span>
</code></pre></td></tr></table>
</div>
</div><p>Alternatively, we can visualise the cumulative masss function (CMF), which plots, Pr(X≤x). For example: Pr(X≤1)=Pr(X=0)+Pr(X=1), or Pr(X≤8)=Pr(X=0)+Pr(X=1)+&mldr;+Pr(X=8) The CMF for the binomial distribution with n=12, p=0.85 is visualised below. As this is a CMF, it is bound between a probability of 0 and 1. To find Pr(X≤8), we look for 8 on the x axis. We can’t see the exact value, but we know it’s going be be less than 0.1.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968098/MATH1324/ModelFour/BinomialDistribution3_rm3naj.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968098/MATH1324/ModelFour/BinomialDistribution3_rm3naj.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968098/MATH1324/ModelFour/BinomialDistribution3_rm3naj.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968098/MATH1324/ModelFour/BinomialDistribution3_rm3naj.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968098/MATH1324/ModelFour/BinomialDistribution3_rm3naj.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968098/MATH1324/ModelFour/BinomialDistribution3_rm3naj.png></p>
<p>Easy to do in R using a slightly different pbinom() function:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>pbinom(q = 8, size = 12, prob = 0.85, lower.tail = TRUE)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.09220633</span>
</code></pre></td></tr></table>
</div>
</div><p>which we recall is exactly the same as:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>dbinom(x = 0:8, size = 12, prob = .85) %&gt;% sum()
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.09220633</span>
</code></pre></td></tr></table>
</div>
</div><p>We use q instead of x and we add lower.tail = TRUE to ensure we calculate $Pr(X≤x)$ and not $Pr(X>x)$, which would be specified as lower.tail = FALSE. The answer is .092. Once again, it would be unusual to observe the vaccine only working for 8 or less people out of 12, given p=0.85.</p>
<p>Here’s the code for the CMF plot above.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=c1>## Set binomial parameters.</span>

<span class=n>n</span> <span class=o>&lt;-</span> <span class=m>12</span>
<span class=n>p</span> <span class=o>=</span> <span class=m>.85</span>

<span class=c1>## Define CMF to highlight - Pr(X &lt; x), Pr(X &gt; x), or Pr(a &lt; x &lt; b)</span>
<span class=c1>## Leave blank &#34;&#34; for no highlights</span>
<span class=n>x</span> <span class=o>&lt;-</span> <span class=s>&#34;&#34;</span>
<span class=n>a</span> <span class=o>&lt;-</span> <span class=m>0</span>
<span class=n>b</span> <span class=o>&lt;-</span> <span class=m>8</span>

<span class=c1>## Set sequence of x values to plot</span>
<span class=n>Successes</span> <span class=o>&lt;-</span> <span class=nf>seq</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=n>n</span><span class=p>)</span>

<span class=c1>## Calculate CMF</span>
<span class=n>CMF</span> <span class=o>&lt;-</span> <span class=nf>pbinom</span><span class=p>(</span><span class=n>q</span> <span class=o>=</span> <span class=n>Successes</span><span class=p>,</span> <span class=n>size</span> <span class=o>=</span> <span class=n>n</span><span class=p>,</span> <span class=n>prob</span> <span class=o>=</span> <span class=n>p</span><span class=p>)</span>

<span class=c1>## Define points to highlight in plot</span>

<span class=n>highlight</span> <span class=o>&lt;-</span> <span class=nf>ifelse</span><span class=p>(</span><span class=n>Successes</span> <span class=o>&lt;=</span> <span class=n>b</span> <span class=o>&amp;</span> 
                      <span class=n>Successes</span> <span class=o>&gt;=</span> <span class=n>a</span> <span class=o>|</span>
                      <span class=n>Successes</span> <span class=o>==</span> <span class=n>x</span><span class=p>,</span> <span class=s>&#34;red&#34;</span><span class=p>,</span> <span class=s>&#34;blue&#34;</span><span class=p>)</span>

<span class=c1>## Plot CMF</span>
<span class=nf>plot</span><span class=p>(</span><span class=n>Successes</span><span class=p>,</span> <span class=n>CMF</span><span class=p>,</span> <span class=n>type</span> <span class=o>=</span> <span class=s>&#34;p&#34;</span><span class=p>,</span>
     <span class=n>main</span> <span class=o>=</span> <span class=nf>paste</span><span class=p>(</span><span class=s>&#34;Binomial Distribution, n = &#34;</span><span class=p>,</span><span class=n>n</span><span class=p>,</span><span class=s>&#34;, p = &#34;</span><span class=p>,</span><span class=n>p</span><span class=p>),</span> <span class=n>col</span> <span class=o>=</span> <span class=n>highlight</span><span class=p>)</span>
<span class=nf>lines</span><span class=p>(</span><span class=n>Successes</span><span class=p>,</span><span class=n>CMF</span><span class=p>,</span> <span class=n>type</span> <span class=o>=</span> <span class=s>&#34;h&#34;</span><span class=p>,</span> <span class=n>col</span> <span class=o>=</span> <span class=n>highlight</span><span class=p>)</span>
<span class=nf>grid</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><h4 id=13-what-is-the-probability-that-the-vaccine-will-work-in-more-than-8-random-people>1.3. What is the probability that the vaccine will work in more than 8 random people?</h4>
<p>$$Pr(X > k)$$</p>
<p>Once again, a slightly different question. This time we need to find, $Pr(X>8)$. According to the total probability rule, $Pr(0≤X≤12)=1$. The pbinom() function in R, by default, gives us $Pr(X≤8)$, therefore, $Pr(X>8)=1−Pr(X≤8)$. In other words, $Pr(X>8)=Pr(X=9)+Pr(X=10)+Pr(X=11)+Pr(X=12)$. Let’s visualise this question. The $Pr(X>8)$ is shaded in red.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968446/MATH1324/ModelFour/BinomialDistribution4_qpkmpm.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968446/MATH1324/ModelFour/BinomialDistribution4_qpkmpm.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968446/MATH1324/ModelFour/BinomialDistribution4_qpkmpm.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968446/MATH1324/ModelFour/BinomialDistribution4_qpkmpm.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968446/MATH1324/ModelFour/BinomialDistribution4_qpkmpm.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968446/MATH1324/ModelFour/BinomialDistribution4_qpkmpm.png></p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>pbinom(q = 8, size = 12, prob = 0.85, lower.tail = FALSE)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.9077937</span>
</code></pre></td></tr></table>
</div>
</div><p>or…</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>1-pbinom(q = 8, size = 12, prob = 0.85, lower.tail = TRUE)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.9077937</span>
</code></pre></td></tr></table>
</div>
</div><p>Note the use of lower.tail = FALSE to calculate $Pr(X>8)$. The answer should be .908. Now adding $Pr(X≤8)+Pr(X>8)=.092+.908=1!$ This confirms the total probability rule.</p>
<h4 id=14-what-is-the-probability-that-the-vaccine-will-work-for-between-9-to-11-people>1.4. What is the probability that the vaccine will work for between 9 to 11 people?</h4>
<p>$$Pr(a \leq k \leq b)$$</p>
<p>Now this is a little tricky. We are asked to find $Pr(9≤X≤11)$. Let’s visualise it.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968638/MATH1324/ModelFour/BinomialDistribution5_vwup2q.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968638/MATH1324/ModelFour/BinomialDistribution5_vwup2q.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968638/MATH1324/ModelFour/BinomialDistribution5_vwup2q.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968638/MATH1324/ModelFour/BinomialDistribution5_vwup2q.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968638/MATH1324/ModelFour/BinomialDistribution5_vwup2q.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617968638/MATH1324/ModelFour/BinomialDistribution5_vwup2q.png></p>
<p>We could just add, $Pr(X=9)+Pr(X=10)+Pr(X=11)$. That’s a perfectly acceptable answer.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>dbinom(x = 9:11, size = 12, prob = .85) %&gt;% sum()
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.7655519</span>
</code></pre></td></tr></table>
</div>
</div><p>We can also use some tricky subtraction:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>pbinom(11, 12, 0.85, lower.tail = TRUE) - pbinom(8, 12, 0.85, lower.tail = TRUE)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.7655519</span>
</code></pre></td></tr></table>
</div>
</div><p>This formula takes the cumulative probability, Pr(X≤11) and subtracts Pr(X≤8). The probability left over includes Pr(9≤X≤11).</p>
<h4 id=15-what-is-the-expected-value-and-standard-deviation-of-the-binomial-distribution-with-n12-p085>1.5. What is the expected value and standard deviation of the binomial distribution with n=12, p=0.85?</h4>
<p>$$ E(x) & Var(x) $$</p>
<p>Looking back at the formula, we can write some quick R code to answer this question. First we create two objects called n and p. We assign the parameters from the example to these objects.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>n</span> <span class=o>&lt;-</span> <span class=m>12</span>
<span class=n>p</span> <span class=o>&lt;-</span> <span class=m>0.85</span>
</code></pre></td></tr></table>
</div>
</div><p>Now we can call these objects into our formula.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1># Mean or expected value</span>
<span class=go>n*p
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 10.2</span>
<span class=gp>#</span><span class=c1># SD</span>
<span class=go>sqrt(n*p*(1-p))
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 1.236932</span>
</code></pre></td></tr></table>
</div>
</div><p>The advantage of this approach is if we need to change n and p to work on a different example. We simply change the object values (e.g. n &lt;- 50, p &lt;- 0.5) and re-run the formula. There is no need to rewrite the values into the formula. This can save a lot of time in the long run.</p>
<h3 id=poisson-distribution>Poisson Distribution</h3>
<p>The Poisson distribution is used to model the occurrence of discrete events over a specific period of time, t. The Poisson distribution has one parameter, $λ$, which is the expected, E(x), or mean, $μ$, number of events in a unit of time. For example, the expected daily number of patients for a doctor during winter might be $λ=16$. $λ$ can be adjusted to take into account different time periods using $μ=λt$. For example, the mean number of patients for the same doctor over a week in winter is $μ=λt=16∗7=112$. This assumes $λ$ is time constant. The mean, $μ$, and variance, $σ2$, of a Poisson random variable is simply $λ$. The Poisson distribution has the following probability mass function:</p>
<p>$$Pr(X = k) = \frac{e^{-\mu}\mu^k}{k!}$$</p>
<p>where, k = the number of occurrences, e = the exponential function, and ! is a factorial.</p>
<h4 id=-ex--varx->$$ E(x) & Var(x) $$</h4>
<p>The mean, μ,or expected value, E(X), variance, $\sigma^2$, and standard deviation, $\sigma$, for a Poisson distributed variable are as follows:</p>
<ul>
<li>$\mu = E(X) = \lambda$</li>
<li>$\sigma^2 = Var(X) = \lambda$</li>
<li>$\sigma = \sqrt{\lambda}$</li>
</ul>
<p>We will work through some Poisson problems using R.</p>
<h5 id=21-what-is-the-probability-the-doctor-will-see-exactly-16-patients-in-a-given-day>2.1. What is the probability the doctor will see exactly 16 patients in a given day?</h5>
<p>$$Pr(X = x)$$</p>
<p>This is a simple one. We need to find $Pr(X=16)$. The red area in the following plot highlights the probability visually. The plot represents a PMF of the Poisson distribution with $\lambda = 16$.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617970344/MATH1324/ModelFour/PoissonDistribution1_blns7v.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617970344/MATH1324/ModelFour/PoissonDistribution1_blns7v.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617970344/MATH1324/ModelFour/PoissonDistribution1_blns7v.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617970344/MATH1324/ModelFour/PoissonDistribution1_blns7v.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617970344/MATH1324/ModelFour/PoissonDistribution1_blns7v.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617970344/MATH1324/ModelFour/PoissonDistribution1_blns7v.png></p>
<p>In R, use the dpois(x, lambda) function, which has the following options:</p>
<ul>
<li><strong>x</strong>: This is the x value you want to look up under the Poisson distribution</li>
<li><strong>lambda</strong>: This the mean rate over time, $\mu$</li>
</ul>
<p>Therefore, we use the following formula:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>dpois(x = 16, lambda = 16)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.09921753</span>
</code></pre></td></tr></table>
</div>
</div><p>The function dpois() computes the probability of observing a particular number of occurrences for a Poisson distribution. The answer to question 1 is Pr(X=16)=.099. We can use the following code to replicate the visualisation above:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=c1>## Set Poisson parameters. </span>

<span class=n>lambda</span> <span class=o>&lt;-</span> <span class=m>16</span>
<span class=n>time_multiplier</span> <span class=o>&lt;-</span> <span class=m>1</span>
<span class=n>mu</span> <span class=o>&lt;-</span> <span class=n>lambda</span><span class=o>*</span><span class=n>time_multiplier</span>

<span class=c1>## Define PMF to highlight - Pr(X &lt; x), Pr(X &gt; x), or Pr(a &lt; x &lt; b)</span>
<span class=c1>## Leave blank &#34;&#34; for no highlights</span>
<span class=n>x</span> <span class=o>&lt;-</span> <span class=m>16</span>
<span class=n>a</span> <span class=o>&lt;-</span> <span class=s>&#34;&#34;</span>
<span class=n>b</span> <span class=o>&lt;-</span> <span class=s>&#34;&#34;</span>

<span class=c1>## Set sequence of x values to plot</span>
<span class=n>Events</span> <span class=o>&lt;-</span> <span class=nf>seq</span><span class=p>(</span><span class=nf>ifelse</span><span class=p>(</span><span class=nf>sign</span><span class=p>(</span><span class=nf>round</span><span class=p>(</span><span class=n>mu</span><span class=o>-</span><span class=nf>sqrt</span><span class=p>(</span><span class=n>mu</span><span class=p>)</span><span class=o>*</span><span class=m>4</span><span class=p>,</span><span class=m>0</span><span class=p>))</span><span class=o>==</span><span class=m>-1</span><span class=p>,</span><span class=m>0</span><span class=p>,</span>
                     <span class=nf>round</span><span class=p>(</span><span class=n>mu</span><span class=o>-</span><span class=nf>sqrt</span><span class=p>(</span><span class=n>mu</span><span class=p>)</span><span class=o>*</span><span class=m>4</span><span class=p>,</span><span class=m>0</span><span class=p>)),</span>
              <span class=nf>round</span><span class=p>(</span><span class=n>mu</span><span class=o>+</span><span class=nf>sqrt</span><span class=p>(</span><span class=n>mu</span><span class=p>)</span><span class=o>*</span><span class=m>4</span><span class=p>,</span><span class=m>0</span><span class=p>))</span>

<span class=c1>## Calculate PMF</span>
<span class=n>PMF</span> <span class=o>&lt;-</span> <span class=nf>dpois</span><span class=p>(</span><span class=n>x</span> <span class=o>=</span> <span class=n>Events</span><span class=p>,</span> <span class=n>lambda</span> <span class=o>=</span> <span class=n>mu</span><span class=p>)</span>

<span class=c1>## Define points to highlight in plot</span>

<span class=n>highlight</span> <span class=o>&lt;-</span> <span class=nf>ifelse</span><span class=p>(</span><span class=n>Events</span> <span class=o>&lt;=</span> <span class=n>b</span> <span class=o>&amp;</span> 
                      <span class=n>Events</span> <span class=o>&gt;=</span> <span class=n>a</span> <span class=o>|</span>
                      <span class=n>Events</span> <span class=o>==</span> <span class=n>x</span><span class=p>,</span> <span class=s>&#34;red&#34;</span><span class=p>,</span> <span class=s>&#34;blue&#34;</span><span class=p>)</span>

<span class=c1>## Plot PMF</span>
<span class=nf>plot</span><span class=p>(</span><span class=n>Events</span><span class=p>,</span> <span class=n>PMF</span><span class=p>,</span> <span class=n>type</span> <span class=o>=</span> <span class=s>&#34;p&#34;</span><span class=p>,</span> 
     <span class=n>main</span> <span class=o>=</span> <span class=nf>paste</span><span class=p>(</span><span class=s>&#34;Poisson Distribution, Mean = &#34;</span><span class=p>,</span><span class=n>mu</span><span class=p>),</span> <span class=n>col</span> <span class=o>=</span> <span class=n>highlight</span><span class=p>)</span>
<span class=nf>lines</span><span class=p>(</span><span class=n>Events</span><span class=p>,</span> <span class=n>PMF</span><span class=p>,</span> <span class=n>type</span> <span class=o>=</span> <span class=s>&#34;h&#34;</span><span class=p>,</span> <span class=n>col</span> <span class=o>=</span> <span class=n>highlight</span><span class=p>)</span>
<span class=nf>grid</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><h5 id=22-what-is-the-probability-the-doctor-will-see-12-or-less-patients-in-a-given-day>2.2. What is the probability the doctor will see 12 or less patients in a given day?</h5>
<p>$$Pr(X \leq x)$$</p>
<p>This time we’re asked $Pr(X ≤ 12)$. Visually…</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617970878/MATH1324/ModelFour/PoissonDistribution2_pfd6vj.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617970878/MATH1324/ModelFour/PoissonDistribution2_pfd6vj.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617970878/MATH1324/ModelFour/PoissonDistribution2_pfd6vj.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617970878/MATH1324/ModelFour/PoissonDistribution2_pfd6vj.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617970878/MATH1324/ModelFour/PoissonDistribution2_pfd6vj.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617970878/MATH1324/ModelFour/PoissonDistribution2_pfd6vj.png></p>
<p>In R…</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>ppois(q = 12, lambda = 16)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.1931215</span>
</code></pre></td></tr></table>
</div>
</div><p>Notice that we need to use the function ppois(), which gives $Pr(X &lt;= x)$, rather than the earlier function dpois(), to solve for the cumulative probability, CMF, of the doctor seeing 0 to 12 patients in a given day. Remember the difference between these two functions. Visually, the Poisson CMF looks like the following:</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971039/MATH1324/ModelFour/PoissonDistribution3_v3ji5d.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971039/MATH1324/ModelFour/PoissonDistribution3_v3ji5d.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971039/MATH1324/ModelFour/PoissonDistribution3_v3ji5d.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971039/MATH1324/ModelFour/PoissonDistribution3_v3ji5d.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971039/MATH1324/ModelFour/PoissonDistribution3_v3ji5d.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971039/MATH1324/ModelFour/PoissonDistribution3_v3ji5d.png></p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=c1>## Set Poisson parameters. </span>
<span class=nf>Pr</span><span class=p>(</span><span class=m>8</span> <span class=n>\leq</span> <span class=n>X</span> <span class=n>\leq</span> <span class=m>24</span><span class=p>)</span> <span class=o>=</span> <span class=m>0.968</span>
<span class=n>lambda</span> <span class=o>&lt;-</span> <span class=m>16</span>
<span class=n>time_multiplier</span> <span class=o>&lt;-</span> <span class=m>1</span>
<span class=n>mu</span> <span class=o>&lt;-</span> <span class=n>lambda</span><span class=o>*</span><span class=n>time_multiplier</span>

<span class=c1>## Define PMF to highlight - Pr(X &lt; x), Pr(X &gt; x), or Pr(a &lt; x &lt; b)</span>
<span class=c1>## Leave blank &#34;&#34; for no highlights</span>
<span class=n>x</span> <span class=o>&lt;-</span> <span class=s>&#34;&#34;</span>
<span class=n>a</span> <span class=o>&lt;-</span> <span class=m>0</span>
<span class=n>b</span> <span class=o>&lt;-</span> <span class=m>12</span>

<span class=c1>## Set sequence of x values to plot</span>
<span class=n>Events</span> <span class=o>&lt;-</span> <span class=nf>seq</span><span class=p>(</span><span class=nf>ifelse</span><span class=p>(</span><span class=nf>sign</span><span class=p>(</span><span class=nf>round</span><span class=p>(</span><span class=n>mu</span><span class=o>-</span><span class=nf>sqrt</span><span class=p>(</span><span class=n>mu</span><span class=p>)</span><span class=o>*</span><span class=m>4</span><span class=p>,</span><span class=m>0</span><span class=p>))</span><span class=o>==</span><span class=m>-1</span><span class=p>,</span><span class=m>0</span><span class=p>,</span>
                     <span class=nf>round</span><span class=p>(</span><span class=n>mu</span><span class=o>-</span><span class=nf>sqrt</span><span class=p>(</span><span class=n>mu</span><span class=p>)</span><span class=o>*</span><span class=m>4</span><span class=p>,</span><span class=m>0</span><span class=p>)),</span>
              <span class=nf>round</span><span class=p>(</span><span class=n>mu</span><span class=o>+</span><span class=nf>sqrt</span><span class=p>(</span><span class=n>mu</span><span class=p>)</span><span class=o>*</span><span class=m>4</span><span class=p>,</span><span class=m>0</span><span class=p>))</span>

<span class=c1>## Calculate CMF</span>
<span class=n>CMF</span> <span class=o>&lt;-</span> <span class=nf>ppois</span><span class=p>(</span><span class=n>q</span> <span class=o>=</span> <span class=n>Events</span><span class=p>,</span> <span class=n>lambda</span> <span class=o>=</span> <span class=n>mu</span><span class=p>)</span>

<span class=c1>## Define points to highlight in plot</span>

<span class=n>highlight</span> <span class=o>&lt;-</span> <span class=nf>ifelse</span><span class=p>(</span><span class=n>Events</span> <span class=o>&lt;=</span> <span class=n>b</span> <span class=o>&amp;</span> 
                      <span class=n>Events</span> <span class=o>&gt;=</span> <span class=n>a</span> <span class=o>|</span>
                      <span class=n>Events</span> <span class=o>==</span> <span class=n>x</span><span class=p>,</span> <span class=s>&#34;red&#34;</span><span class=p>,</span> <span class=s>&#34;blue&#34;</span><span class=p>)</span>

<span class=c1>## Plot PMF</span>
<span class=nf>plot</span><span class=p>(</span><span class=n>Events</span><span class=p>,</span> <span class=n>CMF</span><span class=p>,</span> <span class=n>type</span> <span class=o>=</span> <span class=s>&#34;p&#34;</span><span class=p>,</span> 
     <span class=n>main</span> <span class=o>=</span> <span class=nf>paste</span><span class=p>(</span><span class=s>&#34;Poisson Distribution, Mean = &#34;</span><span class=p>,</span><span class=n>mu</span><span class=p>),</span> <span class=n>col</span> <span class=o>=</span> <span class=n>highlight</span><span class=p>)</span>
<span class=nf>lines</span><span class=p>(</span><span class=n>Events</span><span class=p>,</span> <span class=n>CMF</span><span class=p>,</span> <span class=n>type</span> <span class=o>=</span> <span class=s>&#34;h&#34;</span><span class=p>,</span> <span class=n>col</span> <span class=o>=</span> <span class=n>highlight</span><span class=p>)</span>
<span class=nf>grid</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><h5 id=23-what-is-the-probability-that-the-doctor-will-see-less-than-or-equal-to-100-patients-in-a-week>2.3. What is the probability that the doctor will see less than or equal to 100 patients in a week?</h5>
<p>We need to adjust the mean value to $\mu = 16*7 = 112$. The questions asks $Pr(X≤100)$. Visually…</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971269/MATH1324/ModelFour/PoissonDistribution4_icnsj0.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971269/MATH1324/ModelFour/PoissonDistribution4_icnsj0.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971269/MATH1324/ModelFour/PoissonDistribution4_icnsj0.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971269/MATH1324/ModelFour/PoissonDistribution4_icnsj0.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971269/MATH1324/ModelFour/PoissonDistribution4_icnsj0.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971269/MATH1324/ModelFour/PoissonDistribution4_icnsj0.png></p>
<p>Using R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>ppois(q = 100, lambda = 16*7)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.1378483</span>
</code></pre></td></tr></table>
</div>
</div><p>The answer will be Pr(X≤100)=.138.</p>
<h5 id=24-what-is-the-probability-that-the-doctor-will-see-more-than-25-patients-in-a-day>2.4. What is the probability that the doctor will see more than 25 patients in a day?</h5>
<p>$$Pr(X > x)$$</p>
<p>This time we are asked Pr(X>25). Visually…</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971398/MATH1324/ModelFour/PoissonDistribution5_dlt4tk.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971398/MATH1324/ModelFour/PoissonDistribution5_dlt4tk.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971398/MATH1324/ModelFour/PoissonDistribution5_dlt4tk.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971398/MATH1324/ModelFour/PoissonDistribution5_dlt4tk.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971398/MATH1324/ModelFour/PoissonDistribution5_dlt4tk.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971398/MATH1324/ModelFour/PoissonDistribution5_dlt4tk.png></p>
<p>We can solve this by solving $Pr(X > 25) = 1 - Pr( X \leq 25$.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>1 - ppois(q = 25, lambda = 16)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.01311856</span>
</code></pre></td></tr></table>
</div>
</div><p>or…</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>ppois(q = 25, lambda = 16, lower.tail = FALSE)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.01311856</span>
</code></pre></td></tr></table>
</div>
</div><p>The probability is very small at Pr(X>25)=.013.</p>
<h5 id=25-what-is-the-probability-that-the-doctor-will-see-between-8-to-24-patients-in-a-given-day>2.5. What is the probability that the doctor will see between 8 to 24 patients in a given day?</h5>
<p>$$Pr(a \leq X \leq b)$$</p>
<p>This is a little tricky. We need to find $Pr(8 \leq X \leq 24)$. Visually…</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971597/MATH1324/ModelFour/PoissonDistribution6_cxsbds.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971597/MATH1324/ModelFour/PoissonDistribution6_cxsbds.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971597/MATH1324/ModelFour/PoissonDistribution6_cxsbds.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971597/MATH1324/ModelFour/PoissonDistribution6_cxsbds.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971597/MATH1324/ModelFour/PoissonDistribution6_cxsbds.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617971597/MATH1324/ModelFour/PoissonDistribution6_cxsbds.png></p>
<p>We could just add $Pr(X = 8) + Pr(X = 9) + &mldr; + Pr(X = 24)$. However, this is a little slow. Try…</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>ppois(q = 24, lambda = 16) - ppois(q = 7, lambda = 16)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.9676847</span>
</code></pre></td></tr></table>
</div>
</div><p>Much quicker! The answer is found to be $Pr(8 \leq X \leq 24) = 0.968$. The reason we put x=7 into the second part of the formula is that we want to include $Pr(X=8)$ in the left over cumulative probability.</p>
<h3 id=normal-distribution>Normal Distribution</h3>
<p>The continuous, normal, or Gaussian, distribution is ubiquitous in the field of statistics. Many random variables exhibit a normal distribution shape or, at least, do so approximately. Continuous variables that are known to have a normal distribution make determining the probability of certain events easy to calculate. Probabilities for normal distributions can be readily obtained from tables in the back of most statistics textbooks or functions built into spreadsheets and statistical packages. We will focus on using technology to calculate these probabilities.</p>
<p>To illustrate the application of the normal distribution, we will consider looking at an example involving IQ or “intelligence” scores. IQ scores are believed to have a normal distribution in the population. Most people score close to the average, while few people score really low (e.g. those with learning disabilities) or really high (e.g. geniuses). The normal distribution has two parameters, a mean, $\mu$, and a standard deviation, $\sigma$. For IQ we would denote the theoretical normal distribution as follows:</p>
<p>$$IQ \sim N(\mu, \sigma) \sim N(100,15)$$</p>
<p>The following info-graphic shows the theoretical normal distribution of IQ scores. The shaded areas refer to 1 standard deviation, $\sigma$. Normal distributions have very specific properties. As you can see from the info graphic, 68% of a normal distribution falls within 1 standard deviation of the mean, $85&lt;x&lt;115$. From 1 to 2 standard deviations, $115&lt;x&lt;130$, 13.5% of values will fall. As the normal distribution is perfectly symmetric, we can also see that 13.5% of values will fall between -1 and -2 standard deviations, $70&lt;x&lt;85$. We also have 2.5% of values falling beyond 2 and -2 standard deviations, $x&lt;70$ and $x>130$.</p>
<p>Note that for continuous distributions, there is no distinction between $Pr(X&lt;x)$ and $(X \leq x)$. These two statements are the same because for a continuous distribution the exact probability $Pr(X=x)$ always equals 0. This course will always use the &lt; sign in place of $\leq$ because &lt; is quicker to type!</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617972688/MATH1324/ModelFour/NormalDistribution1_wyx06z.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617972688/MATH1324/ModelFour/NormalDistribution1_wyx06z.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617972688/MATH1324/ModelFour/NormalDistribution1_wyx06z.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617972688/MATH1324/ModelFour/NormalDistribution1_wyx06z.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617972688/MATH1324/ModelFour/NormalDistribution1_wyx06z.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617972688/MATH1324/ModelFour/NormalDistribution1_wyx06z.png></p>
<p>So assuming IQ scores are theoretically normally distributed in the population, what types of questions can we answer? Let’s work through some examples to get an idea. Along the way, we will look at using simple functions in R to quickly and effectively answer these questions.</p>
<h4 id=1-what-is-the-probability-that-a-random-person-from-the-population-will-have-an-iq-score-less-than-80>1. What is the probability that a random person from the population will have an IQ score less than 80?</h4>
<p>The question is asking $Pr(X&lt;80)$. We use X to represent a measurement for a random variable. If we plot the theoretical normal distribution and shade the area red that represents this probability, it would look like the following:</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617972805/MATH1324/ModelFour/NormalDistribution2_xobufv.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617972805/MATH1324/ModelFour/NormalDistribution2_xobufv.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617972805/MATH1324/ModelFour/NormalDistribution2_xobufv.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617972805/MATH1324/ModelFour/NormalDistribution2_xobufv.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617972805/MATH1324/ModelFour/NormalDistribution2_xobufv.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617972805/MATH1324/ModelFour/NormalDistribution2_xobufv.png></p>
<p>So what’s the best way to find this probability? Use the built in functions of R. Specifically, we will use the function, pnorm(q, mean , sd , lower.tail = TRUE). This function has the following arguments:</p>
<ul>
<li><strong>q</strong>: This is the value you want to look up under the normal distribution.</li>
<li><strong>mean</strong>: The population mean.</li>
<li><strong>sd</strong>: The population standard deviation (don’t confuse this with the variance).</li>
<li><strong>lower.tail</strong>: If TRUE = Pr(X&lt;x), the cumulative probability up to x . If false, Pr(X>x) will be returned. TRUE is used by default, so it’s often ignored.
Therefore, in R, we use the formula:</li>
</ul>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>pnorm(q = 80, mean = 100, sd = 15)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.09121122</span>
</code></pre></td></tr></table>
</div>
</div><p>We find Pr(X&lt;80)=0.091. This means we have a 9.1% chance of randomly selecting a person with an IQ below 80. To reproduce the plot see the code at the end of this section (It’s rather long).</p>
<h4 id=2-what-is-the-probability-that-you-will-randomly-select-a-person-from-the-population-with-an-iq-score-above-110>2. What is the probability that you will randomly select a person from the population with an IQ score above 110?</h4>
<p>$$Pr(X > x)$$</p>
<p>This time we need to find Pr(X > 110). Visually…</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617973090/MATH1324/ModelFour/NormalDistribution3_yb41ns.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617973090/MATH1324/ModelFour/NormalDistribution3_yb41ns.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617973090/MATH1324/ModelFour/NormalDistribution3_yb41ns.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617973090/MATH1324/ModelFour/NormalDistribution3_yb41ns.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617973090/MATH1324/ModelFour/NormalDistribution3_yb41ns.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617973090/MATH1324/ModelFour/NormalDistribution3_yb41ns.png></p>
<p>One way to solve this is to use the rule that Pr(X>x) = 1 − Pr(X&lt;x). In R, we would write the formula as either:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>1 - pnorm(q = 110, mean = 100, sd = 15)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.2524925</span>
</code></pre></td></tr></table>
</div>
</div><p>or…</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>pnorm(q = 110, mean = 100, sd = 15, lower.tail = FALSE)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.2524925</span>
</code></pre></td></tr></table>
</div>
</div><p>Note the use of lower.tail = FALSE in the second formula. This reports Pr(X>110). The answer was found to be Pr(X>110)=.252.</p>
<h4 id=3-what-is-the-probability-that-a-randomly-selected-person-from-the-population-will-have-an-iq-score-within-one-standard-deviation-from-the-mean>3. What is the probability that a randomly selected person from the population will have an IQ score within one standard deviation from the mean?</h4>
<p>$$Pr(a &lt; x &lt; b)$$</p>
<p>The population standard deviation is 15 points, therefore, we need to find Pr(85&lt;X&lt;115). Visually…
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617973356/MATH1324/ModelFour/NormalDistribution4_x8hpud.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617973356/MATH1324/ModelFour/NormalDistribution4_x8hpud.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617973356/MATH1324/ModelFour/NormalDistribution4_x8hpud.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617973356/MATH1324/ModelFour/NormalDistribution4_x8hpud.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617973356/MATH1324/ModelFour/NormalDistribution4_x8hpud.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617973356/MATH1324/ModelFour/NormalDistribution4_x8hpud.png></p>
<p>This is getting a little tricky. We can solve this by first calculating Pr(X&lt;115). We then calculate Pr(X&lt;85). If we subtract Pr(X&lt;85) from Pr(X&lt;115), we are left with Pr(85&lt;X&lt;115). This gives us the following useful formula:</p>
<p>$$Pr(a &lt; x &lt; b) = Pr(X &lt; b) - Pr(X &lt; a)$$</p>
<p>In R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>pnorm(q = 115, mean = 100, sd = 15) - pnorm(q = 85, mean = 100, sd = 15)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.6826895</span>
</code></pre></td></tr></table>
</div>
</div><p>The answer is Pr(85&lt;X&lt;115)=.683. Now look back at the info-graphic. Therefore, there is a 68.3% chance that a person’s IQ score will be within one standard deviation from the mean. Simple! Well, sort of…</p>
<h4 id=find-x-given-percentile>Find X given percentile</h4>
<ol start=4>
<li>A random person is selected from the population and their IQ is found to be in the 90th percentile. What was their IQ?</li>
</ol>
<p>This is a different question again. We are given a percentile and asked to find the person’s actual IQ. Scoring in the 90th percentile means that a person scored equal to or better than 90% of other people in the population. Therefore, we need to solve for x, in Pr(X&lt;x)=.9. We need to use a different formula in R. The formula in question is qnorm(p, mean, sd, lower.tail = TRUE/FALSE), which has four arguments.</p>
<ul>
<li><strong>p</strong>: This is the cumulative probability Pr(X &lt; x).</li>
<li><strong>mean</strong>: The population mean.</li>
<li><strong>sd</strong>: This is the population standard deviation (don’t confuse this with the variance).</li>
<li><strong>lower.tail</strong>: If TRUE = Pr(X&lt;x), the cumulative probability up to x . If FALSE, Pr(X>x), TRUE is set by default if left blank.</li>
</ul>
<p>To answer the question, we complete the formula as follows:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>qnorm(p = 0.9, mean = 100, sd = 15)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 119.2233</span>
</code></pre></td></tr></table>
</div>
</div><p>Rounding the answer to a whole number, we find Pr(X&lt;119)=.9. Therefore, if a person scored in the 90th percentile, their IQ was 119.</p>
<h4 id=find-b-given-a-and-percentile>Find b given a and percentile</h4>
<ol start=5>
<li>You are told that 95% of the population’s IQ scores fall between a score of 71 and an unsolved upper value. What is the upper value?</li>
</ol>
<p>The question asks Pr(71&lt;X&lt;b)=.95. This one is also quite tricky. Let’s have a think… We can find Pr(X>71)=.973, which tells us how much probability is above a score of 71.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>1 - pnorm(q = 71, mean = 100, sd = 15)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.9734024</span>
</code></pre></td></tr></table>
</div>
</div><p>or…</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>pnorm(q = 71, mean = 100, sd = 15, lower.tail = FALSE)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.9734024</span>
</code></pre></td></tr></table>
</div>
</div><p>This means that there is .973−.95=.023 probability left above the upper value x, or Pr(X>x)=.023. This x value is the answer to our question. To find this x value, we use:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>qnorm(p = 1 - .023, mean = 100, sd = 15)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 129.9309</span>
</code></pre></td></tr></table>
</div>
</div><p>Note how we have used 1−.023, which corresponds to the 97.7th percentile. The answer to the above formula is Pr(71&lt;X&lt;130)=.95. Visually, the red shaded area corresponds to .95 probability.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617974230/MATH1324/ModelFour/NormalDistribution5_iu4lip.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617974230/MATH1324/ModelFour/NormalDistribution5_iu4lip.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617974230/MATH1324/ModelFour/NormalDistribution5_iu4lip.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617974230/MATH1324/ModelFour/NormalDistribution5_iu4lip.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617974230/MATH1324/ModelFour/NormalDistribution5_iu4lip.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1617974230/MATH1324/ModelFour/NormalDistribution5_iu4lip.png></p>
<p>We can check our answer using the formula:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>pnorm(q = 130, mean = 100, sd = 15) - pnorm(q = 71, mean = 100, sd = 15)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.9506523</span>
</code></pre></td></tr></table>
</div>
</div><p>The answer is confirmed to be .95! Phew, that one was getting tricky.</p>
<h3 id=the-standard-normal-z-distribution>The Standard Normal Z-Distribution</h3>
<p>The standard normal z-distribution is sometimes used in statistics as it allows for probabilities to be looked up using standard tables available in textbooks. We need to know a little bit about the z-distribution, particularly the concept of standardisation, as it appears in a number of other modules. The standard normal distribution has the following properties:</p>
<p>$$z \sim N(0,1)$$</p>
<p>where z refers to a standard normal variable. Let’s look at an example. Thinking back to IQ scores, we can convert IQ scores to a standard normal variable using the equation:</p>
<p>$$z = \frac{x - \mu}{\sigma}$$</p>
<p>The z-score divides the difference between an x value and the mean by a population standard deviation. Therefore, z scores are standard deviations. So, suppose we are asked to find Pr(X>110) using the standard normal distribution. First, we convert the IQ variable, x, to z, i.e. a z-score or standard deviation.</p>
<p>$$z = \frac{x - \mu}{\sigma} = \frac{110 - 100}{15} = \frac{10}{15} = .667$$</p>
<p>Therefore, an IQ score of 110 sits .667 standard deviations above the mean of 100. Simple!</p>
<p>Now we can find Pr(Z>.667) using the pnorm() function in R.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>1 - pnorm(q = .667, mean = 0, sd = 1)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.2523861</span>
</code></pre></td></tr></table>
</div>
</div><p>or…</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>pnorm(q = .667, mean = 0, sd = 1, lower.tail = FALSE)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.2523861</span>
</code></pre></td></tr></table>
</div>
</div><p>We find Pr(X>110)=0.252. You will find the answer to be exactly the same as when we used:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>1 - pnorm(q = 110, mean = 100, sd = 15) 
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.2524925</span>
</code></pre></td></tr></table>
</div>
</div><p>or</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=go>pnorm(q = 110, mean = 100, sd = 15, lower.tail = FALSE)
</span><span class=go></span><span class=gp>#</span><span class=c1>## [1] 0.2524925</span>
</code></pre></td></tr></table>
</div>
</div><p>You will need to use standardisation techniques throughout the course. This section has aimed to give you a heads up. There is nothing special about the z-distribution. It’s just a way to standardise a variable so that common probability tables can used. To convert a z-score back to its original x value use the following equation:</p>
<p>$$x = \mu + \sigma{}z$$</p>
<p>E.g…</p>
<p>$$x=100+15(.667)=110$$</p>
<h4 id=normal-distribution-visualisation-code>Normal Distribution Visualisation Code</h4>
<p>This is the code used to create the visualisations of the normal distribution.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=c1>## Set Normal distribution parameters. Use SD, not Var!</span>

<span class=n>mu</span> <span class=o>&lt;-</span> <span class=m>100</span>
<span class=n>sd</span> <span class=o>&lt;-</span> <span class=m>15</span>

<span class=c1>## Set values to highlight</span>
<span class=c1>## x: Pr(x &lt; x) or Pr(X &gt; x)</span>
<span class=c1>## a and b: Pr(a &lt; x &lt; b)</span>

<span class=n>x</span> <span class=o>&lt;-</span> <span class=m>80</span>
<span class=n>a</span> <span class=o>&lt;-</span> <span class=s>&#34;&#34;</span>
<span class=n>b</span> <span class=o>&lt;-</span> <span class=s>&#34;&#34;</span>

<span class=c1>## Highlight area under curve - Pr(X &lt; x) = &#34;less&#34;,</span>
<span class=c1>## Pr(X &gt; x) = &#34;greater&#34;, Pr(a &lt; x &lt; b) = &#34;between&#34;</span>

<span class=n>area</span> <span class=o>&lt;-</span> <span class=s>&#34;less&#34;</span>

<span class=c1>## Define area to highlight</span>

<span class=nf>if </span><span class=p>(</span><span class=n>area</span> <span class=o>==</span> <span class=s>&#34;less&#34;</span><span class=p>)</span> <span class=p>{</span>
  <span class=n>auc</span> <span class=o>&lt;-</span> <span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=nf>dnorm</span><span class=p>(</span><span class=nf>seq</span><span class=p>(</span><span class=n>mu</span><span class=o>-</span><span class=n>sd</span><span class=o>*</span><span class=m>4</span><span class=p>,</span><span class=n>x</span><span class=p>,</span><span class=n>sd</span><span class=o>*</span><span class=m>0.01</span><span class=p>),</span> <span class=n>mean</span> <span class=o>=</span> <span class=n>mu</span><span class=p>,</span> <span class=n>sd</span> <span class=o>=</span> <span class=n>sd</span><span class=p>),</span><span class=m>0</span><span class=p>)</span>
  <span class=n>x_values</span> <span class=o>&lt;-</span> <span class=nf>c</span><span class=p>(</span><span class=n>mu</span><span class=o>-</span><span class=n>sd</span><span class=o>*</span><span class=m>4</span><span class=p>,</span><span class=nf>seq</span><span class=p>(</span><span class=n>mu</span><span class=o>-</span><span class=n>sd</span><span class=o>*</span><span class=m>4</span><span class=p>,</span><span class=n>x</span><span class=p>,</span><span class=n>sd</span><span class=o>*</span><span class=m>0.01</span><span class=p>),</span><span class=n>x</span><span class=p>)</span>
  <span class=p>}</span> <span class=n>else</span> <span class=p>{</span>
  <span class=nf>if </span><span class=p>(</span><span class=n>area</span> <span class=o>==</span> <span class=s>&#34;greater&#34;</span><span class=p>)</span> <span class=p>{</span>
    <span class=n>auc</span> <span class=o>&lt;-</span> <span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=nf>dnorm</span><span class=p>(</span><span class=nf>seq</span><span class=p>(</span><span class=n>x</span><span class=p>,</span><span class=n>mu</span><span class=o>+</span><span class=n>sd</span><span class=o>*</span><span class=m>4</span><span class=p>,</span><span class=n>sd</span><span class=o>*</span><span class=m>0.01</span><span class=p>),</span> <span class=n>mean</span> <span class=o>=</span> <span class=n>mu</span><span class=p>,</span> <span class=n>sd</span> <span class=o>=</span> <span class=n>sd</span><span class=p>),</span><span class=m>0</span><span class=p>)</span>
    <span class=n>x_values</span> <span class=o>&lt;-</span> <span class=nf>c</span><span class=p>(</span><span class=n>x</span><span class=p>,</span><span class=nf>seq</span><span class=p>(</span><span class=n>x</span><span class=p>,</span><span class=n>mu</span><span class=o>+</span><span class=n>sd</span><span class=o>*</span><span class=m>4</span><span class=p>,</span><span class=n>sd</span><span class=o>*</span><span class=m>0.01</span><span class=p>),</span><span class=n>mu</span><span class=o>+</span><span class=n>sd</span><span class=o>*</span><span class=m>4</span><span class=p>)</span>
  <span class=p>}</span> <span class=n>else</span> <span class=p>{</span>
    <span class=nf>if </span><span class=p>(</span><span class=n>area</span> <span class=o>==</span> <span class=s>&#34;between&#34;</span><span class=p>)</span> <span class=p>{</span>
      <span class=n>auc</span> <span class=o>&lt;-</span> <span class=nf>c</span><span class=p>(</span><span class=m>0</span><span class=p>,</span><span class=nf>dnorm</span><span class=p>(</span><span class=nf>seq</span><span class=p>(</span><span class=n>a</span><span class=p>,</span><span class=n>b</span><span class=p>,</span><span class=n>sd</span><span class=o>*</span><span class=m>0.01</span><span class=p>),</span> <span class=n>mean</span> <span class=o>=</span> <span class=n>mu</span><span class=p>,</span> <span class=n>sd</span> <span class=o>=</span> <span class=n>sd</span><span class=p>),</span><span class=m>0</span><span class=p>)</span>
      <span class=n>x_values</span> <span class=o>&lt;-</span> <span class=nf>c</span><span class=p>(</span><span class=n>a</span><span class=p>,</span><span class=nf>seq</span><span class=p>(</span><span class=n>a</span><span class=p>,</span><span class=n>b</span><span class=p>,</span><span class=n>sd</span><span class=o>*</span><span class=m>0.01</span><span class=p>),</span><span class=n>b</span><span class=p>)</span>
    <span class=p>}</span>
  <span class=p>}</span>
<span class=p>}</span>

<span class=c1>## Create probability statement</span>

<span class=nf>if </span><span class=p>(</span><span class=n>area</span> <span class=o>==</span> <span class=s>&#34;less&#34;</span><span class=p>)</span> <span class=p>{</span>
  <span class=n>prob_statement</span> <span class=o>&lt;-</span> <span class=nf>paste</span><span class=p>(</span><span class=s>&#34;Pr(X &lt; &#34;</span><span class=p>,</span><span class=n>x</span><span class=p>,</span><span class=s>&#34;) = &#34;</span><span class=p>,</span> <span class=nf>round</span><span class=p>(</span><span class=nf>pnorm</span><span class=p>(</span><span class=n>x</span><span class=p>,</span><span class=n>mu</span><span class=p>,</span><span class=n>sd</span><span class=p>),</span><span class=m>3</span><span class=p>),</span> <span class=n>sep</span> <span class=o>=</span> <span class=s>&#34;&#34;</span><span class=p>)</span>
  <span class=p>}</span> <span class=n>else</span> <span class=p>{</span>
    <span class=nf>if </span><span class=p>(</span><span class=n>area</span> <span class=o>==</span> <span class=s>&#34;greater&#34;</span><span class=p>)</span> <span class=p>{</span>
      <span class=n>prob_statement</span> <span class=o>&lt;-</span> <span class=nf>paste</span><span class=p>(</span><span class=s>&#34;Pr(X &gt; &#34;</span><span class=p>,</span><span class=n>x</span><span class=p>,</span><span class=s>&#34;) = &#34;</span><span class=p>,</span> 
                              <span class=nf>round</span><span class=p>(</span><span class=nf>pnorm</span><span class=p>(</span><span class=n>x</span><span class=p>,</span><span class=n>mu</span><span class=p>,</span><span class=n>sd</span><span class=p>,</span><span class=n>lower.tail</span> <span class=o>=</span> <span class=kc>FALSE</span><span class=p>),</span><span class=m>3</span><span class=p>),</span> <span class=n>sep</span> <span class=o>=</span> <span class=s>&#34;&#34;</span><span class=p>)</span>
      <span class=p>}</span> <span class=n>else</span> <span class=p>{</span>
        <span class=nf>if </span><span class=p>(</span><span class=n>area</span> <span class=o>==</span> <span class=s>&#34;between&#34;</span><span class=p>)</span> <span class=p>{</span>
          <span class=n>prob_statement</span> <span class=o>&lt;-</span> <span class=nf>paste</span><span class=p>(</span><span class=s>&#34;Pr(&#34;</span><span class=p>,</span><span class=n>a</span><span class=p>,</span><span class=s>&#34; &lt; x &lt; &#34;</span><span class=p>,</span><span class=n>b</span><span class=p>,</span><span class=s>&#34;) = &#34;</span><span class=p>,</span> 
                                  <span class=nf>round</span><span class=p>(</span><span class=nf>pnorm</span><span class=p>(</span><span class=n>b</span><span class=p>,</span><span class=n>mu</span><span class=p>,</span><span class=n>sd</span><span class=p>)</span> <span class=o>-</span> <span class=nf>pnorm</span><span class=p>(</span><span class=n>a</span><span class=p>,</span><span class=n>mu</span><span class=p>,</span><span class=n>sd</span><span class=p>),</span><span class=m>3</span><span class=p>),</span> <span class=n>sep</span> <span class=o>=</span> <span class=s>&#34;&#34;</span><span class=p>)}</span>
        <span class=n>else</span> <span class=p>{</span>
          <span class=n>prob_statement</span> <span class=o>&lt;-</span> <span class=s>&#34;&#34;</span>
        <span class=p>}</span>
      <span class=p>}</span>
  <span class=p>}</span>


<span class=c1>## Plot density</span>
<span class=nf>curve</span><span class=p>(</span><span class=n>expr</span> <span class=o>=</span> <span class=nf>dnorm</span><span class=p>(</span><span class=n>x</span><span class=p>,</span><span class=n>mu</span><span class=p>,</span><span class=n>sd</span><span class=p>),</span> 
      <span class=n>xlim</span> <span class=o>=</span> <span class=nf>c</span><span class=p>(</span><span class=n>mu</span><span class=o>-</span><span class=n>sd</span><span class=o>*</span><span class=m>4</span><span class=p>,</span><span class=n>mu</span><span class=o>+</span><span class=n>sd</span><span class=o>*</span><span class=m>4</span><span class=p>),</span> 
      <span class=n>main</span> <span class=o>=</span> <span class=nf>paste</span><span class=p>(</span><span class=s>&#34;Normal Distribution, Mean = &#34;</span><span class=p>,</span><span class=n>mu</span><span class=p>,</span><span class=s>&#34;, Sigma = &#34;</span><span class=p>,</span><span class=n>sd</span><span class=p>),</span>
      <span class=n>ylab</span> <span class=o>=</span> <span class=s>&#34;Density&#34;</span><span class=p>)</span>
<span class=nf>if </span><span class=p>(</span><span class=n>area</span> <span class=o>!=</span> <span class=s>&#34;&#34;</span><span class=p>)</span> <span class=p>{</span>
  <span class=nf>polygon</span><span class=p>(</span><span class=n>x</span> <span class=o>=</span> <span class=n>x_values</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>auc</span><span class=p>,</span> <span class=n>col</span> <span class=o>=</span> <span class=s>&#34;tomato&#34;</span><span class=p>)</span>
  <span class=nf>text</span><span class=p>(</span><span class=n>x</span> <span class=o>=</span> <span class=n>mu</span><span class=o>-</span><span class=n>sd</span><span class=o>*</span><span class=m>4</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=nf>dnorm</span><span class=p>(</span><span class=n>mu</span><span class=o>-</span><span class=n>sd</span><span class=o>/</span><span class=m>4</span><span class=p>,</span><span class=n>mu</span><span class=p>,</span><span class=n>sd</span><span class=p>),</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>prob_statement</span><span class=p>,</span> <span class=n>pos</span> <span class=o>=</span> <span class=m>4</span><span class=p>)</span>
<span class=p>}</span>
</code></pre></td></tr></table>
</div>
</div><h3 id=module-4---exercises>Module 4 - Exercises</h3>
<p>Complete the following module exercises (Submit your solutions via
Blackboard) before the deadlines in order to obtain a participation mark (1%). The exercises aim to help develop your conceptual understanding and prepare you for the exam. Exam questions will be very similar to the module exercises (except in the exam you won’t be required to use R). Answers are available following submission. Working together in groups is encouraged, but please don’t give away the answers to other a students who haven’t done the work
(they won’t be learning anything!). These exercises are designed to aid your learning.</p>
<ol>
<li>Exercise 1
The risk of females experiencing an anxiety disorder during a given 12-month period is approximately 1 in 5. Suppose a researcher plans to take o a random sample of females and monitor their anxiety over 12 months. Which probability . distribution can be used to model the expected number of females in a sample experiencing an anxiety disorder within this period?</li>
</ol>
<ul>
<li>Binomial distribution</li>
<li>F distribution</li>
<li>Normal distribution</li>
<li>Poisson Distribution</li>
</ul>
<p>Answer: Binomial distribution</p>
<ol start=2>
<li>Exercise 2
If 20 females are randomly sampled, what is the probability that exactly 10 will experience an anxiety disorder during this 12-month period? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>dbinom(x = 10, size = 20, prob = 0.20) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=3>
<li>Exercise 3
If 20 females are randomly sampled, what is the probability that exactly 5 will experience an anxiety disorder? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>dbinom(x = 5, size = 20, prob = 0.20) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=4>
<li>Exercise 4
If 30 females are randomly sampled, what is the probability that exactly 5 will experience an anxiety disorder?</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>dbinom(x = 5, size = 30, prob = 0.20) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=5>
<li>Exercise 5
If 20 females are randomly sampled, what is the probability that 5 or 6 will experience an anxiety disorder? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>dbinom(x = 5:6, size = 20, prob = 0.20) %&gt;% sum() %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=6>
<li>Exercise 6
If 10 females are randomly sampled, what is the probability that 5 or more will experience an anxiety disorder? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>1 - pbinom(q = 4, size = 10, prob = 0.20) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><p>Or,</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pbinom(q = 4, size = 10, prob = 0.20, lower.tail = FALSE) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=7>
<li>Exercise 7
If 20 females are randomly sampled, what is the probability that 2 or more will experience an anxiety disorder? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>1 - pbinom(q = 1, size = 20, prob = 0.20) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><p>Or,</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pbinom(q = 1, size = 20 , prob = 0.20, lower.tail = FALSE) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=8>
<li>Exercise 8
If 20 females are randomly sampled, what is the probability that 5 or less will experience an anxiety disorder? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pbinom(q = 5, size = 20, prob = 0.20) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=9>
<li>Exercise 9
If 30 females are randomly sampled, what is the probability that 10 or less will experience an anxiety disorder? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pbinom(q = 10, size = 30, prob = 0.20) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=10>
<li>Exercise 10
Suppose the average number of people that become victim to a shark attack in Australia each year is 10. Which probability distribution can be used to model the annual expected number of shark attacks in Australia?</li>
</ol>
<ul>
<li>Normal distribution</li>
<li>Binomial distribution</li>
<li>Poisson Distribution</li>
<li>F distribution</li>
</ul>
<p>Answer: Poisson distribution</p>
<ol start=11>
<li>Exercise 11
What is the expected number of shark attacks over a two year period? (Round answer to the nearest whole number)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>2 * 10
</code></pre></td></tr></table>
</div>
</div><ol start=12>
<li>Exercise 12
Assuming the rate of shark attacks in Australia remains constant over time, what is the probability that 10 people will be attacked within a given year? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>dpois(x = 10, lambda = 10) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=13>
<li>Exercise 13
Assuming the rate of shark attacks in Australia remains constant over time, what is the probability that 30 people will be attacked by a shark across two years? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>dpois(x = 30, lambda = 10*2) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=14>
<li>Exercise 14
Assuming the rate of shark attacks remains constant over time, what is the probability that 20 or less will be attacked by a shark within a year? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>ppois(q = 20, lambda = 10) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=15>
<li>Exercise 15
Assuming the rate of shark attacks in Australia remains constant over time, what is the probability that 15 - 20 people will be attacked within a year? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>ppois(q = 20, lambda =10) %&gt;% - ppois(q = 14, lambda = 10) %&gt;% round(3)

</code></pre></td></tr></table>
</div>
</div><ol start=16>
<li>Exercise 16
Assuming rate of shark attacks in Australia remains constant over time, what is the probability that more than 20 people will be attacked within a year? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>1 - ppois(q = 20, lambda = 10) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><p>Or,</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>ppois(q = 20, lambda = 10, lower.tail = FALSE) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=17>
<li>Exercise 17
Assuming the rate of shark attacks remains constant over time, what is the probability that 15 or 17 people will be attacked within a year? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>dpois(x = 15, lambda = 10) %&gt;% + dpois(x = 17, lambda = 10) %&gt;% round(3)

</code></pre></td></tr></table>
</div>
</div><ol start=18>
<li>
<p>Exercise 18
What is the standard deviation of the standard normal distribution?
Answer: 1</p>
</li>
<li>
<p>Exercise 19
What is the mean of the standard normal distribution?
Answer: 0</p>
</li>
<li>
<p>Exercise 20
All symmetric distributions are normal distributions. True or false?</p>
</li>
</ol>
<p>Answer: False - A distribution cannot be normal if it is not symmetric, how
ever, not all symmetric distributions are normal.</p>
<ol start=21>
<li>Exercise 21
Assume body temperature scores are normally distributed in the population with a mean of 36.81°C and a standard deviation of 0.41°C. A person’s body temperature is 37.33°C. Calculate their z -score.
(Round answer to 2 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>((37.33 - 36.81)/0.41) %&gt;% round(2)
</code></pre></td></tr></table>
</div>
</div><ol start=22>
<li>Exercise 22
Calculate the z-score for a person who has a body temperature of 35.72°C. (Round answer to 2 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>((35.72 - 36.81)/0.41) %&gt;% round(2)
</code></pre></td></tr></table>
</div>
</div><ol start=23>
<li>Exercise 23
A person’s z-score for body temperature is calculated to be 2.41. What is their body temperature? (Round answer to 2 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>((2.41 * 0.41) + 36.81) %&gt;% round(2)
</code></pre></td></tr></table>
</div>
</div><ol start=24>
<li>Exercise 24
A person’s z-score for body temperature is calculated to be -1.24. What is their body temperature? (Round answer to 2 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>((-1.24 * 0.41) + 36.81) %&gt;% round(2)
</code></pre></td></tr></table>
</div>
</div><ol start=25>
<li>Exercise 25
If you take a random person from the population, what is the probability their body temperature will be less than 36.39°C? v (Round answer to 2 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pnorm(q = 36.39, mean = 36.81, sd = 0.41) %&gt;% round(2)
</code></pre></td></tr></table>
</div>
</div><ol start=26>
<li>Exercise 26
If you take a random person from the population, what the probability their body temperature will be less than 37.93°C? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pnorm(q = 37.93, mean = 36.81, sd = 0.41) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=27>
<li>Exercise 27
If you take a random person from the population, what is the probability their body temperature will be less than 35.82°C? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pnorm(q = 35.82, mean = 36.81, sd = 0.41) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=28>
<li>Exercise 28
If you take a random person from the population, what is the probability their body temperature will be greater than 36.02°C? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>1 - pnorm(q = 36.02, mean = 36.81, sd = 0.41) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><p>Or,</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pnorm(q = 36.02, mean = 36.81, sd = 0.41, lower.tail = FALSE) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=29>
<li>Exercise 29
If you take a random person from the population, what is the probability their body temperature will be greater than 37.39°C? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>1 - pnorm(q = 37.39, mean = 36.81, sd = 0.41) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pnorm(q = 37.39, mean = 36.81, sd = 0.41, lower.tail = FALSE) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=30>
<li>Exercise 30
If you take a random person from the population, what is the probability their body temperature will be greater than 38°C? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>1 - pnorm(q = 38, mean = 36.81, sd = 0.41) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pnorm(q = 38, mean = 36.81, sd = 0.41, lower.tail = FALSE) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=31>
<li>Exercise 31
If you take a random person from the population, what is the probability their body temperature will be between 36.13°C and 36.64°C? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pnorm(q = 36.64, mean = 36.81, sd = 0.41) %&gt;% - pnorm(q = 36.13, mean = 36.81, sd = 0.41) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=32>
<li>Exercise 32
If you take a random person from the population, what is the probability their body temperature will be between 36.95°C and 37.05°C? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pnorm(q = 37.05, mean = 36.81, sd = 0.41) %&gt;% - pnorm(q = 36.95, mean = 36.81, sd = 0.41) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=33>
<li>Exercise 33
If you take a random i person from the population, what is the probability their body temperature will be between 37.20°C and 37.30°C? (Round answer to 3 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pnorm(q = 37.30, mean = 36.81, sd = 0.41) %&gt;% - pnorm(q = 37.20, mean = 36.81, sd = 0.41) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><ol start=34>
<li>Exercise 34
If you take a random person from the population and find that they scored in the 87th percentile for body temperature, what is their actual body temperature? (Round answer to 2 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>qnorm(p = .87, mean = 36.81, sd = 0.41) %&gt;% round(2)
</code></pre></td></tr></table>
</div>
</div><ol start=35>
<li>Exercise 35
If you take a random person from the population and find that they scored in the 9th percentile for body temperature, what is their actual body temperature? (Round answer to 2 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>qnorm(p = .09, mean = 36.81, sd = 0.41) %&gt;% round(2)
</code></pre></td></tr></table>
</div>
</div><ol start=36>
<li>Exercise 36
A mild fever is defined as a body temperature of 39°C. What percentile does a mild fever correspond to in the normal body temperature population? (Round your a answer to 2 decimal places)</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>pnorm(q = 39, mean = 36.81, sd = 0.41) %&gt;% round(2) * 100
</code></pre></td></tr></table>
</div>
</div><h2 id=module-5-sampling-randomly-representative>Module 5 Sampling: Randomly Representative</h2>
<h3 id=introduction-to-the-module>Introduction to the Module</h3>
<p>This topic is covered in Module 5 of course website. Often a population is immeasurable. Therefore, statistical investigations must often rely on the use of a sample from the population. This module will introduce sampling from populations.</p>
<h3 id=learning-objectives-3>Learning Objectives</h3>
<p>The learning objectives associated with this module are:</p>
<ul>
<li>Describe the purpose of sampling for estimation and inference.</li>
<li>Define and distinguish between different sampling methods.</li>
<li>Define a sampling distribution for a statistic.</li>
<li>Define the expected value and variance of a sampling distribution.</li>
<li>Use technology to simulate and explore the characteristics of sampling distributions.</li>
<li>Define and apply the Central Limit Theorem (CLT).</li>
</ul>
<h3 id=module-video>Module Video</h3>
<p>This a nice video that explains the challenge of sampling in ecology research. The video discusses populations, samples and random samples.</p>
<p>{% youtube nsMWvSuJm08 %}</p>
<h3 id=populations-and-samples>Populations and Samples</h3>
<p>In this module we will dive deeper into the world of inferential statistics first introduced back in Module 1. Recall, statistical inference refers to methods for estimating population parameters using sample data. A <strong>population</strong> is the larger group that a researcher wants to generalise their results to. For example, a researcher may need to know the average battery life for a new model of mobile phone, or estimate the average transfer speeds for a new computer hard disk drive. It would be too expensive or infeasible to test every unit manufactured. Therefore, the researcher must use another method.</p>
<p>A researcher’s confidence in their ability to infer what’s happening in the population comes down to the quality of the sample and quality of the data collected. In this section we will deal with samples. A <strong>sample</strong> is a smaller subset of a population. If the sample is chosen appropriately, it can provide a fairly accurate account of the population. Why do we use samples? Cost, time and practical constraints often make measuring the population impossible. Think back to the mobile phone and hard disk drive example in the previous paragraph. When an entire population is measured, it is called a census. The Australian Bureau of Statistics (ABS) conducts the Australian Census every five years at an estimated cost of $440 million (Based on 2011 Census). As you can understand, this amount of time and money is well beyond the means of most statistical investigations.</p>
<p>There are good and bad ways of gathering samples. Probability-based methods maximise the chances of gathering a randomly representative sample. Common probability-based methods include simple random sampling, cluster sampling and stratified sampling. Non-probability based methods make no effort to ensure the sample is randomly representative. The best example of these types of methods are convenience sampling, purposive sampling, quota sampling and snowballing. Let’s take a closer look at the probability-based methods.</p>
<h3 id=sampling-methods>Sampling Methods</h3>
<h4 id=simple-random-sampling-srs>Simple Random Sampling (SRS)</h4>
<p>In SRS, every unit in a population has an equal chance of being selected. For example, every new model mobile phone manufactured has an equal chance of being selected to undertake a battery test. This is the most simple and effective probability-based sampling method. However, it can be tricky to implement. For example, if we were looking at the population, how do we get a list of every single Australian so you can ensure everyone has an equal chance of being selected? A phone book is a good start, but what about people without landlines? This course will focus mainly on simple random sampling. Watch the following video by Steve Mays for a nice overview of SRS.</p>
<p>{% youtube yx5KZi5QArQ %}</p>
<h4 id=stratified-sampling>Stratified Sampling</h4>
<p>Stratified sampling divides the population into subpopulations, called strata (e.g. gender, age bands, ethnicity), and then takes a SRS from each strata proportional to the strata’s representation in the population. For example, the Australian population is approximately 49% male and 51% female. A stratified sample for gender would divide the population into males and females and then proceed to take SRSs of males and females so the resulting sample is approximately 49:51 male:female. Stratified sampling can be more complex as there is no limit to the number of strata and levels within the strata. For example, a researcher may wish to stratify the population by gender, age bands and ethnicity. This would result in a sample that is more likely to be representative, but would require substantially more time and effort.</p>
<p>{% youtube sYRUYJYOpG0 %}</p>
<h4 id=cluster-sampling>Cluster Sampling</h4>
<p>Cluster sampling first divides the population into naturally occurring and homogeneous clusters, e.g. postcodes, towns, manufacturing batches, factories, etc. The investigator then randomly selects a defined number of clusters. For example, referring back to the hard disk drive example, the company may have manufactured 100 batches of hard disk drives on different days. They may decide to randomly select 10 batches which they define as the clusters. Using these randomly sampled clusters, the investigator would then proceed with the use of SRS within each cluster to select their sample. For example, the investigator might decide to randomly select 10 hard disk drives from each of the 10 batches making a total sample size of 100. Cluster sampling can be more economical and less time-consuming than SRS. This is because the researcher is required to perform SRS only within a limited number of clusters and not the entire population.</p>
<p>{% youtube QOxXy-I6ogs %}</p>
<h4 id=convenience-sampling>Convenience Sampling</h4>
<p>Convenience sampling methods, or non-probabilistic sampling, make no effort to randomly sample from the population. Therefore, the degree to which a convenience sample is randomly representative to the population is always unknown. Convenience samples have a high probability of being biased. A biased sample is a sample that cannot be considered representative of the target population. It is possible for a convenience sample to be representative, but the probability is always unknown. Substantial caution must be placed on inferences drawn from the use of convenience samples. Regardless, convenience samples are probably the most common samples used in research due to their low cost and relative ease. Very few researchers have the time and money to use probabilistic methods. That’s not to say you shouldn’t try, but if you’re forced to use a convenience sample, you should always note its limitations.</p>
<p>{% youtube MJjq0NILrnk %}</p>
<p>It’s important to note that probability-based sampling methods do not guarantee a representative sample either. That’s why we say the sample is <strong>randomly representative</strong>. There is still uncertainty. This is particularly true for small samples. We can take another look at the info-graphic provided by Wild, Pfannkuch and Horton (2011) that looks at populations, samples and sample size. Note that Wild et al. are referring to probability-based sampling methods.</p>
<p>The larger a random sample, the more likely it is to represent the population.</p>
<p>This is an important lesson. Sample size does matter and should always be considered an important consideration when planning an investigation. In the next section will be explore this concept further when we consider sampling distributions.</p>
<h3 id=sampling-distributions>Sampling Distributions</h3>
<p>Take a random sample from the population, of say size n=100, measure a quantitative variable on each unit and calculate the sample mean. Write down the sample mean in a data recording sheet. Now place the sample back into the population and take another random sample of the same size. Measure your variable, calculate the sample mean, and record its value in the same recording sheet. The sample mean won’t be the same, because it’s a slightly different sample. Remember, this is called sampling variability or error. Now, repeat this process many, many times, say one thousand. Now, take all the one thousand sample means you recorded and plot them using a histogram. This histogram of the sample means is an example of a <strong>sampling distribution</strong>.</p>
<p>{% youtube z0Ry_3_qhDw %}</p>
<p>A sampling distribution is a hypothetical distribution of a sample statistic, such as a mean, median or proportion, constructed through the repeated sampling from a population. A sampling distribution describes what would happen if we were to repeat a study many times over and for each replicated study we recorded a summary statistic.</p>
<p>Sampling distributions are influenced by two major factors.</p>
<ul>
<li>The first factor is the underlying distribution of the random variable. For example, if your random variable is distributed normally, binomially, or exponentially, this will have an effect on the characteristics of the sampling distribution.</li>
<li>The second major factor is the sample size n. The sample size of the hypothetical repeated studies has some interesting effects on the sampling distribution, as we will discover shortly.</li>
</ul>
<p>The <a href=https://calpolystat1.shinyapps.io/sampling_distribution/ target=_blank rel="noopener noreferrer">Cal Poly Sampling Distribution Shiny app</a> will allow you to commence exploring sampling distributions.</p>
<p><strong>Activity 1</strong></p>
<ol>
<li>Set the following inputs:</li>
</ol>
<ul>
<li>Population Distribution: Normal</li>
<li>Population mean: 0</li>
<li>Population standard deviation: 1</li>
<li>Sample size: 10</li>
<li>Statistic: Mean</li>
<li>Number of samples: 1</li>
</ul>
<ol start=2>
<li>Click <strong>Draw samples</strong>. This draws one random sample (n=10) from the population. The sample values are displayed in the first histogram. The sample mean is calculated and plotted on the sampling distribution of the mean plot.</li>
<li>Number of samples: 1000</li>
<li>Click Draw samples. The app will quickly draw 1000 random samples and plot their means. Note the difference between a sample distribution versus a sampling distribution of the mean.</li>
</ol>
<p><strong>Activity 2</strong></p>
<ol>
<li>Now let’s change the underlying population distribution and increase the sample size. Set the following inputs:</li>
</ol>
<ul>
<li>Population Distribution: Left-skewed</li>
<li>Population mean: 0</li>
<li>Population standard deviation: 1</li>
<li>Sample size: 100</li>
<li>Statistic: Mean</li>
<li>Number of samples: 1000</li>
</ul>
<ol start=2>
<li>Click <strong>Draw samples</strong>. Note that while the population distribution is heavily left-skewed, the sampling distribution of the means is not. You will learn more about this when we look at the central limit theorem.</li>
</ol>
<h4 id=youtube-data>YouTube Data</h4>
<p>We will use the <a href=https://raw.githubusercontent.com/yanboyang713/RMIT-Data-Repository/main/Youtube.csv target=_blank rel="noopener noreferrer">YouTube.csv</a> data to explore the concepts of a sampling distribution. The data were originally sourced from the <a href=https://archive.ics.uci.edu/ml/datasets/Online+Video+Characteristics+and+Transcoding+Time+Dataset target=_blank rel="noopener noreferrer">UCI Machine Learning Repository</a>. The dataset contains the basic video characteristics of over 24,000 YouTube clips. The variables are as follows:</p>
<ul>
<li><strong>id</strong>: Youtube vide id</li>
<li><strong>duration</strong>: duration of video</li>
<li><strong>bitrate</strong>: bitrate(total in Kbits)</li>
<li><strong>bitrate.video</strong>: bitrate(video bitrate in Kbits)</li>
<li><strong>height</strong>: height of video in pixles</li>
<li><strong>width</strong>: width of video in pixles</li>
<li><strong>framerate</strong>: actual video frame rate</li>
<li><strong>frame.rate.est.</strong>: estimated video frame rate</li>
<li><strong>codec</strong>: coding standard used for the video</li>
<li><strong>category</strong>: YouTube video category</li>
</ul>
<h4 id=population-distribution>Population Distribution</h4>
<p>The <a href=https://raw.githubusercontent.com/yanboyang713/RMIT-Data-Repository/main/Youtube.csv target=_blank rel="noopener noreferrer">Youtube.csv</a> data will be treated as the unknown population. As the dataset contains over 24,000 video characteristics, this isn’t too difficult to imagine, even though the total population size of YouTube is much, much, much higher (I am yet to find a credible estimate! If you find one email me). For the sake of the example, we will imagine this to be the unknown reality that we are trying to estimate. We will look at estimating the average YouTube video duration, measured in seconds (sec). The data has been cleaned to enable a better a visualisation of the population distribution. Extreme outliers (Duration > Q3 + [IQR∗3]) have been removed to help lessen the extent of the extreme values in the right tail of the distribution. I used the following R code and saved the filtered data object as YouTube_clean.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>YouTube_clean</span> <span class=o>&lt;-</span> <span class=n>YouTube</span> <span class=o>%&gt;%</span> <span class=nf>filter</span><span class=p>(</span><span class=n>duration</span> <span class=o>&lt;</span> <span class=p>(</span><span class=m>281</span> <span class=o>+</span> <span class=p>((</span><span class=m>281-52</span><span class=p>)</span><span class=o>*</span><span class=m>3</span><span class=p>)))</span>
</code></pre></td></tr></table>
</div>
</div><p>This step only removed around 3% of the original data. The YouTube video duration distribution is visualised in the following density plot. A density plot is similar to a histogram, but uses a smoothing algorithm to remove the need for bins. The mean is depicted using a red line. The distribution is skewed to the right. Visually:</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618677526/MATH1324/ModelFive/youtubeVideoDistribution_gywftq.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618677526/MATH1324/ModelFive/youtubeVideoDistribution_gywftq.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618677526/MATH1324/ModelFive/youtubeVideoDistribution_gywftq.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618677526/MATH1324/ModelFive/youtubeVideoDistribution_gywftq.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618677526/MATH1324/ModelFive/youtubeVideoDistribution_gywftq.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618677526/MATH1324/ModelFive/youtubeVideoDistribution_gywftq.png></p>
<p>Here are the population’s parameters:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>YouTube_clean</span><span class=o>$</span><span class=n>duration</span> <span class=o>%&gt;%</span> <span class=nf>summary</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span>
<span class=gp>#</span><span class=c1>##       1      50     131     193     261     966</span>
</code></pre></td></tr></table>
</div>
</div><p>The population mean, which we denote as μ, rounds to 193 secs (or 3 minutes 21 secs). However, variability is high with a population standard deviation, which we denote as σ, of 193 secs.</p>
<h4 id=simulations-in-r>Simulations in R</h4>
<p>We can use R to simulate repeated random sampling from the population of YouTube video durations. Let’s run a simulation that generates 10,000 random samples of size n=10. The simulator will save the sample means in order to create a sampling distribution. Here’s a simple simulator:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>set.seed</span><span class=p>(</span><span class=m>123456</span><span class=p>)</span> <span class=c1>#Set random seed number to allow replication</span>

<span class=n>n</span> <span class=o>&lt;-</span> <span class=m>10</span> <span class=c1>#set sample size</span>

<span class=n>sims</span> <span class=o>&lt;-</span> <span class=m>10000</span> <span class=c1>#Set number of random samples to be drawn</span>

<span class=n>x_bar</span> <span class=o>&lt;-</span> <span class=nf>data.frame</span><span class=p>(</span><span class=n>x</span><span class=o>=</span><span class=nf>as.numeric</span><span class=p>())</span> <span class=c1>#Create a data.frame to store sample means from simulation</span>

<span class=nf>for </span><span class=p>(</span><span class=n>i</span> <span class=n>in</span> <span class=m>1</span><span class=o>:</span><span class=n>sims</span><span class=p>)</span> <span class=p>{</span> <span class=c1>#create a loop to perform the simulations</span>
  <span class=n>samp</span> <span class=o>&lt;-</span> <span class=n>YouTube_clean</span> <span class=o>%&gt;%</span> <span class=nf>sample_n</span><span class=p>(</span><span class=n>n</span><span class=p>)</span> <span class=c1>#Generate a random sample</span>
  <span class=n>x_bar[i</span><span class=p>,</span><span class=m>1</span><span class=n>]</span> <span class=o>&lt;-</span> <span class=n>samp</span><span class=o>$</span><span class=n>duration</span> <span class=o>%&gt;%</span> <span class=nf>mean</span><span class=p>()</span> <span class=c1>#Store the sample mean in the data.frame</span>
<span class=p>}</span>

<span class=n>x_bar</span><span class=o>$</span><span class=n>x</span> <span class=o>%&gt;%</span> <span class=nf>summary</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span>
<span class=gp>#</span><span class=c1>##    34.5   148.6   187.0   192.7   231.8   476.4</span>
</code></pre></td></tr></table>
</div>
</div><p>The set.seed() function forces R’s built-in random number generator to start at a particular seeding value. This ensures that others, like yourself, can re-run this code, and get the same results. If we used a different seed, the results would be a little different. Try for yourself if you wish.</p>
<p>Next, we set the sample size n &lt;- 10, and the number of random samples to draw from the population distribution, sims &lt;- 10000. Generally, we should do this at least 10,000 times, but keep in mind that requires computational time.</p>
<p>Next, we want to same the results of the simulation to an object, which we will define as a data.frame named x_bar. The loop function, for (i in 1:n){} tells R to loop through as function starting at 1 and ending at n. We use the sims object to tell R who many times to loop. If we change the sims object, we can quickly change the number of simulations, e.g. sims &lt;- 1000 or sims &lt;-100000.</p>
<p>Inside the loop, we use the sample_n function to take a random sample of size n from the YouTube_clean data frame. Then we take the mean duration of the sample and assign it to the ith row in the data frame. i is set as the loop number.</p>
<p>Once the loop finishes, the simulation is complete, and we can use the x_bar object to analyse the simulated sampling distribution of the mean.</p>
<p>Let’s visualise these steps:</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678056/MATH1324/ModelFive/SamplingDistributionSimulationOverview_sjbzkq.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678056/MATH1324/ModelFive/SamplingDistributionSimulationOverview_sjbzkq.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678056/MATH1324/ModelFive/SamplingDistributionSimulationOverview_sjbzkq.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678056/MATH1324/ModelFive/SamplingDistributionSimulationOverview_sjbzkq.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678056/MATH1324/ModelFive/SamplingDistributionSimulationOverview_sjbzkq.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678056/MATH1324/ModelFive/SamplingDistributionSimulationOverview_sjbzkq.png></p>
<p>Let’s take a closer look at the sampling distribution visualised using a histogram. Also included for comparison is the population distribution. Pay attention to the differences. Notice how the variability of the sampling distribution is much smaller and the mean of the sampling distribution is approximately the same as the population mean?</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618677526/MATH1324/ModelFive/youtubeVideoDistribution_gywftq.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618677526/MATH1324/ModelFive/youtubeVideoDistribution_gywftq.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618677526/MATH1324/ModelFive/youtubeVideoDistribution_gywftq.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618677526/MATH1324/ModelFive/youtubeVideoDistribution_gywftq.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618677526/MATH1324/ModelFive/youtubeVideoDistribution_gywftq.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618677526/MATH1324/ModelFive/youtubeVideoDistribution_gywftq.png></p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678261/MATH1324/ModelFive/sampleDistributionOfMeanYoutube_slqp1d.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678261/MATH1324/ModelFive/sampleDistributionOfMeanYoutube_slqp1d.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678261/MATH1324/ModelFive/sampleDistributionOfMeanYoutube_slqp1d.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678261/MATH1324/ModelFive/sampleDistributionOfMeanYoutube_slqp1d.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678261/MATH1324/ModelFive/sampleDistributionOfMeanYoutube_slqp1d.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678261/MATH1324/ModelFive/sampleDistributionOfMeanYoutube_slqp1d.png></p>
<h4 id=expected-value-and-variance>Expected Value and Variance</h4>
<p>These observations introduce two important concepts related to the sampling distributions. For sampling distributions of the mean, the expected value, E(x¯), variance, Var(x¯) and standard deviation, σx¯, are as follows:</p>
<p>$$E(\bar{x}) = \mu_{\bar{x}} = \mu$$
$$Var(\bar{x}) = \sigma^2_{\bar{x}} = \frac{\sigma^2}{n}$$
$$\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}}$$</p>
<p>where x¯ refers to a sample mean, and n = sample size. Let’s demonstrate that this is true. The population parameters are as follows:</p>
<p>$$\mu = 193$$
$$\sigma^2 = 193^2$$
$$\sigma = 193$$</p>
<p>Note that, conincidently, μ=σ=193.</p>
<p>According to the formula above, the mean, variance and standard deviation of a sampling distribution of the mean using a sample size n=10, are…</p>
<p>$$E(\bar{x}) = \mu_{\bar{x}} = 193$$</p>
<p>$$Var(\bar{x}) = \sigma^2_{\bar{x}} = \frac{\sigma^2}{n} = \frac{193^2}{10} = 3724.9$$</p>
<p>$$\sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}} = \frac{193}{\sqrt{10}} = 61.03$$</p>
<p>Now, keeping in mind that we used a simulation, and we expect there to be some random error (especially for the variance), recall the descriptive statistics of the sampling distribution simulated in R…</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>x_bar</span><span class=o>$</span><span class=n>x</span> <span class=o>%&gt;%</span> <span class=nf>mean</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 192.7484</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>x_bar</span><span class=o>$</span><span class=n>x</span> <span class=o>%&gt;%</span> <span class=nf>var</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 3723.879</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>x_bar</span><span class=o>$</span><span class=n>x</span> <span class=o>%&gt;%</span> <span class=nf>sd</span><span class=p>()</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 61.02359</span>
</code></pre></td></tr></table>
</div>
</div><p>These simulation estimates are very close! We get closer if we increase the simulation size, but this becomes impractical due to the extra computational time.</p>
<h4 id=standard-error>Standard Error</h4>
<p>The standard deviation for a sampling distribution is known as the standard error (SE). So, we could write the standard error for the mean as:</p>
<p>$$SE = \sigma_{\bar{x}} = \frac{\sigma}{\sqrt{n}}$$</p>
<p>The size of the sample and the standard error share an inverse relationship. As sample size increases, the SE for the mean decreases. Consider the following plot visualising this relations assuming σ=10.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678836/MATH1324/ModelFive/standardError_zm3vpj.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678836/MATH1324/ModelFive/standardError_zm3vpj.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678836/MATH1324/ModelFive/standardError_zm3vpj.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678836/MATH1324/ModelFive/standardError_zm3vpj.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678836/MATH1324/ModelFive/standardError_zm3vpj.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618678836/MATH1324/ModelFive/standardError_zm3vpj.png></p>
<p>Why? Larger random samples provide more reliable estimates of population parameters, therefore, less error. Let’s demonstrate this further by running the simulation outlined above for three different sample sizes, n = 10, 30, and 100. The results for the simulations are summarised in the following three histograms:</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms1_g4dg6l.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms1_g4dg6l.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms1_g4dg6l.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms1_g4dg6l.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms1_g4dg6l.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms1_g4dg6l.png>
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms2_tjkxfb.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms2_tjkxfb.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms2_tjkxfb.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms2_tjkxfb.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms2_tjkxfb.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms2_tjkxfb.png>
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms3_j18y30.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms3_j18y30.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms3_j18y30.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms3_j18y30.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms3_j18y30.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679262/MATH1324/ModelFive/histograms3_j18y30.png></p>
<p>As you can see, as the sample size increases, the standard error decreases. You might also detect that the shape changes from being slightly skewed to symmetric. This brings us to the next important concept.</p>
<h4 id=central-limit-theorem>Central Limit Theorem</h4>
<p>There are a few useful rules we need to know about sampling distributions of the mean. If the underlying population distribution of a variable is normally distributed, the resulting sampling distribution of the mean will be normally distributed. This rule is referred to the Central Limit Theorem and can be written as:</p>
<p>$$\text{If } x \sim N(\mu,\sigma) \text{ then } \bar{x} \sim N(\mu,\frac{\sigma}{\sqrt{n}})$$</p>
<p>This makes sense. However, what if the population distribution isn’t normally distributed as was the case with YouTube video durations? We got a hint in the previous figure. Let’s take a closer look.</p>
<p>We use our simulator to create a sampling distribution of the mean duration using 10,000 samples of size 100. We plot the distribution and overlay a hypothetical normal distribution (blue line) with μx¯=193 and σx¯=19.3:</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679514/MATH1324/ModelFive/centralLimitTheorem_phgyvy.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679514/MATH1324/ModelFive/centralLimitTheorem_phgyvy.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679514/MATH1324/ModelFive/centralLimitTheorem_phgyvy.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679514/MATH1324/ModelFive/centralLimitTheorem_phgyvy.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679514/MATH1324/ModelFive/centralLimitTheorem_phgyvy.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618679514/MATH1324/ModelFive/centralLimitTheorem_phgyvy.png></p>
<p>The blue (theoretical) line is a near perfect fit to the sampling distribution. This is another important property of the Central Limit Theorem. When the sample size we use is large, typically defined as n>30, the sampling distribution of the mean is approximately normal, regardless of the variable’s underlying population distribution.</p>
<p><strong>NOTE:</strong></p>
<ol>
<li>When sampling from a population with mean $/mu$ and finite standard deviation $/sigma$ , the sampling
distribution of the sample mean will tend to be a normal distribution with mean $/mu$ and standard deviation $/sigma / /sqrt{n}$ as the sample size becomes large (n>30).</li>
</ol>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618694588/MATH1324/ModelSix/clt_jbtxpu.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618694588/MATH1324/ModelSix/clt_jbtxpu.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618694588/MATH1324/ModelSix/clt_jbtxpu.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618694588/MATH1324/ModelSix/clt_jbtxpu.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618694588/MATH1324/ModelSix/clt_jbtxpu.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618694588/MATH1324/ModelSix/clt_jbtxpu.png></p>
<ol start=2>
<li>Why CLT is important?
Many statistics have distributions that are approximately normal for large sample sizes, even when we are sampling from a distribution that is not normal and this means that we can often use well-developed statistical inference and probability calculations procedures that are based on a normal distribution even if we are sampling from a population that is not normal, provided we have a large sample size.</li>
</ol>
<h4 id=what-are-sampling-distributions-used-for>What are sampling distributions used for?</h4>
<p>We will start using sampling distributions in greater depth to help us answer interesting questions about the results of statistical investigation later in Module 7. For now, we go through a few examples to start getting a sense of how sampling distributions are used in statistics. We will use the CLT to quickly calculate probabilities of observing different sample means for various sample sizes, assuming the population mean and standard deviation of YouTube video duration is 193 secs.</p>
<ol>
<li>What is the probability of randomly selecting a sample of size n=100 that has a sample mean duration of less than 150 secs?
Because we have a large sample size, we can invoke the CLT, which means the sampling distribution of the mean can be approximated as:</li>
</ol>
<p>$$\bar{x} \sim N(\mu,\frac{\sigma}{\sqrt{n}}) = N(193,19.3)$$</p>
<p>Now we can use R’s normal distribution functions to determine Pr(x¯&lt;150). In R we use the formula:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>pnorm</span><span class=p>(</span><span class=n>q</span> <span class=o>=</span> <span class=m>150</span><span class=p>,</span> <span class=n>mean</span> <span class=o>=</span> <span class=m>193</span><span class=p>,</span> <span class=n>sd</span> <span class=o>=</span> <span class=m>19.3</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 0.01294095</span>
</code></pre></td></tr></table>
</div>
</div><p>The probability, Pr(x¯&lt;150)), was found to equal .013. Therefore, there is a 1.3% chance that an investigator will randomly select a sample with a mean below 150 secs. In other words, this would be unusual.</p>
<ol start=2>
<li>What is the probability of randomly selecting a sample of size n = 100 that has a mean duration greater than four minutes?
We need to find Pr(x¯>240). In R, we use the formula:</li>
</ol>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>pnorm</span><span class=p>(</span><span class=n>q</span> <span class=o>=</span> <span class=m>240</span><span class=p>,</span> <span class=n>mean</span> <span class=o>=</span> <span class=m>193</span><span class=p>,</span> <span class=n>sd</span> <span class=o>=</span> <span class=m>19.3</span><span class=p>,</span> <span class=n>lower.tail</span> <span class=o>=</span> <span class=kc>FALSE</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 0.007441098</span>
</code></pre></td></tr></table>
</div>
</div><p>The answer is found to be Pr(x¯>240)=0.007.</p>
<ol start=3>
<li>What is the probability of randomly selecting a sample of size n = 200 that has a mean duration greater than five minutes?</li>
</ol>
<p>We need to change the standard error as the example calls for a larger sample. We can do this directly in R using:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>pnorm</span><span class=p>(</span><span class=n>q</span> <span class=o>=</span> <span class=m>300</span><span class=p>,</span> <span class=n>mean</span> <span class=o>=</span> <span class=m>193</span><span class=p>,</span> <span class=n>sd</span> <span class=o>=</span> <span class=m>193</span><span class=o>/</span><span class=nf>sqrt</span><span class=p>(</span><span class=m>200</span><span class=p>),</span> <span class=n>lower.tail</span> <span class=o>=</span> <span class=kc>FALSE</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 2.244519e-15</span>
</code></pre></td></tr></table>
</div>
</div><p>Note how we calculated SE directly in the formula using the sqrt() function. We find Pr(x¯>300)=2.244519e−15. What does that mean? When you see e-15, that means to move the decimal place to the right 15 places from 2.244519, so, Pr(x¯>300)=0.000000000000002244519. In other words, the probability is really, really small.</p>
<p>Why has the probability substantially dropped? As a larger sample size was used, the sampling distribution has a smaller standard error. Therefore, observing a sample mean duration of 300 secs would be very unlikely when the sample size was n=200 vs. n=100. Larger random samples provide more reliable estimates of population parameters.</p>
<ol start=4>
<li>The probability distribution of 6-month incomes of account executives has mean $20,000 and standard deviation $5,000. n=64 account executives are randomly selected. What is the probability that the sample mean exceeds $20,500?</li>
</ol>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618694903/MATH1324/ModelSix/Example4_nlz7vt.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618694903/MATH1324/ModelSix/Example4_nlz7vt.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618694903/MATH1324/ModelSix/Example4_nlz7vt.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618694903/MATH1324/ModelSix/Example4_nlz7vt.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618694903/MATH1324/ModelSix/Example4_nlz7vt.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618694903/MATH1324/ModelSix/Example4_nlz7vt.png></p>
<ol start=5>
<li>A business client of FedEx wants to deliver urgently a large freight from Australia to China. When asked about the weight of the cargo they could not supply the exact weight, however they have specified that there are total of 36 boxes. You are working as a Business analyst for FedEx. And you have been challenged to tell the executives quickly whether or not they can do certain delivery.</li>
</ol>
<p>Since, we have worked with them for so many years and have seen so many freights from them we can confidently say that the type of cargo they follow is a distribution with a mean of μ= 72 lb (32.66 kg) and a standard deviation of σ = 3 lb (1.36 kg). The plane you have can carry the max cargo weight up to 2640 lb (1193 kg). Based on this information what is the probability that all of the cargo can be safely loaded onto the planes and transported?</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618695129/MATH1324/ModelSix/Example5_demouz.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618695129/MATH1324/ModelSix/Example5_demouz.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618695129/MATH1324/ModelSix/Example5_demouz.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618695129/MATH1324/ModelSix/Example5_demouz.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618695129/MATH1324/ModelSix/Example5_demouz.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618695129/MATH1324/ModelSix/Example5_demouz.png></p>
<h5 id=demonstrations-of-clt>Demonstrations of CLT</h5>
<ul>
<li>
<p>A fantastic toy for exploring this can be found here:
<a href=http://onlinestatbook.com/stat_sim/sampling_dist/ target=_blank rel="noopener noreferrer">http://onlinestatbook.com/stat_sim/sampling_dist/</a></p>
</li>
<li>
<p>Another can be found here:
<a href=https://gallery.shinyapps.io/CLT_mean/ target=_blank rel="noopener noreferrer">https://gallery.shinyapps.io/CLT_mean/</a></p>
</li>
</ul>
<h3 id=exercises-1>Exercises</h3>
<h1 id=exercises-2>Exercises</h1>
<p>Complete the following module exercises (Submit your solutions via Canvas) before the deadlines in order to obtain a participation mark (1%). The exercises aim to help develop your conceptual understanding and prepare you for the exam. Exam questions will be very similar to the module exercises (except in the exam you won’t be required to use R). Answers are available following submission. Working together in groups is encouraged, but please don’t give away the answers to other students who haven’t done the work (they won’t be learning anything!). These exercises are designed to aid your learning.</p>
<ol>
<li>Exercise 1
Why do researchers use samples instead of populations?</li>
</ol>
<ul>
<li>Because a random sample always approximates the population</li>
<li>Because samples are always representative of the population</li>
<li>Because measuring an entire population is generally impossible</li>
<li>Because samples and populations are the same thing</li>
</ul>
<p>Answer: because measuring an entire population is generally impossible</p>
<ol start=2>
<li>Exercise 2
How can a researcher guarantee selecting a representative sample from a population?</li>
</ol>
<ul>
<li>By using random sampling</li>
<li>By using cluster sampling</li>
<li>By using stratified sampling</li>
<li>There is no way to “guarantee” your sample is representative</li>
</ul>
<p>Answer: There is no way to &ldquo;guarantee&rdquo; your sample is representative. Random, cluster and stratified sampling can only ever maximise the probability of selecting a representative sample.</p>
<ol start=3>
<li>Exercise 3
A researcher wants to gather a cluster sample of Australians to survey their exercise habits. Which of the following could be used as a cluster?</li>
</ol>
<ul>
<li>State</li>
<li>Postcode</li>
<li>City/Town</li>
<li>All of the above</li>
</ul>
<p>Answer: All of the above</p>
<ol start=4>
<li>Exercise 4</li>
</ol>
<p>Which of the following methods is considered an example of simple random sampling from the Australian population?</p>
<ul>
<li>Randomly sample postcodes and then randomly sample participants within the selected postcodes</li>
<li>Divide the population up into age categories and then randomly select participants in each category proportional to the population distribution</li>
<li>From a list of the entire population, randomly select the desired number of participants</li>
<li>From the hometown of the researcher, approach people in a shopping centre</li>
</ul>
<p>Answer: From a list of the entire population, randomly select the desired number of participants</p>
<ol start=5>
<li>Exercise 5</li>
</ol>
<p>When is a sample said to be biased?</p>
<ul>
<li>When the sample is likely to not be representative of the population</li>
<li>When the sample has a negative attitude towards the research being conducted</li>
<li>When the sample is likely to be representative of the population</li>
<li>When the sample is small</li>
</ul>
<p>Answer: When the sample is likely to not be representative of the population</p>
<p>Sampling bias occurs when some members of a population are systematically more likely to be selected in a sample than others. It is also called ascertainment bias in medical fields.</p>
<p>Sampling bias limits the generalizability of findings because it is a threat to external validity, specifically population validity. In other words, findings from biased samples can only be generalized to populations that share characteristics with the sample.</p>
<ol start=6>
<li>Exercise 6</li>
</ol>
<p>Large samples are representative samples. True or false?</p>
<p>Answer: False. Even though a sample might be considered large, whether it is likely to be representative comes down to how it was selected. Large biased samples are still biased. Probability sampling techniques are the best way to maximise the probability of getting a representative sample.</p>
<ol start=7>
<li>Exercise 7</li>
</ol>
<p>Sampling Distribution Activity</p>
<p>We will use the Sampling Distribution Shiny app hosted here - <a href=https://calpolystat1.shinyapps.io/sampling_distribution/ target=_blank rel="noopener noreferrer">https://calpolystat1.shinyapps.io/sampling_distribution/</a> to explore the concept of a sampling distribution.</p>
<p>For the app, set the following options:</p>
<p>Population distribution: Normal
Population mean: 100
Population standard deviation: 15
Sample size: 10
Statistic: Mean
Number of samples: 1000
Click here to display population characteristics: Select this option.
Display summaries of sampling distribution: Checked.
Click the Draw Sample button. This will generate 1000 sample means and plot them as a sampling distribution. Y</p>
<p>The standard deviation of a sampling distribution is also known as which of the following?</p>
<ul>
<li>Sampling standard deviation</li>
<li>Standard error</li>
<li>Standard normal score</li>
<li>Z-score</li>
</ul>
<p>Answer: Standard error</p>
<ol start=8>
<li>Exercise 8</li>
</ol>
<p>In the long run, what will be the mean of the sampling distribution of the mean if we took many more samples of size = 10?</p>
<ul>
<li>0</li>
<li>15</li>
<li>99</li>
<li>100</li>
</ul>
<p>Answer: 100</p>
<ol start=9>
<li>Exercise 9</li>
</ol>
<p>Change the Sample Size to 100. Clear the app and Draw 1000 new samples of n=100. What happened to the standard deviation of the sampling distribution of the mean?</p>
<ul>
<li>Equalled the mean</li>
<li>Did not change</li>
<li>Increased</li>
<li>Decreased</li>
</ul>
<p>Answer: Decreased</p>
<ol start=10>
<li>Exercise 10</li>
</ol>
<p>Therefore, as sample size increases, the standard error of a statistic…</p>
<ul>
<li>stays the same</li>
<li>increases</li>
<li>decreases</li>
<li>varies randomly</li>
</ul>
<p>Answer: decreases</p>
<ol start=11>
<li>Exercise 11</li>
</ol>
<p>Central Limit Theorem Activity</p>
<p>Using the same Shiny app, set the following options:</p>
<p>Population distribution: Right-skewed
Population mean: 100
Population standard deviation: 15
Sample size: 10
Statistic: Mean
Number of samples: 1000
Click here to display population characteristics: Select this option.
Display summaries of sampling distribution: Checked.</p>
<p>Click the Draw Sample button. This will generate 1000 sample means and plot them as a sampling distribution.</p>
<p>The population distribution is right-skewed. For a sampling distribution of the mean where n=10, how would you describe its shape?</p>
<ul>
<li>Bi-modal</li>
<li>Left-skewed</li>
<li>Approximately normal</li>
<li>Right-skewed</li>
</ul>
<p>Answer: Right-skewed</p>
<ol start=12>
<li>Exercise 12</li>
</ol>
<p>Change the Sample Size to 100. Clear the app and Draw 1000 new samples. Now how would you describe the shape of the sampling distribution of the means?</p>
<ul>
<li>Bi-modal</li>
<li>Right-skewed</li>
<li>Left-skewed</li>
<li>Approximately normal</li>
</ul>
<p>Answer: Approximately normal</p>
<ol start=13>
<li>Exercise 13</li>
</ol>
<p>A population distribution is negatively skewed. If a sampling distribution is created using samples of size N=10, what would be the expected shape of the sampling distribution?</p>
<ul>
<li>Approximately normal</li>
<li>Skewed to the left</li>
<li>Skewed positively</li>
<li>Symmetric</li>
</ul>
<p>Answer: Skewed to the left. Only sampling distributions a of sample sizes greater than 30 will be approximately normal when the underlying population disstribution is not normal.</p>
<ol start=14>
<li>Exercise 14</li>
</ol>
<p>Mobile Phone Battery Life</p>
<p>Suppose the average duration of a new iPhone battery for continuous video playback is 10 hours with a standard deviation of 30 minutes.</p>
<p>Suppose a store orders 50 iPhones and asks their customers to record their continuous video playback time in hours.</p>
<p>What is the standard error for the sampling distribution of the mean playback time (hours) for n=50? (Round to three decimal places)</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback>(0.5/sqrt(50)) %&gt;% round(3)
</code></pre></td></tr></table>
</div>
</div><h2 id=module-6-estimating-uncertainty-confidently>Module 6 Estimating Uncertainty Confidently</h2>
<h3 id=overview-1>Overview</h3>
<p>Our best, and often only, estimate for a population parameter is the sample estimate. However, due to sampling variability, the sample estimate is always uncertain. Module 6 will introduce the concept of confidence intervals as an interval estimate that expresses the degree of uncertainty associated with sample statistics.</p>
<h3 id=learning-objectives-4>Learning Objectives</h3>
<p>The learning objectives associated with this module are:</p>
<ul>
<li>Differentiate between a point and interval estimate.</li>
<li>Define the concept of a confidence interval.</li>
<li>Discuss the major factors that impact the width of a confidence interval.</li>
<li>Use technology to calculate confidence intervals for common statistics including means, proportions and rates.</li>
</ul>
<h3 id=types-of-inference>Types of Inference</h3>
<ul>
<li>
<p><strong>Estimation</strong>:
– Estimating or predicting the value of the parameter
– “What is (are) the most likely values of μ or p?”</p>
<ul>
<li>Example: A consumer wants to estimate the average price of similar homes in her city before putting her home on the market.
<ul>
<li>Estimation: Estimate μ, the average home price.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Hypothesis Testing</strong>: (I will teach it on module 7)
– Deciding about the value of a parameter based on some preconceived idea.
– &ldquo;Did the sample come from a population with m = 5 or p = .2?&rdquo;</p>
<ul>
<li>Example: A manufacturer wants to know if a new type of steel is more resistant to high temperatures than an old type was.
<ul>
<li>Hypothesis test: Is the new average resistance, μΝ equal to the old average resistance, $ μ_Ο $?</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id=point-and-interval-estimation>Point and Interval Estimation</h3>
<h4 id=definitions>Definitions</h4>
<p>An estimator is a rule, usually a formula, that tells you how to calculate the estimate based on the sample.</p>
<ul>
<li>
<p><strong>Point estimation</strong>: A single number is calculated to estimate the parameter.
The <strong>point estimate</strong> of a sample statistic, such as the mean, median, proportion or rate are single, or point values. They are often our best estimate for a population parameter, but do not express the degree of uncertainty for an estimate associated with its sampling variability. Point estimates should be accompanied by additional information to assist with drawing inferences about the population.</p>
</li>
<li>
<p><strong>Interval estimation</strong>: Two numbers are calculated to create an interval within which the parameter is expected to lie.
<strong>Interval estimation</strong> serves to overcome this limitation. The idea is to supplement the point estimate with an interval that reflects the degree of uncertainty associated with a statistic. The most common type of interval estimator is called the <strong>confidence interval</strong>, or CI for short.</p>
</li>
</ul>
<h4 id=some-definitions>Some definitions</h4>
<ul>
<li>A point estimate is a single number,</li>
<li>a confidence interval provides additional information about the variability of the estimate (based on the sampling distribution)</li>
</ul>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610086/MATH1324/ModelSix/Mon_May_10_11_26_32_AM_AEST_2021_oyiigh.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610086/MATH1324/ModelSix/Mon_May_10_11_26_32_AM_AEST_2021_oyiigh.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610086/MATH1324/ModelSix/Mon_May_10_11_26_32_AM_AEST_2021_oyiigh.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610086/MATH1324/ModelSix/Mon_May_10_11_26_32_AM_AEST_2021_oyiigh.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610086/MATH1324/ModelSix/Mon_May_10_11_26_32_AM_AEST_2021_oyiigh.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610086/MATH1324/ModelSix/Mon_May_10_11_26_32_AM_AEST_2021_oyiigh.png></p>
<h5 id=properties-of-point-estimators>Properties of Point Estimators</h5>
<ul>
<li>
<p>Since an estimator is calculated from sample values, it varies from sample to sample according to its <strong>sampling distribution</strong>.</p>
</li>
<li>
<p>An <strong>estimator</strong> is <strong>unbiased</strong> if the mean of its sampling distribution equals the parameter of interest.
– It does not systematically overestimate or underestimate the target parameter.
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610736/MATH1324/ModelSix/Mon_May_10_11_38_27_AM_AEST_2021_pqb6am.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610736/MATH1324/ModelSix/Mon_May_10_11_38_27_AM_AEST_2021_pqb6am.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610736/MATH1324/ModelSix/Mon_May_10_11_38_27_AM_AEST_2021_pqb6am.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610736/MATH1324/ModelSix/Mon_May_10_11_38_27_AM_AEST_2021_pqb6am.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610736/MATH1324/ModelSix/Mon_May_10_11_38_27_AM_AEST_2021_pqb6am.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610736/MATH1324/ModelSix/Mon_May_10_11_38_27_AM_AEST_2021_pqb6am.png></p>
</li>
<li>
<p>Of all the <strong>unbiased</strong> estimators, we prefer the estimator whose sampling distribution has the <strong>smallest spread</strong> or <strong>variability</strong>.
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610843/MATH1324/ModelSix/Mon_May_10_11_40_12_AM_AEST_2021_ajtlae.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610843/MATH1324/ModelSix/Mon_May_10_11_40_12_AM_AEST_2021_ajtlae.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610843/MATH1324/ModelSix/Mon_May_10_11_40_12_AM_AEST_2021_ajtlae.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610843/MATH1324/ModelSix/Mon_May_10_11_40_12_AM_AEST_2021_ajtlae.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610843/MATH1324/ModelSix/Mon_May_10_11_40_12_AM_AEST_2021_ajtlae.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620610843/MATH1324/ModelSix/Mon_May_10_11_40_12_AM_AEST_2021_ajtlae.png></p>
</li>
</ul>
<h5 id=measuring-the-goodness-of-an-estimator>Measuring the Goodness of an Estimator</h5>
<p>The distance between an estimate and the true value of the parameter is the <strong>error of estimation</strong>.
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620631387/MATH1324/ModelSix/Mon_May_10_05_22_34_PM_AEST_2021_bep0ld.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620631387/MATH1324/ModelSix/Mon_May_10_05_22_34_PM_AEST_2021_bep0ld.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620631387/MATH1324/ModelSix/Mon_May_10_05_22_34_PM_AEST_2021_bep0ld.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620631387/MATH1324/ModelSix/Mon_May_10_05_22_34_PM_AEST_2021_bep0ld.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620631387/MATH1324/ModelSix/Mon_May_10_05_22_34_PM_AEST_2021_bep0ld.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620631387/MATH1324/ModelSix/Mon_May_10_05_22_34_PM_AEST_2021_bep0ld.png></p>
<p><strong>NOTE:</strong> The distance between the bullet and the bull’s-eye.</p>
<h5 id=the-margin-of-error>The Margin of Error</h5>
<p>For <strong>unbiased</strong> estimators with normal sampling distributions, 95% of all point estimates will lie within 1.96 standard deviations of the parameter of interest.
<strong>Margin of error</strong>: The maximum error of estimation, calculated as
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620631927/MATH1324/ModelSix/Mon_May_10_05_31_29_PM_AEST_2021_yl5mpp.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620631927/MATH1324/ModelSix/Mon_May_10_05_31_29_PM_AEST_2021_yl5mpp.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620631927/MATH1324/ModelSix/Mon_May_10_05_31_29_PM_AEST_2021_yl5mpp.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620631927/MATH1324/ModelSix/Mon_May_10_05_31_29_PM_AEST_2021_yl5mpp.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620631927/MATH1324/ModelSix/Mon_May_10_05_31_29_PM_AEST_2021_yl5mpp.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620631927/MATH1324/ModelSix/Mon_May_10_05_31_29_PM_AEST_2021_yl5mpp.png></p>
<h5 id=confidence-intervals>Confidence Intervals</h5>
<p>An interval gives a range of values:</p>
<ul>
<li>Takes into consideration variation in sample statistics from sample to sample</li>
<li>Gives information about “closeness” to unknown population parameters</li>
<li>Stated in terms of level of confidence
– e.g. 95% confident, 99% confident
– Can never be 100% confident</li>
</ul>
<p>Let’s consider a typical confidence interval using a hypothetical example. Let’s assume height is normally distributed in the population with a standard deviation of 7 cm (This is unrealistic as we often do not know the population SD, but let’s go with it for now). An investigator takes a random sample of 10 peoples’ height (cm). Say the mean of the sample was found to be 176.5 cm. To calculate a <strong>confidence interval for the mean of a normally distributed variable with a known standard deviation</strong>, we use the following formula:</p>
<p>$$\bar{x} \pm z_{1 - (\alpha/2)}\frac{\sigma}{\sqrt{n}}$$</p>
<p>We need to discuss the z critical value, Z1−(α/2), in the above formula. This value is obtained from the standard normal distribution. Recall, the standard normal distribution has the following properties:</p>
<p>$$z \sim N(0,1)$$</p>
<p>The α value refers to what is known as the significance level. Almost all studies will use a standard level of α=0.05. The α value is based on the level of the confidence interval. A CI is defined as 100(1−α) CI. If we use α=0.05, this means we’re going to calculate a 100(1−0.05) = 95% CI.</p>
<p>The z critical value in the confidence interval formula is found by looking up the z-value associated with the 1−α/2=1−0.05/2=1−0.025=.975 percentile of the standard normal distribution. We might write:</p>
<p>$$Pr(Z &lt; z) = .975$$</p>
<p>We dealt with solving a similar problem in Module 4. Fortunately, this is easy to solve in R. To solve the formula above we type the following into R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>qnorm</span><span class=p>(</span><span class=n>p</span> <span class=o>=</span> <span class=m>.975</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 1.959964</span>
</code></pre></td></tr></table>
</div>
</div><p>Note, that if we don’t specify the mean and standard deviation for qnorm(), the R function reverts to a standard normal distribution with mean = 0 and sd = 1. We discover $ Pr( Z &lt; 1.96 ) = .975 $. The following figure shows how $ z = 1.96 $ relates back to the 95% CI. We can see that $ Pr(−1.96 &lt; z &lt; 1.96) = .95 $ or 95%. This means that 0.025 probability sits in the upper and lower tail of the distribution. As you will discover later on, the critical value is required in the conference interval formula to ensure the confidence interval achieves the desired level of coverage, e.g. 95%.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618681589/MATH1324/ModelSix/significanceInterval_a2gi1s.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618681589/MATH1324/ModelSix/significanceInterval_a2gi1s.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618681589/MATH1324/ModelSix/significanceInterval_a2gi1s.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618681589/MATH1324/ModelSix/significanceInterval_a2gi1s.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618681589/MATH1324/ModelSix/significanceInterval_a2gi1s.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618681589/MATH1324/ModelSix/significanceInterval_a2gi1s.png></p>
<p>Beauty! Now we can calculate the 95% CI for the sample mean:</p>
<p>$$176.5 \pm z_{1 - (\alpha/2)}\frac{\sigma}{\sqrt{n}} = 1.96\frac{7}{\sqrt{10}} = 4.34$$</p>
<p>We would write x¯=176.5, 95% CI [172.161, 180.84]. The confidence interval captures a wide range of values for the mean height and reflects the high degree of uncertainty expected from a sample of n=10. This interval is depicted as follows:</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618681847/MATH1324/ModelSix/CIBreakDownForMean_sgac5a.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618681847/MATH1324/ModelSix/CIBreakDownForMean_sgac5a.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618681847/MATH1324/ModelSix/CIBreakDownForMean_sgac5a.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618681847/MATH1324/ModelSix/CIBreakDownForMean_sgac5a.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618681847/MATH1324/ModelSix/CIBreakDownForMean_sgac5a.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618681847/MATH1324/ModelSix/CIBreakDownForMean_sgac5a.png></p>
<h3 id=confidence-intervals-1>Confidence Intervals</h3>
<p>Before we dig deeper, you need to have a definition of a CI in the back of your mind. When we refer to confidence in statistics, we need to understand very carefully what this means. In this course we will use a strict frequentist definition. Not all statistics instructors will be this stringent and in the past you may have been taught something different. However, for my course assessment, I expect you to understand and use this definition.</p>
<p>100(1−α)% CI, is an interval estimate for a population parameter, based on a given sample statistic, where if samples of a certain size n were repeatedly drawn from the population and a CI for each sample’s statistic was calculated, 100(1−α)% of these intervals would capture the population parameter, whereas the other 100(α)% would not.</p>
<p>Now with this strange and long-winded definition in mind, let’s start digging deeper into the theory.</p>
<h4 id=the-general-process>The General Process</h4>
<p>The general formula for all confidence intervals is:
$$ Point Estimate ± (Critical Value)(Standard Error) $$</p>
<p>Where:</p>
<ul>
<li>Point Estimate is the sample statistic estimating the population parameter of interest</li>
<li>Critical Value is a table value based on the sampling distribution of the point estimate and the desired confidence level</li>
<li>Standard Error is the standard deviation of the point estimate</li>
</ul>
<h3 id=theory>Theory</h3>
<p>We will explore confidence interval theory using a simulation and visualisation. We will first make some assumptions about the population. Let’s assume height is normally distributed with a mean of 175 and a standard deviation of 7:</p>
<p>$$Height∼N(175,7)$$</p>
<p>As investigators, we don’t tend to know population parameters in advance, and hence the reason we need to gather a sample and estimate it. However, for the purpose of this lesson, we need to assume these values.</p>
<p>Now imagine drawing 100 random samples of size 10 from the population. For each of the 100 samples, you calculate the sample mean and 95% CI. You can plot all these means and 95% CIs like in Plot 1 below. Plot 2 and 3 repeat the same procedure, each displaying the means and 95% CIs of 100 random samples of size 10. At the top of each plot, the percentage of CIs that miss capturing the population mean, μ=175, are reported. Missed intervals are coloured red. For Plot 1, we see that Missed = 3 % of the CIs missed μ=175, for Plot 2, Missed = 5 %, and for Plot 3, Missed = 4 %. If we repeated this for many thousands of plots and samples, what do you think this missed percentage would average? If you guessed 5%, you’re already on your way to understanding CIs. The 5% of CIs that will miss capturing the population mean is our α=0.05.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618682453/MATH1324/ModelSix/confidenceIntervals_vvb9bm.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618682453/MATH1324/ModelSix/confidenceIntervals_vvb9bm.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618682453/MATH1324/ModelSix/confidenceIntervals_vvb9bm.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618682453/MATH1324/ModelSix/confidenceIntervals_vvb9bm.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618682453/MATH1324/ModelSix/confidenceIntervals_vvb9bm.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618682453/MATH1324/ModelSix/confidenceIntervals_vvb9bm.png></p>
<p>Think carefully about the plots above and now re-read the CI definition:</p>
<p>100(1−α)% CI, is an interval estimate for a population parameter, based on a given sample statistic, where if samples of a certain size n were repeatedly drawn from the population and a CI for each sample’s statistic was calculated, 100(1−α)% of these intervals would capture the population parameter, whereas the other 100(α)% would not.</p>
<p>CIs should now be starting to make a little more sense. Basically, CIs are constructed in a way that in the long run, a certain percentage (e.g. 95%) of CIs calculated by repeating the same random sampling procedure will capture a population parameter, for example μ=175.</p>
<p>CIs can be calculated for a wide range of statistics using formulaic approaches. However, the methods vary depending on the type of statistic being estimated and the assumptions we make about the population from which the data are drawn. Later sections in this module explain calculating CIs for various situations and statistics.</p>
<h3 id=influencing-factors>Influencing Factors</h3>
<h4 id=sample-size>Sample Size</h4>
<p>Look at the formula for a CI for the mean of a normally distributed variable with a known standard deviation:</p>
<p>$$\bar{x} \pm z_{1 - (\alpha/2)}\frac{\sigma}{\sqrt{n}}$$</p>
<p>You can see the standard error of the mean in the formula:</p>
<p>$$SE = \sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}$$</p>
<p>Therefore, it comes as no surprise that CIs share some of the same rules as sampling distributions. Consider the following plots. Note that the number of simulated samples have been increased to 1000 so we get better estimates of the “Missed” percentage. We know from the previous module that sample size shares an inverse relationship with SE. As N increases, SE decreases. Moving from Plot 1 to Plot 3, sample sizes are 10, 50 and100. What happens to the width of the CIs as sample size increases?</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618682986/MATH1324/ModelSix/confidenceIntervalsTwo_sleuwn.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618682986/MATH1324/ModelSix/confidenceIntervalsTwo_sleuwn.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618682986/MATH1324/ModelSix/confidenceIntervalsTwo_sleuwn.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618682986/MATH1324/ModelSix/confidenceIntervalsTwo_sleuwn.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618682986/MATH1324/ModelSix/confidenceIntervalsTwo_sleuwn.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618682986/MATH1324/ModelSix/confidenceIntervalsTwo_sleuwn.png></p>
<p>We see a dramatic decrease in the width of the intervals. Why? Mathematically, as sample size increases, the SE in the CI formula decreases, meaning that the lower and upper bounds fall closer to the sample mean.</p>
<p>For example, if in the height example the investigator had used a sample size of 30, the confidence interval would become:</p>
<p>$$176.5 \pm z_{1 - (\alpha/2)}\frac{\sigma}{\sqrt{n}} = 1.96\frac{7}{\sqrt{30}} = 2.50$$</p>
<p>and therefore, x¯=176.5, 95% CI [174.00, 179.00]. This 95% CI is narrower than the interval calculated for n=10, 95% CI [172.16, 180.84]. Conceptually, larger random samples are better estimates of the population and therefore, we can be more certain in their estimates over the use of smaller samples.</p>
<h4 id=confidenece-level>Confidenece Level</h4>
<ul>
<li>Expressed as a percentage (&lt;100%)</li>
<li>Suppose confidence level = 95%
– Also written (1 - α) = 0.95, (so α = 0.05)</li>
<li>A relative frequency interpretation:
– 95% of all the confidence intervals that can be constructed will contain the unknown true parameter</li>
<li>A specific interval either will contain or will not contain the true parameter
– No probability involved in a specific interval</li>
</ul>
<p>While the 95% CI is the most common, it is possible to use other levels of confidence. Let’s compute a 90% and 99% confidence interval for the sample mean height when n=10. This is depicted in the following plot. Plot 1 reports a 99% CI, Plot 2, 95% CI, and Plot 3, 90% CI.</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618683157/MATH1324/ModelSix/confidenceIntervalsThree_wgrptl.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618683157/MATH1324/ModelSix/confidenceIntervalsThree_wgrptl.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618683157/MATH1324/ModelSix/confidenceIntervalsThree_wgrptl.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618683157/MATH1324/ModelSix/confidenceIntervalsThree_wgrptl.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618683157/MATH1324/ModelSix/confidenceIntervalsThree_wgrptl.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618683157/MATH1324/ModelSix/confidenceIntervalsThree_wgrptl.png></p>
<p>As you can see, higher levels of confidence are associated with wider intervals. This makes sense. If you want to be more confident about capturing a population parameter, cast a wider interval!</p>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620633826/MATH1324/ModelSix/Mon_May_10_06_03_11_PM_AEST_2021_itm5l8.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620633826/MATH1324/ModelSix/Mon_May_10_06_03_11_PM_AEST_2021_itm5l8.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620633826/MATH1324/ModelSix/Mon_May_10_06_03_11_PM_AEST_2021_itm5l8.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620633826/MATH1324/ModelSix/Mon_May_10_06_03_11_PM_AEST_2021_itm5l8.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620633826/MATH1324/ModelSix/Mon_May_10_06_03_11_PM_AEST_2021_itm5l8.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620633826/MATH1324/ModelSix/Mon_May_10_06_03_11_PM_AEST_2021_itm5l8.png></p>
<h5 id=confidence-interval-for-μ-σ-known>Confidence Interval for μ (σ Known)</h5>
<ul>
<li>Assumptions
– Population standard deviation σ is known
– Population is normally distributed
– If population is not normal, use large sample (n > 30)</li>
<li>Confidence interval estimate:
$$ \bar{X} \pm Z_{\alpha/2} \frac{\sigma}{\sqrt{n}}$$</li>
</ul>
<p>where $ \bar {X} $ is the point estimate, $ Z_{\alpha/2} $ is the normal distribution critical value for a probability of $ \alpha/2 $ in each tail is the standard error.</p>
<ul>
<li>
<p>Finding the Critical Value, $ Z_{\alpha/2} $
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634357/MATH1324/ModelSix/Mon_May_10_06_12_02_PM_AEST_2021_h5afqy.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634357/MATH1324/ModelSix/Mon_May_10_06_12_02_PM_AEST_2021_h5afqy.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634357/MATH1324/ModelSix/Mon_May_10_06_12_02_PM_AEST_2021_h5afqy.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634357/MATH1324/ModelSix/Mon_May_10_06_12_02_PM_AEST_2021_h5afqy.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634357/MATH1324/ModelSix/Mon_May_10_06_12_02_PM_AEST_2021_h5afqy.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634357/MATH1324/ModelSix/Mon_May_10_06_12_02_PM_AEST_2021_h5afqy.png></p>
</li>
<li>
<p>Commonly used levels are 90%, 95% and 99%
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634427/MATH1324/ModelSix/Mon_May_10_06_13_24_PM_AEST_2021_sg8urt.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634427/MATH1324/ModelSix/Mon_May_10_06_13_24_PM_AEST_2021_sg8urt.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634427/MATH1324/ModelSix/Mon_May_10_06_13_24_PM_AEST_2021_sg8urt.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634427/MATH1324/ModelSix/Mon_May_10_06_13_24_PM_AEST_2021_sg8urt.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634427/MATH1324/ModelSix/Mon_May_10_06_13_24_PM_AEST_2021_sg8urt.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634427/MATH1324/ModelSix/Mon_May_10_06_13_24_PM_AEST_2021_sg8urt.png></p>
</li>
<li>
<p>Intervals and Level of Confidence
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634520/MATH1324/ModelSix/Mon_May_10_06_14_55_PM_AEST_2021_puxcwi.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634520/MATH1324/ModelSix/Mon_May_10_06_14_55_PM_AEST_2021_puxcwi.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634520/MATH1324/ModelSix/Mon_May_10_06_14_55_PM_AEST_2021_puxcwi.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634520/MATH1324/ModelSix/Mon_May_10_06_14_55_PM_AEST_2021_puxcwi.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634520/MATH1324/ModelSix/Mon_May_10_06_14_55_PM_AEST_2021_puxcwi.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620634520/MATH1324/ModelSix/Mon_May_10_06_14_55_PM_AEST_2021_puxcwi.png></p>
</li>
</ul>
<p>Now let’s look at the formula. We need to change the z critical value for the confidence interval formula:</p>
<p>$$\bar{x} \pm z_{1 - (\alpha/2)}\frac{\sigma}{\sqrt{n}}$$</p>
<p>We will begin with the 90% CI. This CI width corresponds to a significance level of α=0.1. We need to find Pr(Z&lt;z)=1−α/2=1−0.1/2=1−0.05=.95. In R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>qnorm</span><span class=p>(</span><span class=n>p</span> <span class=o>=</span> <span class=m>.95</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 1.644854</span>
</code></pre></td></tr></table>
</div>
</div><p>The z-value is found to be 1.64. Now completing the 90% CI equation:</p>
<p>$$176.5 \pm z_{1 - (\alpha/2)}\frac{\sigma}{\sqrt{n}} = 1.64\frac{7}{\sqrt{10}} = 3.64$$</p>
<p>We calculate x¯=176.5, 90% CI [172.86, 180.14]. Now compare this 90% CI to the 95% CI [172.16, 180.84]. The 90% CI is narrower. Why? Because as we are less certain about the CI capturing the population parameter in the long run, the width of the confidence interval will reduce. Think of it like casting a smaller net to capture the population mean.</p>
<p>For a 99% CI, we must change the z critical value again. This CI width corresponds to a significance level of α=0.01. Therefore, we need to find Pr(Z&lt;z)=1−α/2=1−0.01/2=1−0.005=.995. In R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>qnorm</span><span class=p>(</span><span class=n>p</span> <span class=o>=</span> <span class=m>.995</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 2.575829</span>
</code></pre></td></tr></table>
</div>
</div><p>The z-value is found to be 2.58. Next…</p>
<p>$$176.5 \pm z_{1 - (\alpha/2)}\frac{\sigma}{\sqrt{n}} = 2.58\frac{7}{\sqrt{10}} = 5.70$$</p>
<p>The result is x¯=176.5, 99% CI [170.80, 182.20]. Comparing this to the 95% CI [172.16, 180.84], we note that the 99% CI is wider. As we are trying to be extra certain (99% of confidence interval will capture the population mean in the long run), we need to widen the interval. In other words, the 99% CI is casting a wider net to catch the population parameter.</p>
<p>My Confidence Interval app below can be used explore confidence intervals and the effect of changing different parameters. If the app does not load in this page, you can view the app <a href=https://jbaglin.shinyapps.io/Confidence_Intervals/ target=_blank rel="noopener noreferrer">here</a>.</p>
<h3 id=calculating-confidence-intervals>Calculating Confidence Intervals</h3>
<h4 id=pizza-data>Pizza Data</h4>
<p>This section will compare the mean diameter for pizzas made by Dominos and Eagle Boys. This is an issue close to many students’ hearts.</p>
<p>Eagle Boys claim their pizzas are larger than their main competitor, Dominos. The Pizza dataset contains the diameters (cm) of 125 random pizzas from each company. The dataset is available from the data repository. You can read all about the data <a href=https://raw.githubusercontent.com/yanboyang713/RMIT-Data-Repository/main/Pizza.csv target=_blank rel="noopener noreferrer">here</a>.</p>
<p>Specifically, the Pizza dataset contains the following variables:</p>
<ul>
<li><strong>ID</strong>: An identifier</li>
<li><strong>Store</strong>: The pizza store/company; one of Dominos or EagleBoys</li>
<li><strong>Crust</strong>: The crust type for the pizza; DeepPan, Mid and Thin.</li>
<li><strong>Topping</strong>: The pizza topping: BBQMeatlovers, Hawaiian and Supreme</li>
<li><strong>Diameter</strong>: The pizza diameter in centimetres</li>
</ul>
<h4 id=comparing-means>Comparing Means</h4>
<p>We start with the descriptive statistics and histograms comparing the pizza diameters (cm) of the two companies.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>library</span><span class=p>(</span><span class=n>dplyr</span><span class=p>)</span>
<span class=n>Pizza</span> <span class=o>%&gt;%</span> <span class=nf>group_by</span><span class=p>(</span><span class=n>Store</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>summarise</span><span class=p>(</span><span class=n>Min</span> <span class=o>=</span> <span class=nf>min</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Q1</span> <span class=o>=</span> <span class=nf>quantile</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>probs</span> <span class=o>=</span> <span class=m>.25</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Median</span> <span class=o>=</span> <span class=nf>median</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Q3</span> <span class=o>=</span> <span class=nf>quantile</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>probs</span> <span class=o>=</span> <span class=m>.75</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Max</span> <span class=o>=</span> <span class=nf>max</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Mean</span> <span class=o>=</span> <span class=nf>mean</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>SD</span> <span class=o>=</span> <span class=nf>sd</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>n</span> <span class=o>=</span> <span class=nf>n</span><span class=p>(),</span>
                                         <span class=n>Missing</span> <span class=o>=</span> <span class=nf>sum</span><span class=p>(</span><span class=nf>is.na</span><span class=p>(</span><span class=n>Diameter</span><span class=p>)))</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## # A tibble: 2 x 10</span>
<span class=gp>#</span><span class=c1>##   Store       Min    Q1 Median    Q3   Max  Mean    SD     n Missing</span>
<span class=gp>#</span><span class=c1>##   &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;int&gt;</span>
<span class=gp>#</span><span class=c1>## 1 Dominos    25.5  26.6   26.9  28.8  29.7  27.4 1.17    125       0</span>
<span class=gp>#</span><span class=c1>## 2 EagleBoys  26.6  28.8   29.1  29.5  31.1  29.2 0.626   125       0</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>library</span><span class=p>(</span><span class=n>lattice</span><span class=p>)</span>
<span class=nf>library</span><span class=p>(</span><span class=n>ggplot2</span><span class=p>)</span>
<span class=n>Pizza</span> <span class=o>%&gt;%</span> <span class=nf>histogram</span><span class=p>(</span><span class=o>~</span><span class=n>Diameter</span> <span class=o>|</span> <span class=n>Store</span><span class=p>,</span> <span class=n>data</span> <span class=o>=</span> <span class=n>.,layout</span><span class=o>=</span><span class=nf>c</span><span class=p>(</span><span class=m>1</span><span class=p>,</span><span class=m>2</span><span class=p>))</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618683958/MATH1324/ModelSix/histogramDiameter_uqtral.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618683958/MATH1324/ModelSix/histogramDiameter_uqtral.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618683958/MATH1324/ModelSix/histogramDiameter_uqtral.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618683958/MATH1324/ModelSix/histogramDiameter_uqtral.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618683958/MATH1324/ModelSix/histogramDiameter_uqtral.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618683958/MATH1324/ModelSix/histogramDiameter_uqtral.png></p>
<p>There appears to be a strange looking distribution for the Dominos’ pizzas. The distribution appears to be bi-modal. Does the crust type has something to do with it?</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Pizza</span> <span class=o>%&gt;%</span> <span class=nf>group_by</span><span class=p>(</span><span class=n>Store</span><span class=p>,</span> <span class=n>Crust</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>summarise</span><span class=p>(</span><span class=n>Min</span> <span class=o>=</span> <span class=nf>min</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Q1</span> <span class=o>=</span> <span class=nf>quantile</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>probs</span> <span class=o>=</span> <span class=m>.25</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Median</span> <span class=o>=</span> <span class=nf>median</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Q3</span> <span class=o>=</span> <span class=nf>quantile</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>probs</span> <span class=o>=</span> <span class=m>.75</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Max</span> <span class=o>=</span> <span class=nf>max</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Mean</span> <span class=o>=</span> <span class=nf>mean</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>SD</span> <span class=o>=</span> <span class=nf>sd</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>n</span> <span class=o>=</span> <span class=nf>n</span><span class=p>(),</span>
                                         <span class=n>Missing</span> <span class=o>=</span> <span class=nf>sum</span><span class=p>(</span><span class=nf>is.na</span><span class=p>(</span><span class=n>Diameter</span><span class=p>)))</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## # A tibble: 6 x 11</span>
<span class=gp>#</span><span class=c1>## # Groups:   Store [2]</span>
<span class=gp>#</span><span class=c1>##   Store     Crust     Min    Q1 Median    Q3   Max  Mean    SD     n Missing</span>
<span class=gp>#</span><span class=c1>##   &lt;fct&gt;     &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;int&gt;</span>
<span class=gp>#</span><span class=c1>## 1 Dominos   DeepPan  26.0  26.4   26.6  26.8  28.8  26.7 0.462    40       0</span>
<span class=gp>#</span><span class=c1>## 2 Dominos   Mid      25.5  26.6   26.7  27.0  28.9  26.8 0.510    42       0</span>
<span class=gp>#</span><span class=c1>## 3 Dominos   Thin     25.6  28.8   29.0  29.2  29.7  28.8 0.801    43       0</span>
<span class=gp>#</span><span class=c1>## 4 EagleBoys DeepPan  28.2  28.7   29.0  29.4  30.4  29.1 0.479    43       0</span>
<span class=gp>#</span><span class=c1>## 5 EagleBoys Mid      26.6  28.6   28.8  29    29.8  28.8 0.483    43       0</span>
<span class=gp>#</span><span class=c1>## 6 EagleBoys Thin     28.5  29.4   29.7  30.0  31.1  29.7 0.550    39       0</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684246/MATH1324/ModelSix/deepPan_uz3wb5.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684246/MATH1324/ModelSix/deepPan_uz3wb5.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684246/MATH1324/ModelSix/deepPan_uz3wb5.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684246/MATH1324/ModelSix/deepPan_uz3wb5.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684246/MATH1324/ModelSix/deepPan_uz3wb5.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684246/MATH1324/ModelSix/deepPan_uz3wb5.png>
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684287/MATH1324/ModelSix/mid_chxyoz.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684287/MATH1324/ModelSix/mid_chxyoz.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684287/MATH1324/ModelSix/mid_chxyoz.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684287/MATH1324/ModelSix/mid_chxyoz.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684287/MATH1324/ModelSix/mid_chxyoz.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684287/MATH1324/ModelSix/mid_chxyoz.png>
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684338/MATH1324/ModelSix/thin_kgsjgw.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684338/MATH1324/ModelSix/thin_kgsjgw.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684338/MATH1324/ModelSix/thin_kgsjgw.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684338/MATH1324/ModelSix/thin_kgsjgw.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684338/MATH1324/ModelSix/thin_kgsjgw.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684338/MATH1324/ModelSix/thin_kgsjgw.png></p>
<p>The bi-modal appearance of the Dominos’ pizza diameter can be accounted for by the large difference between Dominos’ DeepPan and Mid pizzas when compared to their This pizzas. Because of this confounding variable, let’s focus on comparing only the thin crusts between Eagle Boys and Dominos.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Pizza_thin</span> <span class=o>&lt;-</span> <span class=n>Pizza</span> <span class=o>%&gt;%</span> <span class=nf>filter</span><span class=p>(</span><span class=n>Crust</span> <span class=o>==</span> <span class=s>&#34;Thin&#34;</span><span class=p>)</span>

<span class=n>Pizza_thin</span> <span class=o>%&gt;%</span> <span class=nf>group_by</span><span class=p>(</span><span class=n>Store</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>summarise</span><span class=p>(</span><span class=n>Min</span> <span class=o>=</span> <span class=nf>min</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Q1</span> <span class=o>=</span> <span class=nf>quantile</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>probs</span> <span class=o>=</span> <span class=m>.25</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Median</span> <span class=o>=</span> <span class=nf>median</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Q3</span> <span class=o>=</span> <span class=nf>quantile</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>probs</span> <span class=o>=</span> <span class=m>.75</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Max</span> <span class=o>=</span> <span class=nf>max</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Mean</span> <span class=o>=</span> <span class=nf>mean</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>SD</span> <span class=o>=</span> <span class=nf>sd</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>n</span> <span class=o>=</span> <span class=nf>n</span><span class=p>(),</span>
                                         <span class=n>Missing</span> <span class=o>=</span> <span class=nf>sum</span><span class=p>(</span><span class=nf>is.na</span><span class=p>(</span><span class=n>Diameter</span><span class=p>)))</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## # A tibble: 2 x 10</span>
<span class=gp>#</span><span class=c1>##   Store       Min    Q1 Median    Q3   Max  Mean    SD     n Missing</span>
<span class=gp>#</span><span class=c1>##   &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;int&gt;</span>
<span class=gp>#</span><span class=c1>## 1 Dominos    25.6  28.8   29.0  29.2  29.7  28.8 0.801    43       0</span>
<span class=gp>#</span><span class=c1>## 2 EagleBoys  28.5  29.4   29.7  30.0  31.1  29.7 0.550    39       0</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Pizza_thin</span> <span class=o>%&gt;%</span> <span class=nf>boxplot</span><span class=p>(</span><span class=n>Diameter</span> <span class=o>~</span> <span class=n>Store</span><span class=p>,</span> <span class=n>data</span> <span class=o>=</span> <span class=n>.)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684440/MATH1324/ModelSix/boxplot_w4mfdj.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684440/MATH1324/ModelSix/boxplot_w4mfdj.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684440/MATH1324/ModelSix/boxplot_w4mfdj.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684440/MATH1324/ModelSix/boxplot_w4mfdj.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684440/MATH1324/ModelSix/boxplot_w4mfdj.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684440/MATH1324/ModelSix/boxplot_w4mfdj.png></p>
<p>There are also a few outliers that we should pay some attention to. We have four values in the Dominos’ group and one in the Eagle Boys’ group. These outliers can have unwanted effects on our estimates, so it is best to deal with them at this point.</p>
<p>There are a few ways that we could do this. A simple approach is to exclude them. When you exclude outliers, you must be sure to explain why you did so. In this example, we will assume that these were due to poor measurements.</p>
<p>We can use the following code to remove outliers using the following definition reported back in Module 2.</p>
<ul>
<li>Lower outlier&lt;Q1−1.5∗IQR</li>
<li>Upper outlier>Q3+1.5∗IQR</li>
</ul>
<p>The following code exploits the boxplot() function which saves a list of the outliers plotted in the box plot.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>boxplot</span> <span class=o>&lt;-</span> <span class=n>Pizza_thin</span> <span class=o>%&gt;%</span> <span class=nf>boxplot</span><span class=p>(</span><span class=n>Diameter</span> <span class=o>~</span> <span class=n>Store</span><span class=p>,</span> <span class=n>data</span> <span class=o>=</span> <span class=n>.,</span> <span class=n>plot</span> <span class=o>=</span> <span class=kc>FALSE</span><span class=p>)</span>
<span class=n>boxplot</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## $stats</span>
<span class=gp>#</span><span class=c1>##        [,1]  [,2]</span>
<span class=gp>#</span><span class=c1>## [1,] 28.320 28.54</span>
<span class=gp>#</span><span class=c1>## [2,] 28.765 29.40</span>
<span class=gp>#</span><span class=c1>## [3,] 29.010 29.68</span>
<span class=gp>#</span><span class=c1>## [4,] 29.200 30.03</span>
<span class=gp>#</span><span class=c1>## [5,] 29.660 30.67</span>
<span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>## $n</span>
<span class=gp>#</span><span class=c1>## [1] 43 39</span>
<span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>## $conf</span>
<span class=gp>#</span><span class=c1>##          [,1]     [,2]</span>
<span class=gp>#</span><span class=c1>## [1,] 28.90519 29.52061</span>
<span class=gp>#</span><span class=c1>## [2,] 29.11481 29.83939</span>
<span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>## $out</span>
<span class=gp>#</span><span class=c1>## [1] 27.04 25.58 27.45 26.38 31.06</span>
<span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>## $group</span>
<span class=gp>#</span><span class=c1>## [1] 1 1 1 1 2</span>
<span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>## $names</span>
<span class=gp>#</span><span class=c1>## [1] &#34;Dominos&#34;   &#34;EagleBoys&#34;</span>
</code></pre></td></tr></table>
</div>
</div><p>Now we can create a filter matrix to identify and remove the outliers in Pizza_thin.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Filt_mat</span> <span class=o>&lt;-</span> <span class=nf>data.frame</span><span class=p>(</span><span class=n>group</span> <span class=o>=</span> <span class=n>boxplot</span><span class=o>$</span><span class=n>group</span><span class=p>,</span> <span class=n>outliers</span> <span class=o>=</span> <span class=n>boxplot</span><span class=o>$</span><span class=n>out</span><span class=p>)</span>
<span class=n>Filt_mat</span><span class=o>$</span><span class=n>group</span> <span class=o>&lt;-</span> <span class=n>Filt_mat</span><span class=o>$</span><span class=n>group</span> <span class=o>%&gt;%</span> <span class=nf>factor</span><span class=p>(</span><span class=n>levels</span> <span class=o>=</span> <span class=nf>c</span><span class=p>(</span><span class=m>1</span><span class=p>,</span><span class=m>2</span><span class=p>),</span> 
                                            <span class=n>labels</span> <span class=o>=</span> <span class=nf>c</span><span class=p>(</span><span class=s>&#34;Dominos&#34;</span><span class=p>,</span><span class=s>&#34;EagleBoys&#34;</span><span class=p>))</span>
<span class=n>Filt_mat</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##       group outliers</span>
<span class=gp>#</span><span class=c1>## 1   Dominos    27.04</span>
<span class=gp>#</span><span class=c1>## 2   Dominos    25.58</span>
<span class=gp>#</span><span class=c1>## 3   Dominos    27.45</span>
<span class=gp>#</span><span class=c1>## 4   Dominos    26.38</span>
<span class=gp>#</span><span class=c1>## 5 EagleBoys    31.06</span>
</code></pre></td></tr></table>
</div>
</div><p>Now we can use dplyr and %in% operator to filter the outliers.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Pizza_thin_filt</span> <span class=o>&lt;-</span> <span class=n>Pizza_thin</span> <span class=o>%&gt;%</span> <span class=nf>filter</span><span class=p>(</span><span class=o>!</span><span class=p>(</span><span class=n>Store</span> <span class=o>%in%</span> <span class=n>Filt_mat</span><span class=o>$</span><span class=n>group</span><span class=p>)</span> 
                                        <span class=o>|</span> <span class=o>!</span><span class=p>(</span><span class=n>Diameter</span> <span class=o>%in%</span> <span class=n>Filt_mat</span><span class=o>$</span><span class=n>outliers</span><span class=p>))</span>
</code></pre></td></tr></table>
</div>
</div><p>This filter uses the filter matrix to identify values that are not considered outliers. The ! symbol mean “not” and the %in% operator check a range of values in a vector. Therefore the filter systematically searches the Pizza_thin dataset for outliers and filters them out, saving the results to Pizza_thin_filt.</p>
<p>Now let’s recheck the box plot:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Pizza_thin_filt</span> <span class=o>%&gt;%</span> <span class=nf>boxplot</span><span class=p>(</span><span class=n>Diameter</span> <span class=o>~</span> <span class=n>Store</span><span class=p>,</span> <span class=n>data</span> <span class=o>=</span> <span class=n>.,</span>
                            <span class=n>main</span> <span class=o>=</span> <span class=s>&#34;Thin Pizza Diamater (Outliers removed)&#34;</span><span class=p>,</span>
                            <span class=n>ylab</span> <span class=o>=</span> <span class=s>&#34;Diameter (cm)&#34;</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684749/MATH1324/ModelSix/boxplot-outliersRemoved_t1xtj9.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684749/MATH1324/ModelSix/boxplot-outliersRemoved_t1xtj9.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684749/MATH1324/ModelSix/boxplot-outliersRemoved_t1xtj9.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684749/MATH1324/ModelSix/boxplot-outliersRemoved_t1xtj9.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684749/MATH1324/ModelSix/boxplot-outliersRemoved_t1xtj9.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618684749/MATH1324/ModelSix/boxplot-outliersRemoved_t1xtj9.png></p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Pizza_thin_filt</span> <span class=o>%&gt;%</span> <span class=nf>group_by</span><span class=p>(</span><span class=n>Store</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>summarise</span><span class=p>(</span><span class=n>Min</span> <span class=o>=</span> <span class=nf>min</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Q1</span> <span class=o>=</span> <span class=nf>quantile</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>probs</span> <span class=o>=</span> <span class=m>.25</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Median</span> <span class=o>=</span> <span class=nf>median</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Q3</span> <span class=o>=</span> <span class=nf>quantile</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>probs</span> <span class=o>=</span> <span class=m>.75</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Max</span> <span class=o>=</span> <span class=nf>max</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>Mean</span> <span class=o>=</span> <span class=nf>mean</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>SD</span> <span class=o>=</span> <span class=nf>sd</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                                         <span class=n>n</span> <span class=o>=</span> <span class=nf>n</span><span class=p>(),</span>
                                         <span class=n>Missing</span> <span class=o>=</span> <span class=nf>sum</span><span class=p>(</span><span class=nf>is.na</span><span class=p>(</span><span class=n>Diameter</span><span class=p>)))</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## # A tibble: 2 x 10</span>
<span class=gp>#</span><span class=c1>##   Store       Min    Q1 Median    Q3   Max  Mean    SD     n Missing</span>
<span class=gp>#</span><span class=c1>##   &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;int&gt;</span>
<span class=gp>#</span><span class=c1>## 1 Dominos    28.3  28.8   29.0  29.2  29.7  29.0 0.307    39       0</span>
<span class=gp>#</span><span class=c1>## 2 EagleBoys  28.5  29.4   29.6  30.0  30.7  29.7 0.509    38       0</span>
</code></pre></td></tr></table>
</div>
</div><p>Sometimes when you are dealing with very large datasets, removing one set of outliers, can create additional outliers in the filtered dataset. This is due to the outlier definition being based on the estimates of the IQR and quartiles. When you remove outliers, you are changing these estimates, which then changes the location of your fences. This is a major problem when dealing with highly skewed distributions. If you’re ever faced with this situation, look into applying a Box-cox power transformation prior to outlier detection and removal. The Box-Cox transformations do an amazing job of normalising distributions, which can greatly assist with outlier detection.</p>
<p>Eagle Boys do appear to have larger diameters. However, the data were taken from a random sample of 77 pizzas across both stores. Before drawing conclusions, we need to quantify our uncertainty of our statistical estimates.</p>
<h4 id=mean---unknown-population-standard-deviation---t-distribution>Mean - Unknown Population Standard Deviation - t-distribution</h4>
<h5 id=do-you-ever-truly-know-σ>Do You Ever Truly Know σ?</h5>
<ul>
<li>Probably not!</li>
<li>In virtually all real world engineering, science and business situations, $ \sigma $ is not known.</li>
<li>If you truly know $ \mu $ there would be no need to gather a sample to estimate it.</li>
</ul>
<h5 id=confidence-interval-for-μ-σ-unknown>Confidence Interval for μ (σ Unknown)</h5>
<ul>
<li>If the population standard deviation $ \sigma $ is unknown, we can substitute the sample standard deviation, S</li>
<li>This introduces extra uncertainty, since S is variable from sample to sample</li>
<li>So we use the t distribution instead of the normal distribution.</li>
<li>Assumptions:
– Population standard deviation is unknown
– Population is normally distributed
– If population is not normal, use large sample (n > 30)</li>
<li>Use Student’s t Distribution</li>
</ul>
<div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden>
<iframe src=https://www.youtube-nocookie.com/embed/Uv6nGIgZMVw style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe>
</div>
<p>In the first example of CIs, we made an unrealistic assumption that the population standard deviation, σ, is known for a normally distributed variable. This allows us to use the standard normal distribution to calculate the CIs. In real research, σ is rarely known and must be estimated from the sample standard deviation, s. As we are estimating two parameters from the sample, the population mean, μ, and standard deviation, σ, we need to take into account the extra uncertainty or error associated with s to ensure the expected coverage of the CI remains at the desired level, e.g. 95%. The family of t-distributions are used for this purpose.</p>
<p>The t-distribution has an extra parameter, called degrees of freedom, df, that can be altered to change the heaviness of the distribution’s tails. Degrees of freedom for a t-distribution are typically calculated as:</p>
<p>The t is a family of distributions</p>
<ul>
<li>The $ t_{α/2} $ value depends on degrees of freedom (d.f.)</li>
<li>Number of observations that are free to vary after sample mean has been calculated</li>
</ul>
<p>$$ d.f. = n - 1 $$</p>
<p>The t-distribution looks very flat in comparison to a normal distribution when the df values are low. However, as df increases (i.e. sample size increases), the t-distribution will start to approximate a normal distribution. In fact, for sample sizes where df > 30, there is very little practical difference between them. As df approaches infinity, the t-distribution will become a normal distribution.</p>
<h6 id=degrees-of-freedom-df>Degrees of Freedom (df)</h6>
<p><strong>Idea</strong>: Number of observations that are free to vary after sample mean has been calculated
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620635777/MATH1324/ModelSix/Mon_May_10_06_35_40_PM_AEST_2021_al0jfk.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620635777/MATH1324/ModelSix/Mon_May_10_06_35_40_PM_AEST_2021_al0jfk.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620635777/MATH1324/ModelSix/Mon_May_10_06_35_40_PM_AEST_2021_al0jfk.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620635777/MATH1324/ModelSix/Mon_May_10_06_35_40_PM_AEST_2021_al0jfk.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620635777/MATH1324/ModelSix/Mon_May_10_06_35_40_PM_AEST_2021_al0jfk.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620635777/MATH1324/ModelSix/Mon_May_10_06_35_40_PM_AEST_2021_al0jfk.png></p>
<p>Here, n = 3, so degrees of freedom = n – 1 = 3 – 1 = 2 (2 values can be any numbers, but the third is not free to vary for a given mean)</p>
<h6 id=students-t-distribution>Student’s t Distribution</h6>
<p>As the degrees of freedom increases, the t distribution approaches the normal distribution.
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620636136/MATH1324/ModelSix/Mon_May_10_06_41_51_PM_AEST_2021_kxgrwx.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620636136/MATH1324/ModelSix/Mon_May_10_06_41_51_PM_AEST_2021_kxgrwx.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620636136/MATH1324/ModelSix/Mon_May_10_06_41_51_PM_AEST_2021_kxgrwx.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620636136/MATH1324/ModelSix/Mon_May_10_06_41_51_PM_AEST_2021_kxgrwx.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620636136/MATH1324/ModelSix/Mon_May_10_06_41_51_PM_AEST_2021_kxgrwx.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620636136/MATH1324/ModelSix/Mon_May_10_06_41_51_PM_AEST_2021_kxgrwx.png></p>
<p>Developed in work with Guinness Brewery for working with small samples.</p>
<h6 id=students-t-table>Student’s t Table</h6>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620636256/MATH1324/ModelSix/Mon_May_10_06_43_48_PM_AEST_2021_oczelf.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620636256/MATH1324/ModelSix/Mon_May_10_06_43_48_PM_AEST_2021_oczelf.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620636256/MATH1324/ModelSix/Mon_May_10_06_43_48_PM_AEST_2021_oczelf.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620636256/MATH1324/ModelSix/Mon_May_10_06_43_48_PM_AEST_2021_oczelf.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620636256/MATH1324/ModelSix/Mon_May_10_06_43_48_PM_AEST_2021_oczelf.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1620636256/MATH1324/ModelSix/Mon_May_10_06_43_48_PM_AEST_2021_oczelf.png></p>
<p>In the Pizza example, we don’t know the population standard deviation, so we have to estimate it using the sample. Do we need to worry about normality of the data to consider whether the confidence interval formula used previously is appropriate? The answer to this question depends on the sample size. If the sample size was small (e.g. n&lt;30), the non-normality of the data would prevent us from applying a regular CI formula. However, thanks to the larger sample size (n=39 for Dominos and n=38 for Eagle Boys) and the CLT introduced in the previous module, the standard CI formula works quite well. We only need to adjust the formula slightly to take into account that we don’t know the population standard deviation.</p>
<p>$$\bar{x} \pm t_{n-1,1-(\alpha/2)}\frac{s}{\sqrt{n}}$$</p>
<p>Notice the inclusion of tn−1,1−(α/2). Instead of looking this value up using a normal distribution, we need to use a different formula in R namely qt(). For example, for Dominos’ thin pizza (outliers removed):</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>qt</span><span class=p>(</span><span class=n>p</span> <span class=o>=</span> <span class=m>0.975</span><span class=p>,</span> <span class=n>df</span> <span class=o>=</span> <span class=m>39</span> <span class=m>-1</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 2.024394</span>
</code></pre></td></tr></table>
</div>
</div><p>$$ 29.04 \pm 2.024\frac{0.306}{\sqrt{39}} = 099 $$</p>
<p>and for Eagle Boys:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>qt</span><span class=p>(</span><span class=n>p</span> <span class=o>=</span> <span class=m>0.975</span><span class=p>,</span> <span class=n>df</span> <span class=o>=</span> <span class=m>38</span> <span class=m>-1</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## [1] 2.026192</span>
</code></pre></td></tr></table>
</div>
</div><p>$$ 29.66 \pm 2.026\frac{0.509}{\sqrt{38}} = 0.167 $$</p>
<table>
<thead>
<tr>
<th>Store</th>
<th>Mean</th>
<th>SD</th>
<th>n</th>
<th>tcrit</th>
<th>SE</th>
<th>95 % CI</th>
</tr>
</thead>
<tbody>
<tr>
<td>Dominos</td>
<td>29.04</td>
<td>0.307</td>
<td>39</td>
<td>2.024</td>
<td>0.049</td>
<td>[28.94, 29.14]</td>
</tr>
<tr>
<td>EagleBoys</td>
<td>29.66</td>
<td>0.509</td>
<td>38</td>
<td>2.026</td>
<td>0.083</td>
<td>[29.49, 29.83]</td>
</tr>
</tbody>
</table>
<p>As the population standard deviation is rarely known, we should always default to using the t-distribution and t-critical values to calculate interval estimates for sample means (assuming Normality or the CLT applies). Only use a z-critical value if the population standard deviation is given (which is rare!).</p>
<p>We can use dplyr and some quick computations to generate tables of 95% CIs for means…</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Pizza_thin_filt</span> <span class=o>%&gt;%</span> <span class=nf>group_by</span><span class=p>(</span><span class=n>Store</span><span class=p>)</span> <span class=o>%&gt;%</span> <span class=nf>summarise</span><span class=p>(</span><span class=n>Mean</span> <span class=o>=</span> <span class=nf>round</span><span class=p>(</span><span class=nf>mean</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span><span class=m>2</span><span class=p>),</span>
                                                  <span class=n>SD</span> <span class=o>=</span> <span class=nf>round</span><span class=p>(</span><span class=nf>sd</span><span class=p>(</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span><span class=m>3</span><span class=p>),</span>
                                                  <span class=n>n</span> <span class=o>=</span> <span class=nf>n</span><span class=p>(),</span>
                                                  <span class=n>tcrit</span> <span class=o>=</span> <span class=nf>round</span><span class=p>(</span><span class=nf>qt</span><span class=p>(</span><span class=n>p</span> <span class=o>=</span> <span class=m>0.975</span><span class=p>,</span> <span class=n>df</span> <span class=o>=</span> <span class=n>n</span> <span class=o>-</span> <span class=m>1</span><span class=p>),</span><span class=m>3</span><span class=p>),</span>
                                                  <span class=n>SE</span> <span class=o>=</span> <span class=nf>round</span><span class=p>(</span><span class=n>SD</span><span class=o>/</span><span class=nf>sqrt</span><span class=p>(</span><span class=n>n</span><span class=p>),</span><span class=m>3</span><span class=p>),</span>
                                                  <span class=n>`95% CI Lower Bound`</span> <span class=o>=</span> <span class=nf>round</span><span class=p>(</span><span class=n>Mean</span> <span class=o>-</span> <span class=n>tcrit</span> <span class=o>*</span> <span class=n>SE</span><span class=p>,</span><span class=m>2</span><span class=p>),</span>
                                                  <span class=n>`95% CI Upper Bound`</span> <span class=o>=</span> <span class=nf>round</span><span class=p>(</span><span class=n>Mean</span> <span class=o>+</span> <span class=n>tcrit</span> <span class=o>*</span> <span class=n>SE</span><span class=p>,</span><span class=m>2</span><span class=p>))</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## # A tibble: 2 x 8</span>
<span class=gp>#</span><span class=c1>##   Store     Mean    SD     n tcrit    SE `95% CI Lower Boun~ `95% CI Upper Boun~</span>
<span class=gp>#</span><span class=c1>##   &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;               &lt;dbl&gt;               &lt;dbl&gt;</span>
<span class=gp>#</span><span class=c1>## 1 Dominos   29.0 0.307    39  2.02 0.049                28.9                29.1</span>
<span class=gp>#</span><span class=c1>## 2 EagleBo~  29.7 0.509    38  2.03 0.083                29.5                29.8</span>
</code></pre></td></tr></table>
</div>
</div><p>We can also use the t-test if we filter the dataset first:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Dominos</span> <span class=o>&lt;-</span> <span class=n>Pizza_thin_filt</span> <span class=o>%&gt;%</span> <span class=nf>filter</span><span class=p>(</span><span class=n>Store</span> <span class=o>==</span> <span class=s>&#34;Dominos&#34;</span><span class=p>)</span>
<span class=nf>t.test</span><span class=p>(</span><span class=n>Dominos</span><span class=o>$</span><span class=n>Diameter</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>##  One Sample t-test</span>
<span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>## data:  Dominos$Diameter</span>
<span class=gp>#</span><span class=c1>## t = 591.66, df = 38, p-value &lt; 2.2e-16</span>
<span class=gp>#</span><span class=c1>## alternative hypothesis: true mean is not equal to 0</span>
<span class=gp>#</span><span class=c1>## 95 percent confidence interval:</span>
<span class=gp>#</span><span class=c1>##  28.94089 29.13962</span>
<span class=gp>#</span><span class=c1>## sample estimates:</span>
<span class=gp>#</span><span class=c1>## mean of x </span>
<span class=gp>#</span><span class=c1>##  29.04026</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>EagleBoys</span> <span class=o>&lt;-</span> <span class=n>Pizza_thin_filt</span> <span class=o>%&gt;%</span> <span class=nf>filter</span><span class=p>(</span><span class=n>Store</span> <span class=o>==</span> <span class=s>&#34;EagleBoys&#34;</span><span class=p>)</span>
<span class=nf>t.test</span><span class=p>(</span><span class=n>EagleBoys</span><span class=o>$</span><span class=n>Diameter</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>##  One Sample t-test</span>
<span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>## data:  EagleBoys$Diameter</span>
<span class=gp>#</span><span class=c1>## t = 359.09, df = 37, p-value &lt; 2.2e-16</span>
<span class=gp>#</span><span class=c1>## alternative hypothesis: true mean is not equal to 0</span>
<span class=gp>#</span><span class=c1>## 95 percent confidence interval:</span>
<span class=gp>#</span><span class=c1>##  29.49735 29.83212</span>
<span class=gp>#</span><span class=c1>## sample estimates:</span>
<span class=gp>#</span><span class=c1>## mean of x </span>
<span class=gp>#</span><span class=c1>##  29.66474</span>
</code></pre></td></tr></table>
</div>
</div><p>If you want to change the confidence level to 99%:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Dominos</span> <span class=o>&lt;-</span> <span class=n>Pizza_thin_filt</span> <span class=o>%&gt;%</span> <span class=nf>filter</span><span class=p>(</span><span class=n>Store</span> <span class=o>==</span> <span class=s>&#34;Dominos&#34;</span><span class=p>)</span>
<span class=nf>t.test</span><span class=p>(</span><span class=n>Dominos</span><span class=o>$</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>conf.level</span><span class=o>=</span><span class=m>0.99</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>##  One Sample t-test</span>
<span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>## data:  Dominos$Diameter</span>
<span class=gp>#</span><span class=c1>## t = 591.66, df = 38, p-value &lt; 2.2e-16</span>
<span class=gp>#</span><span class=c1>## alternative hypothesis: true mean is not equal to 0</span>
<span class=gp>#</span><span class=c1>## 99 percent confidence interval:</span>
<span class=gp>#</span><span class=c1>##  28.90717 29.17335</span>
<span class=gp>#</span><span class=c1>## sample estimates:</span>
<span class=gp>#</span><span class=c1>## mean of x </span>
<span class=gp>#</span><span class=c1>##  29.04026</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>EagleBoys</span> <span class=o>&lt;-</span> <span class=n>Pizza_thin_filt</span> <span class=o>%&gt;%</span> <span class=nf>filter</span><span class=p>(</span><span class=n>Store</span> <span class=o>==</span> <span class=s>&#34;EagleBoys&#34;</span><span class=p>)</span>
<span class=nf>t.test</span><span class=p>(</span><span class=n>EagleBoys</span><span class=o>$</span><span class=n>Diameter</span><span class=p>,</span> <span class=n>conf.level</span><span class=o>=</span><span class=m>0.99</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>##  One Sample t-test</span>
<span class=gp>#</span><span class=c1>## </span>
<span class=gp>#</span><span class=c1>## data:  EagleBoys$Diameter</span>
<span class=gp>#</span><span class=c1>## t = 359.09, df = 37, p-value &lt; 2.2e-16</span>
<span class=gp>#</span><span class=c1>## alternative hypothesis: true mean is not equal to 0</span>
<span class=gp>#</span><span class=c1>## 99 percent confidence interval:</span>
<span class=gp>#</span><span class=c1>##  29.44042 29.88906</span>
<span class=gp>#</span><span class=c1>## sample estimates:</span>
<span class=gp>#</span><span class=c1>## mean of x </span>
<span class=gp>#</span><span class=c1>##  29.66474</span>
</code></pre></td></tr></table>
</div>
</div><p>Visualising confidence intervals can be tricky. I recommend you display the confidence intervals overlaid upon the data. This ensures the viewer does not confuse the 95% CI as the range of the data. Here’s some code that you can adapt to different situations. The visualisation makes use of the ggplot2 and Hmisc package.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=c1>##install.packages(&#34;ggplot2&#34;) # If required</span>
<span class=c1>##install.packages(&#34;Hmisc&#34;) # If required</span>

<span class=nf>library</span><span class=p>(</span><span class=n>ggplot2</span><span class=p>)</span>
<span class=nf>library</span><span class=p>(</span><span class=n>Hmisc</span><span class=p>)</span>

<span class=n>p1</span> <span class=o>&lt;-</span> <span class=nf>ggplot</span><span class=p>(</span><span class=n>data</span> <span class=o>=</span> <span class=n>Pizza_thin_filt</span><span class=p>,</span> <span class=nf>aes</span><span class=p>(</span><span class=n>x</span> <span class=o>=</span> <span class=n>Store</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>Diameter</span><span class=p>))</span>
<span class=n>p1</span> <span class=o>+</span> <span class=nf>geom_dotplot</span><span class=p>(</span><span class=n>binaxis</span> <span class=o>=</span> <span class=s>&#34;y&#34;</span><span class=p>,</span> <span class=n>stackdir</span> <span class=o>=</span> <span class=s>&#34;center&#34;</span><span class=p>,</span> <span class=n>dotsize</span> <span class=o>=</span> <span class=m>1</span><span class=o>/</span><span class=m>2</span><span class=p>,</span> <span class=n>alpha</span> <span class=o>=</span> <span class=m>.25</span><span class=p>)</span> <span class=o>+</span> 
  <span class=nf>stat_summary</span><span class=p>(</span><span class=n>fun.y</span> <span class=o>=</span> <span class=s>&#34;mean&#34;</span><span class=p>,</span> <span class=n>geom</span> <span class=o>=</span> <span class=s>&#34;point&#34;</span><span class=p>,</span> <span class=n>colour</span> <span class=o>=</span> <span class=s>&#34;red&#34;</span><span class=p>)</span> <span class=o>+</span>
  <span class=nf>stat_summary</span><span class=p>(</span><span class=n>fun.data</span> <span class=o>=</span> <span class=s>&#34;mean_cl_normal&#34;</span><span class=p>,</span> <span class=n>colour</span> <span class=o>=</span> <span class=s>&#34;red&#34;</span><span class=p>,</span> 
               <span class=n>geom</span> <span class=o>=</span> <span class=s>&#34;errorbar&#34;</span><span class=p>,</span> <span class=n>width</span> <span class=o>=</span> <span class=m>.2</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618687590/MATH1324/ModelSix/t-test_aoeygi.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618687590/MATH1324/ModelSix/t-test_aoeygi.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618687590/MATH1324/ModelSix/t-test_aoeygi.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618687590/MATH1324/ModelSix/t-test_aoeygi.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618687590/MATH1324/ModelSix/t-test_aoeygi.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618687590/MATH1324/ModelSix/t-test_aoeygi.png></p>
<p>Based on the 95% CIs for the mean pizza diameters of the competing stores, I think we can be very confident that Eagle Boy’s pizzas tend to have a wider mean diameter.</p>
<h4 id=proportions---binomial-distribution>Proportions - binomial distribution</h4>
<p>Interval estimates for other statistics can also be calculated using the following formulas. However, be warned. You can only guarantee the appropriate confidence interval converge will be met if the stated assumptions are satisfied. These methods are referred to as approximations. When approximations cannot be used, we must look to exact methods. Fortunately, R has you covered for both.</p>
<p>Interval estimates for proportions are based on a normal approximation to the binomial distribution. If np(1−p)≥5 , we can approximate a CI using:</p>
<p>$$p \pm z_{1-(\alpha/2)}\sqrt{\frac{p(1-p)}{n}}$$</p>
<p>For example, suppose a researcher randomly selects 300 people from the population and finds that 2% (x=6) have cancer. We confirm, np(1−p)=300∗.02∗.98=5.88≥5. Therefore, we can proceed with the normal approximated CI. We will use the standard 95% CI.</p>
<p>$$.02 \pm z_{1-(\alpha/2)}\sqrt{\frac{p(1-p)}{n}}=1.96\sqrt{\frac{.02(1-.02)}{300}} = 0.016$$</p>
<p>We calculate the prevalence of cancer to be 0.02, 95% CI [.004, .036].</p>
<p>In R, we can use the binom.conf.int() command from the epitools package to quickly calculate the 95% CI.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=c1>##install.packages(&#34;epitools&#34;) #If required</span>
<span class=nf>library</span><span class=p>(</span><span class=n>epitools</span><span class=p>)</span>
<span class=nf>binom.approx</span><span class=p>(</span><span class=m>6</span><span class=p>,</span> <span class=m>300</span><span class=p>,</span> <span class=n>conf.level</span> <span class=o>=</span> <span class=m>0.95</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##   x   n proportion     lower     upper conf.level</span>
<span class=gp>#</span><span class=c1>## 1 6 300       0.02 0.0041578 0.0358422       0.95</span>
</code></pre></td></tr></table>
</div>
</div><p>What do you do if np(1−p)&lt;5? For example, say the above example was changed so n=20, p=.3 (x=6) and 1−p=.7, np(1−p)=20∗.3∗.70=4.2. Therefore, the normal approximation does not apply. We can use the binom.exact() function to deal with this situation.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>binom.exact</span><span class=p>(</span><span class=m>6</span><span class=p>,</span> <span class=m>20</span><span class=p>,</span> <span class=n>conf.level</span> <span class=o>=</span> <span class=m>0.95</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##   x  n proportion     lower     upper conf.level</span>
<span class=gp>#</span><span class=c1>## 1 6 20        0.3 0.1189316 0.5427892       0.95</span>
</code></pre></td></tr></table>
</div>
</div><h4 id=rates---poisson-distribution>Rates - Poisson distribution</h4>
<p>Confidence intervals for rates following a Poisson distribution can be readily obtained using the pois.conf.int() function, which is also part of the epitools package. For example, we can confirm from the output below that the 95% CI for λ=56 is [42.30, 72.72].</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>pois.exact</span><span class=p>(</span><span class=m>56</span><span class=p>,</span> <span class=n>pt</span> <span class=o>=</span> <span class=m>1</span><span class=p>,</span> <span class=n>conf.level</span> <span class=o>=</span> <span class=m>0.95</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##    x pt rate    lower    upper conf.level</span>
<span class=gp>#</span><span class=c1>## 1 56  1   56 42.30181 72.72068       0.95</span>
</code></pre></td></tr></table>
</div>
</div><p>When λ>100, we can use the following normal approximation:</p>
<p>$$ \lambda \pm z_{1-(\alpha/2)}\sqrt{\lambda} $$</p>
<p>Suppose a sample’s point estimate is λ=145. A normal approximated 95% CI for λ is calculated by:</p>
<p>$$ 145 \pm 1.96\sqrt{145} = 23.6 $$</p>
<p>Therefore, λ=145, 95% CI [121.4, 168.6]. Alternatively, in R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>pois.approx</span><span class=p>(</span><span class=m>145</span><span class=p>,</span> <span class=n>pt</span> <span class=o>=</span> <span class=m>1</span><span class=p>,</span> <span class=n>conf.level</span> <span class=o>=</span> <span class=m>0.95</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>##     x pt rate    lower    upper conf.level</span>
<span class=gp>#</span><span class=c1>## 1 145  1  145 121.3989 168.6011       0.95</span>
</code></pre></td></tr></table>
</div>
</div><h3 id=determining-sample-size-for-the-mean>Determining Sample Size for the Mean</h3>
<p><img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618692392/MATH1324/ModelSix/DeterminingSampleSizeForTheMean_vgm6kr.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618692392/MATH1324/ModelSix/DeterminingSampleSizeForTheMean_vgm6kr.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618692392/MATH1324/ModelSix/DeterminingSampleSizeForTheMean_vgm6kr.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618692392/MATH1324/ModelSix/DeterminingSampleSizeForTheMean_vgm6kr.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618692392/MATH1324/ModelSix/DeterminingSampleSizeForTheMean_vgm6kr.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618692392/MATH1324/ModelSix/DeterminingSampleSizeForTheMean_vgm6kr.png>
To determine the required sample size for the mean, you must know:</p>
<ul>
<li>The desired level of confidence (1 - α), which determines the critical value, Zα/2</li>
<li>The acceptable sampling error, e</li>
<li>The standard deviation, σ</li>
</ul>
<h3 id=example-1>Example</h3>
<p>If σ = 45, what sample size is needed to estimate the mean within ± 5 with 90% confidence?
<img class=lazyload src=/svg/loading.min.svg data-src=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618692392/MATH1324/ModelSix/DeterminingSampleSizeForTheMeanExample_sjaaz7.png data-srcset="https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618692392/MATH1324/ModelSix/DeterminingSampleSizeForTheMeanExample_sjaaz7.png, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618692392/MATH1324/ModelSix/DeterminingSampleSizeForTheMeanExample_sjaaz7.png 1.5x, https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618692392/MATH1324/ModelSix/DeterminingSampleSizeForTheMeanExample_sjaaz7.png 2x" data-sizes=auto alt=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618692392/MATH1324/ModelSix/DeterminingSampleSizeForTheMeanExample_sjaaz7.png title=https://res.cloudinary.com/dkvj6mo4c/image/upload/v1618692392/MATH1324/ModelSix/DeterminingSampleSizeForTheMeanExample_sjaaz7.png></p>
<h2 id=module-7-testing-the-null-data-on-trial>Module 7 Testing the Null: Data on Trial</h2>
<h3 id=overview---summary>Overview - Summary</h3>
<p>This module will introduce the use of Hypothesis Testing for gathering statistical evidence from samples in order to draw inferences about the population. Hypothesis testing is very much like a court room trial where evidence is accumulated to reach a verdict. This module will focus on the use of t-tests for comparing means.</p>
<h3 id=learning-objectives-5>Learning Objectives</h3>
<p>The learning objectives associated with this module are:</p>
<ul>
<li>Explain the process and logic of Null Hypothesis Significance Testing (NHST).</li>
<li>Define one-tailed and two-tailed hypothesis testing.</li>
<li>State and test the assumptions behind the different t-tests.</li>
<li>Determine when a one-sample t-test should be applied.</li>
<li>Use technology to compute and interpret a one-sample t-test.</li>
<li>Identify and distinguish between the two-sample and paired sample research designs for continuous variables.</li>
<li>Use technology to compute a two-sample (independent samples) t-test and paired-samples (dependent samples) t-test.</li>
<li>Interpret a two-sample and paired-samples t-test.</li>
</ul>
<h3 id=video>Video</h3>
<div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden>
<iframe src=https://www.youtube-nocookie.com/embed/lgs7d5saFFc style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 allowfullscreen title="YouTube Video"></iframe>
</div>
<h3 id=hypothesis-testing---the-one-sample-t-test>Hypothesis Testing - The One-sample t-test</h3>
<p>This module introduces the important concepts of hypothesis testing in the context of one and two sample inference. To motivate and introduce the use of hypothesis testing, we will take a look at an example considering normal human body temperature.</p>
<h4 id=body-temp-data>Body Temp Data</h4>
<p>Prior to 1990 it was thought that the average oral human body temperature of a healthy adult was 37°Celsius (C). Investigators at that time were interested to know if this mean was correct. They gathered a sample of 130 adults and measured their oral body temperature. The dataset, <a href=https://raw.githubusercontent.com/yanboyang713/RMIT-Data-Repository/main/Body_temp.csv target=_blank rel="noopener noreferrer">Body_temp.csv</a> has the following variables:</p>
<ul>
<li>Body_temp: Body temperature measured in °Celsius (C)</li>
<li>Gender: 1 = Male, 2 = Female</li>
<li>Heart_rate: Resting heart rate measured in beats per minute (BPM)</li>
</ul>
<p>The descriptive statistics and a box plot of the data produced using R are reported below.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Body_temp</span> <span class=o>%&gt;%</span> <span class=nf>summarise</span><span class=p>(</span><span class=n>Min</span> <span class=o>=</span> <span class=nf>min</span><span class=p>(</span><span class=n>Body_temp</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                        <span class=n>Q1</span> <span class=o>=</span> <span class=nf>quantile</span><span class=p>(</span><span class=n>Body_temp</span><span class=p>,</span><span class=n>probs</span> <span class=o>=</span> <span class=m>.25</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                        <span class=n>Median</span> <span class=o>=</span> <span class=nf>median</span><span class=p>(</span><span class=n>Body_temp</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                        <span class=n>Q3</span> <span class=o>=</span> <span class=nf>quantile</span><span class=p>(</span><span class=n>Body_temp</span><span class=p>,</span><span class=n>probs</span> <span class=o>=</span> <span class=m>.75</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                        <span class=n>Max</span> <span class=o>=</span> <span class=nf>max</span><span class=p>(</span><span class=n>Body_temp</span><span class=p>,</span><span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                        <span class=n>Mean</span> <span class=o>=</span> <span class=nf>mean</span><span class=p>(</span><span class=n>Body_temp</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                        <span class=n>SD</span> <span class=o>=</span> <span class=nf>sd</span><span class=p>(</span><span class=n>Body_temp</span><span class=p>,</span> <span class=n>na.rm</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
                        <span class=n>n</span> <span class=o>=</span> <span class=nf>n</span><span class=p>(),</span>
                        <span class=n>Missing</span> <span class=o>=</span> <span class=nf>sum</span><span class=p>(</span><span class=nf>is.na</span><span class=p>(</span><span class=n>Body_temp</span><span class=p>)))</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1>#    Min   Q1 Median   Q3  Max     Mean        SD   n Missing</span>
<span class=gp>#</span><span class=c1># 1 35.7 36.6   36.8 37.1 38.2 36.80769 0.4074149 130       0</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>Body_temp</span><span class=o>$</span><span class=n>Body_temp</span> <span class=o>%&gt;%</span> <span class=nf>boxplot</span><span class=p>(</span><span class=n>ylab</span> <span class=o>=</span> <span class=s>&#34;Temperature (Celsius)&#34;</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><p>The sample mean is found to be 36.81°C. The mean was lower, but we know that samples bring with them sampling error. The researcher needs a way to determine if there was sufficient evidence from the sample to support the idea that the mean body temperature was not equal to 37°C.</p>
<h5 id=hypothesis-testing---datia-on-trial>Hypothesis Testing - DatIa on Trial</h5>
<p><strong>Null hypothesis significance testing</strong>, or hypothesis testing for short, is an inferential decision making method used extensively in statistics and science. It is based solely on the idea of a <strong>Null Hypothesis</strong>, which we will denote as $H_0$. In hypothesis testing, $H_0$ <strong>is always assumed to be true</strong>. It is a statistical hypothesis that assumes equality, no difference or no association/relationship. $H_0$ is the statistical status quo. You should not confuse $H_0$, which is a statistical hypothesis, with other related terms including a research question or research hypothesis.</p>
<p>By assuming $H_0$ is true, we can use our understanding of sampling distributions to calculate the probability of observing a particular sample statistic, or one more extreme. If this probability is really small or unlikely, we reject $H_0$. By rejecting $H_0$ we can provide evidence to support the alternate hypothesis $H_A$. $H_A$ is aligned to the research hypothesis and is the logical negation of $H_0$. If $H_0$ predits there is no difference, $H_A$ predicts there is a difference. If $H_0$ predicts there is no relationship, $H_A$ precits there is a relationship. We will take a look at many examples of $H_0$ and $H_A$.</p>
<p>Another way of writing that the results of hypothesis testing support $H_A$ is to say the results are statistically significant. It’s important to keep in mind at this stage that Hypothesis testing is probabilistic in nature. It cannot be used as a way to “prove” anything. It is merely a tool for accumulating probabilistic evidence. Science still needs to do its thing (e.g. results checked, validity assessed, replication, convergent evidence from multiple lines of enquiry etc.).</p>
<p>If the sample result is consistent or highly probable assuming the $H_0$ is true, we will decide to “fail to reject $H_0$”. If we fail to reject $H_0$, the study fails to find statistically significant evidence to support $H_A$. Or, in other words, the results of the hypothesis test are not statistically significant.</p>
<p>Notice how we have not used the term “accept”. Some statistics instructors will use this term, but this terminology leads to the misconception that hypothesis testing somehow “proves” your results statistically. In this course, the decision from hypothesis tests will always come down to either “reject $H_0$” or “fail to reject $H_0$”.</p>
<p>You might find it helpful to compare the decisions from hypothesis testing to a jury trial. This is outlined in the following slide show:</p>
<h5 id=a-worked-example>A Worked Example</h5>
<p>The one-sample t-test is used to test whether there is evidence taken from a sample mean to suggest that the population mean is different to a previously assumed value. The one-sample t-test assumes the data are normally distributed and the population standard deviation is unknown. If you have a large sample, the normality assumption is not generally needed (see CLT in Module 5). The first step of hypothesis testing is to state the statistical hypotheses. We can summarise these as follows:</p>
<p>$$ H_0: \mu = 37°C $$
$$ H_A: \mu &lt; 37°C $$</p>
<p>where $\mu$ denotes a population mean. The alternate hypothesis is stated as a lower one-tailed test, note the use of the symbol &lt;. This tells you the investigators are predicting that mean body temperature will be lower. One-tailed hypothesis tests predict the alternate hypothesis to be in a specific direction. We could also use > (upper tail) or ≠ (not equal to).</p>
<p>When we use ≠, the test is called a two-tailed test or non-directional hypothesis. In practice, almost all hypothesis tests are two-tailed. If you’re asked to conduct hypothesis testing and the type is not specified, assume you need to conduct a two-tailed test. The type of hypothesis tests we use (i.e. one-tailed or two-tailed) becomes important in the next step.</p>
<p>Next, we need to define a rule to determine if a sample result is unusual enough to reject $H_0$. Recall from previous modules that we have explored the unusualness of sample means by looking at sampling distributions. The hypothesis testing rules introduced in this module build on these concepts.</p>
<p>There are three related ways for doing this - the critical value method, the p-value approach and the confidence interval approach. All methods are based on the idea of a significance level, denoted α. The significance level, typically set at α = 0.05, is the line in the sand we use to judge “unusualness”.</p>
<p>The significance level represents the minimum acceptable probability of committing a Type I Error assuming $H_0$ is true (see the previous slideshow). A Type I Error would be committed by rejecting $H_0$ when in fact $H_0$ is true in the population. How is it possible to get it wrong? Remember, samples are imperfect representations of the populations. Sampling error produces uncertainty. We may never actually know if we have made a Type I error as we never really know for sure what’s happening in the population. That’s the very reason why we are doing the research in the first place.</p>
<p>We will work through using each one of the methods for testing the Null hypothesis using the Body temperature data. The good news is that they will all tell us the same thing. However, in practice, we stick to the p-value and confidence interval methods. The critical value method is a remnant of times before computers. However, it will be demonstrated for completeness.</p>
<h5 id=critical-value-approach>Critical Value Approach</h5>
<p>The idea of the critical value approach is to build a model of a sampling distribution assuming $H_0$ is true. Using this sampling distribution, the point at which a sample result has a less than α (e.g. α = 0.05) probability of occurring is recorded as a critical value. We then compare the sample mean test statistic to the critical value taken from the sampling distribution under the $H_0$ to see if it falls below the significance level α threshold. This will make sense as we work through an example.</p>
<p>Referring back to sampling distributions, we know the sampling distribution of a population mean with a sample size greater than 30, in this example n = 130, will be approximately normally distributed with a mean equal to the population mean, μ = 37, and a standard error of the mean, SEM:</p>
<p>σn−−√
However, we have one problem. We don’t know the population standard deviation, σ. Therefore, we need to use the t-distribution introduced back in Module 6. We can approximate the sampling distribution using the SEM as follows:</p>
<p>sn−−√
Note the use of the sample standard deviation, s, in place of σ. The sampling distribution looks like the following:</p>
<p>As the investigator was using a one-tailed test, we need to know the point in the sampling distribution where there is a less than 5% chance of a sample mean falling below μ=37. We can find this critical value, t∗ using R.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>qt</span><span class=p>(</span><span class=n>p</span> <span class=o>=</span> <span class=m>0.05</span><span class=p>,</span> <span class=n>df</span> <span class=o>=</span> <span class=m>130-1</span><span class=p>,</span> <span class=n>lower.tail</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1># [1] -1.656752</span>
</code></pre></td></tr></table>
</div>
</div><p>This means the t∗ mean sits 1.66 SEs below the population mean of 37. We can write a short R function, named ttox to convert this back to a critical mean.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>tcrittomean</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>t</span> <span class=p>,</span><span class=n>mu</span><span class=p>,</span> <span class=n>s</span><span class=p>,</span> <span class=n>n</span><span class=p>)</span> <span class=p>{</span>
  <span class=n>se</span> <span class=o>&lt;-</span> <span class=n>s</span><span class=o>/</span><span class=nf>sqrt</span><span class=p>(</span><span class=n>n</span><span class=p>)</span>
  <span class=n>x_bar</span> <span class=o>&lt;-</span> <span class=n>mu</span> <span class=o>+</span> <span class=p>(</span><span class=n>t</span><span class=o>*</span><span class=n>se</span><span class=p>)</span> <span class=c1>#Determine critical mean</span>
  <span class=nf>return</span><span class=p>(</span><span class=n>x_bar</span><span class=p>)</span>
<span class=p>}</span>
</code></pre></td></tr></table>
</div>
</div><p>This function can now be called:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>tcrittomean</span><span class=p>(</span><span class=n>t</span> <span class=o>=</span> <span class=nf>qt</span><span class=p>(</span><span class=m>0.05</span><span class=p>,</span> <span class=m>130-1</span><span class=p>,</span> <span class=n>lower.tail</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
     <span class=n>mu</span> <span class=o>=</span> <span class=m>37</span><span class=p>,</span> 
     <span class=n>s</span> <span class=o>=</span> <span class=nf>sd</span><span class=p>(</span><span class=n>Body_temp</span><span class=o>$</span><span class=n>Body_temp</span><span class=p>),</span>
     <span class=n>n</span> <span class=o>=</span> <span class=nf>length</span><span class=p>(</span><span class=n>Body_temp</span><span class=o>$</span><span class=n>Body_temp</span><span class=p>))</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1># [1] 36.9408</span>
</code></pre></td></tr></table>
</div>
</div><p>The t critical mean was found to be 36.94. This means Pr(x¯&lt;36.94)=0.05. In other-words, assuming the population mean = 37, sampling 130 people from the population and finding a mean to be less than 36.94 would happen less than 5% of the time.</p>
<p>Visually, the mean of 36.94 is the point where there is .05 probability in the lower tail of the sampling distribution under H0. This looks like the following plot where the t distribution represents the hypothetical sampling distribution. This area beyond 36.94 is referred to as the rejection region.</p>
<p>If the sample mean from the study falls in the rejection region, the decision will be to reject H0. Where did the sample mean x¯=36.8 fall?</p>
<p>The blue arrow in the image above marks the location of the investigator’s sample mean, x¯=36.81. It is well within the tail of the rejection region of the sampling distribution of the mean under H0. This is telling us, assuming H0: μ = 37 is true, the probability of observing x¯=36.81 is less than α=0.05. This is a statistically significant result.</p>
<p>What would happen if we used a non-directional two-tailed hypothesis test, i.e. HA:μ≠37 ? What would the rejection regions look like then?</p>
<p>For two-tailed hypothesis testing, the rejection regions are split between above and below H0. We still need to maintain an overall significance level of 0.05, so because α/2, we need to find the t critical values associated with 0.05/2 = 0.025 in the upper and lower tail of the sampling distribution under H0. We can find this t∗ value in R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>qt</span><span class=p>(</span><span class=n>p</span> <span class=o>=</span> <span class=m>0.05</span><span class=o>/</span><span class=m>2</span><span class=p>,</span> <span class=n>df</span> <span class=o>=</span> <span class=m>130-1</span><span class=p>,</span> <span class=n>lower.tail</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>)</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1># [1] -1.978524</span>
</code></pre></td></tr></table>
</div>
</div><p>As the t distribution is symmetric, we know the t∗ values lie at -1.98 and +1.98 SE from the mean. Using R we can readily locate the lower critical mean:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>tcrittomean</span><span class=p>(</span><span class=n>t</span> <span class=o>=</span> <span class=nf>qt</span><span class=p>(</span><span class=m>0.05</span><span class=o>/</span><span class=m>2</span><span class=p>,</span><span class=m>130-1</span><span class=p>,</span><span class=n>lower.tail</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
            <span class=n>mu</span> <span class=o>=</span> <span class=m>37</span><span class=p>,</span> 
            <span class=n>s</span> <span class=o>=</span> <span class=nf>sd</span><span class=p>(</span><span class=n>Body_temp</span><span class=o>$</span><span class=n>Body_temp</span><span class=p>),</span>
            <span class=n>n</span> <span class=o>=</span> <span class=nf>length</span><span class=p>(</span><span class=n>Body_temp</span><span class=o>$</span><span class=n>Body_temp</span><span class=p>))</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1># [1] 36.9293</span>
</code></pre></td></tr></table>
</div>
</div><p>and the upper critical mean:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>tcrittomean</span><span class=p>(</span><span class=n>t</span> <span class=o>=</span> <span class=nf>qt</span><span class=p>(</span><span class=m>1</span><span class=o>-</span><span class=p>(</span><span class=m>0.05</span><span class=o>/</span><span class=m>2</span><span class=p>),</span><span class=m>130-1</span><span class=p>,</span><span class=n>lower.tail</span> <span class=o>=</span> <span class=kc>TRUE</span><span class=p>),</span>
            <span class=n>mu</span> <span class=o>=</span> <span class=m>37</span><span class=p>,</span> 
            <span class=n>s</span> <span class=o>=</span> <span class=nf>sd</span><span class=p>(</span><span class=n>Body_temp</span><span class=o>$</span><span class=n>Body_temp</span><span class=p>),</span>
            <span class=n>n</span> <span class=o>=</span> <span class=nf>length</span><span class=p>(</span><span class=n>Body_temp</span><span class=o>$</span><span class=n>Body_temp</span><span class=p>))</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1># [1] 37.0707</span>
</code></pre></td></tr></table>
</div>
</div><p>The lower t critical mean is equal to 36.93 and the upper critical region starts at 37.07.</p>
<p>Now we have the critical regions for a two-tailed test, we can visualise them and plot the location of the sample mean.</p>
<p>As you can see, the sample mean (x¯=36.81) still falls well within the rejection regions even for a two-tailed test. You will notice, when looking back at the one-tailed test, that the lower rejection region of the two-tailed test was further from the mean than the one-tailed test (36.93 vs. 36.94). This is the trade-off for two-tailed tests. As the significance level is split between two tails of the sampling distribution, the critical regions are further from the Null hypothesised mean, meaning it will be slightly harder to reject.</p>
<h5 id=p--value-approach>p -value Approach</h5>
<p>The critical value method tells us whether a sample result is less than the significance level, but it doesn’t tell us by how much. The p-value method overcomes this problem.</p>
<p>A p-value, p, represents the probability of observing a sample statistic, or one even more extreme, under the assumption that H0 is true. You may recognise the p-value to be an example of a conditional probability. For the body temp example using a lower, one-tailed hypothesis test we would write the p-value as follows:</p>
<p>p-value=Pr(x¯&lt;36.81|μ=37)
To calculate the one-sided p-value, we need to convert the mean into a test statistic, t, which reflects how many standard errors, x¯, falls from the population mean, μ.</p>
<p>t=x¯−μsn√
We can write another function called t_stat to perform this operation.</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>t_stat</span> <span class=o>&lt;-</span> <span class=nf>function</span><span class=p>(</span><span class=n>x_bar</span><span class=p>,</span> <span class=n>mu</span><span class=p>,</span> <span class=n>s</span><span class=p>,</span> <span class=n>n</span><span class=p>){</span>
  <span class=n>t</span> <span class=o>&lt;-</span> <span class=p>(</span><span class=n>x_bar</span> <span class=o>-</span> <span class=n>mu</span><span class=p>)</span><span class=o>/</span><span class=p>(</span><span class=n>s</span><span class=o>/</span><span class=nf>sqrt</span><span class=p>(</span><span class=n>n</span><span class=p>))</span>
  <span class=nf>return</span><span class=p>(</span><span class=n>t</span><span class=p>)</span>
<span class=p>}</span>
</code></pre></td></tr></table>
</div>
</div><p>To call the function:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=n>t</span> <span class=o>&lt;-</span> <span class=nf>t_stat</span><span class=p>(</span><span class=n>x_bar</span> <span class=o>=</span> <span class=nf>mean</span><span class=p>(</span><span class=n>Body_temp</span><span class=o>$</span><span class=n>Body_temp</span><span class=p>),</span>
       <span class=n>mu</span> <span class=o>&lt;-</span> <span class=m>37</span><span class=p>,</span>
       <span class=n>s</span> <span class=o>&lt;-</span> <span class=nf>sd</span><span class=p>(</span><span class=n>Body_temp</span><span class=o>$</span><span class=n>Body_temp</span><span class=p>),</span>
       <span class=n>n</span> <span class=o>&lt;-</span> <span class=nf>length</span><span class=p>(</span><span class=n>Body_temp</span><span class=o>$</span><span class=n>Body_temp</span><span class=p>))</span>
<span class=n>t</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1># [1] -5.381848</span>
</code></pre></td></tr></table>
</div>
</div><p>This test statistic is interpreted as the sample mean falling 5.38 SEs below the population mean. Now we can restate the p-value in terms of a SE of the mean using the t statistic. By doing this, we can look up a t distribution which has a mean of 0 and df=n−1. The p-value becomes:</p>
<p>p-value=Pr(t&lt;−5.38|t=0)</p>
<p>We now calculate the exact p-value using the pt() function:</p>
<p>pt(q = t, df= 130 - 1)</p>
<h2 id=1-1680393e-07>[1] 1.680393e-07</h2>
<p>The p-value is very small. In fact, it’s so small that it rounds to 0.000. When the p-value is this small, we write p&lt;.001.</p>
<p>Things get a little strange if we use a two-tailed test. Because we need to take into account the mean also falling 5.38 SEs above the mean, the p-value for a two-tailed test becomes:</p>
<p>p-value=Pr(t&lt;−5.38|t=0)+p-value=Pr(t>5.38|t=0)
Now here’s a neat trick. As the t-distribution is symmetric, the two probabilities to be added are exactly the same. Therefore, a short cut to a two-tailed p-value can be calculated as:</p>
<p>p-value=Pr(t&lt;−5.38|t=0)∗2
Using R:</p>
<div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=nf>pt</span><span class=p>(</span><span class=n>q</span> <span class=o>=</span> <span class=n>t</span><span class=p>,</span> <span class=n>df</span><span class=o>=</span> <span class=m>130</span> <span class=o>-</span> <span class=m>1</span><span class=p>)</span><span class=o>*</span><span class=m>2</span>
</code></pre></td></tr></table>
</div>
</div><div class=highlight><div class=chroma>
<table class=lntable><tr><td class=lntd>
<pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td>
<td class=lntd>
<pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=gp>#</span><span class=c1># [1] 3.360785e-07</span>
</code></pre></td></tr></table>
</div>
</div><p>The answer is still really, really small, so we write p&lt;.001.</p>
<p>So what do we do with this p-value? We compare it to the significance level and apply the following rule:</p>
<p>If p&lt;α,Reject H0
If p>α,Fail to reject H0</p>
<p>In both the one-tailed and two-tailed hypothesis tests, p&lt;.001&lt;α=0.05, therefore we reject H0. As you can see, the probability of observing x¯=36.81, or a sample mean more extreme, assuming H0:μ=37 is true, is extremely unlikely. Therefore, H0 is rejected and we find statistical evidence to support HA. The conclusions you reach from hypothesis testing will be the same across all methods (critical value, p-value and confidence intervals) for testing H0. Different methods just give you more or less information. The critical value is rarely used in practice.</p>
<h5 id=confidence-interval-approach>Confidence Interval Approach</h5>
<p>If we use a confidence interval to test H0 for a one-sample t-test, we will automatically use a two-tailed hypothesis test. That’s because most confidence intervals divide the significance level by 2 in their calculations. One-sided confidence intervals can be calculated, but are not typically applied in practice. So let’s test H0 using a confidence interval. First, we calculate the 95% CI for the sample mean x¯=36.81. Recall, when the population standard deviation is unknown, the 95% CI is calculated as:</p>
<p>x¯±tn−1,1−(α/2)sn−−√</p>
<p>In R, we can calculate the CI using the following code:</p>
<p>t.test(Body_temp$Body_temp, conf.level = .95)$conf.int</p>
<h2 id=1-3673699-3687839>[1] 36.73699 36.87839</h2>
<h2 id=attrconflevel>attr(,&ldquo;conf.level&rdquo;)</h2>
<h2 id=1-095>[1] 0.95</h2>
<p>We find 95% CI for the sample mean, x¯=36.81, [36.74,36.87].</p>
<p>Now we apply the following rule:</p>
<p>If the 95% CI does not capture H0, reject H0
If the 95% captures H0, fail to reject H0</p>
<p>We recall H0:μ=37. Is μ=37 captured by the 95% CI [36.74, 36.87]? No. Therefore, our decision should be to reject H0.</p>
<p>As I have explained previously, all three methods will arrive at the same decision, assuming you use the same significance level and tails. The critical value method is the crudest method, the p-value is better and the 95% CI approach is preferred.</p>
<p>The one-sample t-test in R
You might be a little overwhelmed at this point with all the calculations. Don’t worry. You’re not expected to remember all these. You should focus on understanding the concepts and logic of hypothesis testing. We can use R to easily perform the one-sample t-test in a split second. We use the t.test() function for this purpose. Here’s an example of the lower-tailed hypothesis test:</p>
<p>t.test(Body_temp$Body_temp, mu = 37, alternative=&ldquo;less&rdquo;)</p>
<h2 id=heading></h2>
<h2 id=one-sample-t-test>One Sample t-test</h2>
<h2 id=heading-1></h2>
<h2 id=data--body_tempbody_temp>data: Body_temp$Body_temp</h2>
<h2 id=t---53818-df--129-p-value--168e-07>t = -5.3818, df = 129, p-value = 1.68e-07</h2>
<h2 id=alternative-hypothesis-true-mean-is-less-than-37>alternative hypothesis: true mean is less than 37</h2>
<h2 id=95-percent-confidence-interval>95 percent confidence interval:</h2>
<h2 id=-inf-3686689>-Inf 36.86689</h2>
<h2 id=sample-estimates>sample estimates:</h2>
<h2 id=mean-of-x>mean of x</h2>
<h2 id=3680769>36.80769</h2>
<p>Here’s an example of the two-tailed hypothesis test:</p>
<p>t.test(Body_temp$Body_temp, mu = 37, alternative=&ldquo;two.sided&rdquo;)</p>
<h2 id=heading-2></h2>
<h2 id=one-sample-t-test-1>One Sample t-test</h2>
<h2 id=heading-3></h2>
<h2 id=data--body_tempbody_temp-1>data: Body_temp$Body_temp</h2>
<h2 id=t---53818-df--129-p-value--3361e-07>t = -5.3818, df = 129, p-value = 3.361e-07</h2>
<h2 id=alternative-hypothesis-true-mean-is-not-equal-to-37>alternative hypothesis: true mean is not equal to 37</h2>
<h2 id=95-percent-confidence-interval-1>95 percent confidence interval:</h2>
<h2 id=3673699-3687839>36.73699 36.87839</h2>
<h2 id=sample-estimates-1>sample estimates:</h2>
<h2 id=mean-of-x-1>mean of x</h2>
<h2 id=3680769-1>36.80769</h2>
<p>You can also change the significance level. For example, α=0.01 of a 99% CI:</p>
<p>t.test(Body_temp$Body_temp, mu = 37, conf.level = .99, alternative=&ldquo;two.sided&rdquo;)</p>
<h2 id=heading-4></h2>
<h2 id=one-sample-t-test-2>One Sample t-test</h2>
<h2 id=heading-5></h2>
<h2 id=data--body_tempbody_temp-2>data: Body_temp$Body_temp</h2>
<h2 id=t---53818-df--129-p-value--3361e-07-1>t = -5.3818, df = 129, p-value = 3.361e-07</h2>
<h2 id=alternative-hypothesis-true-mean-is-not-equal-to-37-1>alternative hypothesis: true mean is not equal to 37</h2>
<h2 id=99-percent-confidence-interval>99 percent confidence interval:</h2>
<h2 id=3671427-3690111>36.71427 36.90111</h2>
<h2 id=sample-estimates-2>sample estimates:</h2>
<h2 id=mean-of-x-2>mean of x</h2>
<h2 id=3680769-2>36.80769</h2>
<p>Now that makes things a lot easier! Why did we not do this sooner? You need to understand how these values are calculated, the concepts reported and the logic of hypothesis testing. Without this knowledge, you won’t understand how to interpret the R output.</p>
<h5 id=the-language-of-hypothesis-testing---reporting-your-results>The Language of Hypothesis Testing - Reporting Your Results</h5>
<p>When we report the results of hypothesis testing for professional or scientific writing, we won’t need to mention statistical hypotheses or our decision to reject or fail to reject H0. Instead we use the term “statistical significance” to refer to the rejection of H0. When we fail to reject H0, we would write that the test was NOT statistically significant. Read the following example summarising the results of the one-sample t-test.</p>
<p>A two-tailed, one-sample t-test was used to determine if the mean oral body temperature readings were significantly different from the previously assumed oral body temperature population mean of 37°C. The 0.05 level of significance was used. The sample’s mean oral body temperature was M = 36.81°C, SD = 0.407°C. The results of the one-sample t-test found the mean rectal body temperature to be statistically significantly lower than the population oral mean temperature, t(129) = -5.38, p &lt; .001, 95% CI [36.74, 36.87].</p>
<p>As you can see, there is no mention of a statistical hypothesis or the rejection of H0.</p>
<p>Two-sample t-tests - Body Temperatures Revisited
The two-sample t-test, or independent samples t-test, is used to compare the difference between two population means, e.g. a control group vs. an experimental group, males vs. females, etc. The two-sample t-test assumes the populations being compared are independent of each other, that the data for both populations have equal variance and, for small samples, that the data for both populations are normally distributed. These assumptions must be checked prior to interpreting the results of the two-sample t-test.</p>
<p>We will work through an example to introduce and demonstrate each stage for performing the two-sample t-test. We will revisit the Body_temp.csv data. We ask the question: Do males and females have different average body temperatures? Here are the descriptive statistics and boxplot from R:</p>
<p>Body_temp %>% group_by(Gender) %>% summarise(Min = min(Body_temp,na.rm = TRUE),
Q1 = quantile(Body_temp,probs = .25,na.rm = TRUE),
Median = median(Body_temp, na.rm = TRUE),
Q3 = quantile(Body_temp,probs = .75,na.rm = TRUE),
Max = max(Body_temp,na.rm = TRUE),
Mean = mean(Body_temp, na.rm = TRUE),
SD = sd(Body_temp, na.rm = TRUE),
n = n(),
Missing = sum(is.na(Body_temp)))</p>
<h2 id=-a-tibble-2-x-10># A tibble: 2 x 10</h2>
<h2 id=gender---min----q1-median----q3---max--mean----sd-----n-missing>Gender Min Q1 Median Q3 Max Mean SD n Missing</h2>
<h2 id=fct--dbl-dbl--dbl-dbl-dbl-dbl-dbl-int---int><fct> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <int> <int></h2>
<h2 id=1-male----357--364---367--37----375--367-0388----65-------0>1 Male 35.7 36.4 36.7 37 37.5 36.7 0.388 65 0</h2>
<h2 id=2-female--358--367---369--371--382--369-0413----65-------0>2 Female 35.8 36.7 36.9 37.1 38.2 36.9 0.413 65 0</h2>
<p>Body_temp %>% boxplot(Body_temp ~ Gender, data = ., ylab = &ldquo;Temperature (Celsius)")</p>
<p>It’s a bit close to call, but it looks like females do tend to have higher body temperatures. The two-sample t-test will help us consider whether this difference is statistically significant. Let’s get started by considering the assumptions behind the two-sample t-test.</p>
<p>Testing the Assumption of Normality
When you have small samples, generally less than 30 in one sample, the one-sample and two-sample t-tests assume the data are drawn from a normal population distribution. This is a hard assumption to test, especially in small samples. The best approach is to look at the data visually and rule out gross departures from normality. If we can satisfy that the data are approximately normal, we can go ahead with the two-sample t-test. T-tests are generally robust against minor departures from normality. This means they will tend to maintain the desired significance level (e.g. 0.05) even if normality is not strictly met.</p>
<p>Although not required for the body temperature example due to the large sample sizes (Male n=65 and Female n=65), we will take a look at visually checking normality using Q−Q plots so you know what to do when n&lt;30.</p>
<p>Q−Q plots visualise the data’s distribution comparing it to what we would expect to see assuming the data are normally distributed in the population. We can look at this using a normal Q−Q plot. If the data are normally distributed in the population, the data points will fall close to the diagonal line. However, due to sampling error, the data points won’t always fall directly on the line, so we tend to check for obvious departures from normality. Non-normality is often characterised by strange ‘S’-shaped and other non-linear trends (see the following app).</p>
<p>Let’s look at the body temperature distributions for males and females using the qqPlot() function.</p>
<p>library(car)
Body_temp_male &lt;- Body_temp %>% filter(Gender == &ldquo;Male&rdquo;)
Body_temp_male$Body_temp %>% qqPlot(dist=&ldquo;norm&rdquo;)</p>
<h2 id=1-1-2>[1] 1 2</h2>
<p>Body_temp_female &lt;- Body_temp %>% filter(Gender == &ldquo;Female&rdquo;)
Body_temp_female$Body_temp %>% qqPlot(dist=&ldquo;norm&rdquo;)</p>
<h2 id=1-65--1>[1] 65 1</h2>
<p>We check to see if the data points fall within the dashed red lines. These red lines correspond to 95% CI for the normal quantiles. If the data points follow a trend of falling outside these red lines, you should be careful about assuming normality. The male data looks fine. All the points appear to be following a normal distribution very closely. The female data on the other hand isn’t so clear. You can see points falling outside the tails of the distribution. This suggests the tails are heavier than what we would expect under a normal distribution. You should be cautious about assuming normality for females. Fortunately, due to the large sample size, n=65, we don’t have to worry too much.</p>
<h5 id=central-limit-theorem-1>Central Limit Theorem</h5>
<p>Thanks to the CLT, introduced back in Module 5, we know that the sampling distribution of a mean will be approximately normally distributed, regardless of the underlying population distribution when the sample size is large (i.e. n>30). This means that we can proceed with the two-sample t-test if the normality assumption is violated when the sample sizes in each group are greater than 30. In this example, the sample sizes are much greater than 30 in each group, so we can effectively ignore the issue with normality for the female data. The CLT is extra incentive not to rely on small samples.</p>
<p>Homogeneity of Variance
Homogeneity of variance, or the assumption of equal variance, is tested using the Levene’s test. The Levene’s test has the following statistical hypotheses:</p>
<p>H0:σ21=σ22
HA:σ21≠σ22
where σ21 and σ22 refer to the population variance of group 1 and 2 respectively. The Levene’s test reports a p-value that is compared to the standard 0.05 significance level. We can use the leveneTest() function in R to compare the variances of male and female body temperatures:</p>
<p>leveneTest(Body_temp ~ Gender, data = Body_temp)</p>
<h2 id=levenes-test-for-homogeneity-of-variance-center--median>Levene&rsquo;s Test for Homogeneity of Variance (center = median)</h2>
<h2 id=df-f-value-prf>Df F value Pr(>F)</h2>
<h2 id=group---1--00428-08365>group 1 0.0428 0.8365</h2>
<h2 id=128>128</h2>
<p>The p-value for the Levene’s test of equal variance for body temperature between males and females was p=0.84. We find p>.05, therefore, we fail to reject H0. In plain language, we are safe to assume equal variance.</p>
<p>If the Levene’s test was statistically significant, i.e. p&lt;.05, this would imply that we need to reject H0. In other words, it’s not safe to assume equal variance.</p>
<p>The assumption of equal variance is important because it will determine the type of two-sample t-test we will perform. Don’t ignore this assumption. Ignoring it can lead to poor inference.</p>
<p>#Two-sample t-test - Assuming Equal Variance</p>
<p>Let’s jump straight into R and perform a two-sample t-test assuming equal variance and a two-sided hypothesis test. We use the t.test() function.</p>
<p>t.test(
Body_temp ~ Gender,
data = Body_temp,
var.equal = TRUE,
alternative = &ldquo;two.sided&rdquo;
)</p>
<h2 id=heading-6></h2>
<h2 id=two-sample-t-test>Two Sample t-test</h2>
<h2 id=heading-7></h2>
<h2 id=data--body_temp-by-gender>data: Body_temp by Gender</h2>
<h2 id=t---23204-df--128-p-value--00219>t = -2.3204, df = 128, p-value = 0.0219</h2>
<h2 id=alternative-hypothesis-true-difference-in-means-is-not-equal-to-0>alternative hypothesis: true difference in means is not equal to 0</h2>
<h2 id=95-percent-confidence-interval-2>95 percent confidence interval:</h2>
<h2 id=-03021399--00240139>-0.3021399 -0.0240139</h2>
<h2 id=sample-estimates-3>sample estimates:</h2>
<h2 id=mean-in-group-male-mean-in-group-female>mean in group Male mean in group Female</h2>
<h2 id=3672615-------------3688923>36.72615 36.88923</h2>
<p>There are two important things to note. We use the var.equal = TRUE option to perform the equal variance assumed two-sample t-test and the alternative = &ldquo;two-sided&rdquo; option to specify a two-tailed test. R prints the results of the two-sample t-test. Let’s start working through the results of the test.</p>
<p>The two-sample t-test has the following statistical hypotheses:</p>
<p>H0:μ1−μ2=0
HA:μ1−μ2≠0</p>
<p>where μ1 and μ2 refer to the population means of group 1 and 2 respectively. The null hypothesis is simply that the difference between the two independent population means is 0. The difference between males and females estimated by the sample was 36.726 - 36.889 = -0.163.</p>
<p>The test statistic t=−2.32 was calculated as:</p>
<p>t=x¯1−x¯2s2pn1+s2pn2−−−−−−−√</p>
<p>where s2p is the pooled variance (assuming equal variance):</p>
<p>s2p=(n1−1)s21+(n2−1)s22n1+n2−2</p>
<p>The t-statistic is compared to a two-tailed t-critical value t∗ with df:</p>
<p>df=n1+n2−2</p>
<p>Assuming α=0.05 and a two-tailed test, we find t∗ using the R function:</p>
<p>qt(p = 0.025, df = 65 + 65 - 2)</p>
<h2 id=1--1978671>[1] -1.978671</h2>
<p>As the test statistic t from the two-sample t-test assuming equal variance was t=−2.32, which was more extreme than −1.98, we reject H0. According to the critical value method, there was a statistically significant difference between male and female body temperature means.</p>
<p>The p-value of the two-sample t-test will tell us the probability of observing a sample difference between the means of - 0.163, or one more extreme, assuming the difference was 0 in the population (i.e. H0 is true). The two-tailed p-value was reported to be p=.02.</p>
<p>According to the p-value method, as p=.022&lt;α=0.05, we reject H0. There was a statistically significant difference between the means.</p>
<p>The 95% CI of the difference between the means (- 0.163) was calculated using the following formula in R:</p>
<p>[(x¯1−x¯2)−tn1+n2−2,1−α2s2pn1+s2pn2−−−−−−−−√,(x¯1−x¯2)+tn1+n2−2,1−α2s2pn1+s2pn2−−−−−−−−√]</p>
<p>which R reports as 95% CI [-0.30 -0.02]. As this interval does not capture H0, we reject it. Once again, there was a significant difference between the means.</p>
<p>Two-sample t-test - Assuming Unequal Variance
Had the Levene’s test been statistically significant and the assumption of equal variance violated, the two-sample t-test not assuming equal variance should be interpreted. This version of the test uses an adjusted test statistic t:</p>
<p>t=x¯1−x¯2s21n1+s22n2−−−−−−−√</p>
<p>You will notice how the variances are not pooled. The test also uses an adjusted df′:</p>
<p>df′=(s21n1+s22n2)2(s21/n1)2n1−1+(s22/n2)2n2−1
If you don’t specify var.equal in the t.test() function for R, the two-sample t-test not assuming equal variance is reported by default. This test is also known as the Welch two-sample t-test.</p>
<p>t.test(
Body_temp ~ Gender,
data = Body_temp,
var.equal = FALSE,
alternative = &ldquo;two.sided&rdquo;
)</p>
<h2 id=heading-8></h2>
<h2 id=welch-two-sample-t-test>Welch Two Sample t-test</h2>
<h2 id=heading-9></h2>
<h2 id=data--body_temp-by-gender-1>data: Body_temp by Gender</h2>
<h2 id=t---23204-df--12752-p-value--002191>t = -2.3204, df = 127.52, p-value = 0.02191</h2>
<h2 id=alternative-hypothesis-true-difference-in-means-is-not-equal-to-0-1>alternative hypothesis: true difference in means is not equal to 0</h2>
<h2 id=95-percent-confidence-interval-3>95 percent confidence interval:</h2>
<h2 id=-030214491--002400893>-0.30214491 -0.02400893</h2>
<h2 id=sample-estimates-4>sample estimates:</h2>
<h2 id=mean-in-group-male-mean-in-group-female-1>mean in group Male mean in group Female</h2>
<h2 id=3672615-------------3688923-1>36.72615 36.88923</h2>
<p>Because the variances were very similar between males and females, the adjusted test statistic t=−2.32 and df=128 for the Welch test are actually the same as the equal variances assumed two-sample t-test. This is why some recommend that you should always use the Welch test. If the variances are unequal, the test will make the required adjustment. If not, the test will be similar to a regular two-sample t-test. This means you can skip testing equal variance using the Levene’s test. This might make things simpler, but understanding the difference between these two versions of the two-sample t-test will help to make this decision.</p>
<h5 id=example-write-up>Example Write-up</h5>
<p>A two-sample t-test was used to test for a significant difference between the mean body temperature of males and females. While the body temperatures for females exhibited evidence of non-normality upon inspection of the normal Q-Q plot, the central limit theorem ensured that the t-test could be applied due to the large sample size in each group. The Levene’s test of homogeneity of variance indicated that equal variance could be assumed. The results of the two-sample t-test assuming equal variance found a statistically significant difference between the mean body temperatures of males and females, t(df=128)=−2.32, p=.02, 95% CI for the difference in means [-0.30 -0.02]. The results of the investigation suggest that females have significantly higher average body temperatures than males.</p>
<h4 id=paired-samples-t-test>Paired Samples t-test</h4>
<p>When we measure the same sample twice, the measurements are said to be “paired” or “dependent”. Many experiments measure the same people or objects before (baseline) and after (follow-up) a treatment. The paired-samples t-test, also known as the dependent samples t-test, is used to check for a statistically significant mean change or difference in these situations. Consider the following example.</p>
<h5 id=prison-data>Prison Data</h5>
<p>Investigators want to determine if exercise can help reduce stress in prisoners. The investigators have 15 prisoners fill out a stress questionnaire and then have them play a physically active sport for one hour. Following the exercise, the prisoners fill out the same stress questionnaire. The investigator wants to know if the exercise had an effect on the prisoners’ stress levels. The PrisonStress.csv data set has the following variables:</p>
<p>Subject: ID code
Group: Factor with two levels: Control and Sport
PSSbefore: Stress questionnaire score before condition. Higher scores, higher stress.
PSSafter: Stress questionnaire after condition.</p>
<p>Here are the descriptive statistics from R:</p>
<p>PrisonStress %>% filter(Group == &ldquo;Sport&rdquo;) %>%
summarise(
Min = min(PSSbefore, na.rm = TRUE),
Q1 = quantile(PSSbefore, probs = .25, na.rm = TRUE),
Median = median(PSSbefore, na.rm = TRUE),
Q3 = quantile(PSSbefore, probs = .75, na.rm = TRUE),
Max = max(PSSbefore, na.rm = TRUE),
Mean = mean(PSSbefore, na.rm = TRUE),
SD = sd(PSSbefore, na.rm = TRUE),
n = n(),
Missing = sum(is.na(PSSbefore))
)</p>
<h2 id=min-q1-median---q3-max-----mean-------sd--n-missing>Min Q1 Median Q3 Max Mean SD n Missing</h2>
<h2 id=1--12-19-----23-275--44-2393333-7487768-15-------0>1 12 19 23 27.5 44 23.93333 7.487768 15 0</h2>
<p>PrisonStress %>% filter(Group == &ldquo;Sport&rdquo;) %>%
summarise(
Min = min(PSSafter, na.rm = TRUE),
Q1 = quantile(PSSafter, probs = .25, na.rm = TRUE),
Median = median(PSSafter, na.rm = TRUE),
Q3 = quantile(PSSafter, probs = .75, na.rm = TRUE),
Max = max(PSSafter, na.rm = TRUE),
Mean = mean(PSSafter, na.rm = TRUE),
SD = sd(PSSafter, na.rm = TRUE),
n = n(),
Missing = sum(is.na(PSSafter))
)</p>
<h2 id=min-q1-median-q3-max-mean-------sd--n-missing>Min Q1 Median Q3 Max Mean SD n Missing</h2>
<h2 id=1---8-14-----21-24--33---20-6907553-15-------0>1 8 14 21 24 33 20 6.907553 15 0</h2>
<p>As you can see, stress levels appear to have dropped. We can use the paired-samples t-test to determine if this change can be considered statistically significant . Like the two-sample t-test, the paired-samples t-test assumes the data are normally distributed. This is important in this example because the sample size is only 15. Specifically, the assumption of normality lies in the distribution of the difference scores. A person’s difference score can be calculated as:</p>
<p>d1=xi1−xi2
where i refers to a particular person and 1 and 2 refer to the two dependent measurements. The paired-samples t-test assumes that these differences, d, are normally distributed. In R, we add a difference column to the PrisonStress data object:</p>
<p>PrisonStress &lt;- PrisonStress %>% mutate(d = PSSafter - PSSbefore)
We can then calculate the descriptive statistics for the mean difference, d¯.</p>
<p>PrisonStress %>% filter(Group == &ldquo;Sport&rdquo;) %>%
summarise(
Min = min(d, na.rm = TRUE),
Q1 = quantile(d, probs = .25, na.rm = TRUE),
Median = median(d, na.rm = TRUE),
Q3 = quantile(d, probs = .75, na.rm = TRUE),
Max = max(d, na.rm = TRUE),
Mean = mean(d, na.rm = TRUE),
SD = sd(d, na.rm = TRUE),
n = n(),
Missing = sum(is.na(d))
)</p>
<h2 id=min-q1-median-q3-max------mean-------sd--n-missing>Min Q1 Median Q3 Max Mean SD n Missing</h2>
<h2 id=1--15--7------4--1---4--3933333-5675343-15-------0>1 -15 -7 -4 1 4 -3.933333 5.675343 15 0</h2>
<p>On average, stress levels reduced by 3.93 points. We look at the Q-Q plot to check normality of the differences.</p>
<p>PrisonStress_sport &lt;- PrisonStress %>% filter(Group == &ldquo;Sport&rdquo;)
qqPlot(PrisonStress_sport$d, dist=&ldquo;norm&rdquo;)</p>
<h2 id=1-13--1>[1] 13 1</h2>
<p>The differences appear to be approximately normally distributed, so we are safe to continue with the paired-samples t-test.</p>
<p>The population mean of these differences is denoted:</p>
<p>μΔ
The statistical hypotheses for the paired-samples t-test are as follows:</p>
<p>H0:μΔ=0
HA:μΔ≠0
The t-statistic for the paired-samples t-test is calculated using:</p>
<p>t=d¯sΔnΔ√</p>
<p>We can calculate the paired sample t-test using the t.test() function in R.</p>
<p>t.test(PrisonStress_sport$PSSafter, PrisonStress_sport$PSSbefore,
paired = TRUE,
alternative = &ldquo;two.sided&rdquo;)</p>
<h2 id=heading-10></h2>
<h2 id=paired-t-test>Paired t-test</h2>
<h2 id=heading-11></h2>
<h2 id=data--prisonstress_sportpssafter-and-prisonstress_sportpssbefore>data: PrisonStress_sport$PSSafter and PrisonStress_sport$PSSbefore</h2>
<h2 id=t---26842-df--14-p-value--00178>t = -2.6842, df = 14, p-value = 0.0178</h2>
<h2 id=alternative-hypothesis-true-difference-in-means-is-not-equal-to-0-2>alternative hypothesis: true difference in means is not equal to 0</h2>
<h2 id=95-percent-confidence-interval-4>95 percent confidence interval:</h2>
<h2 id=-70762338--07904329>-7.0762338 -0.7904329</h2>
<h2 id=sample-estimates-5>sample estimates:</h2>
<h2 id=mean-of-the-differences>mean of the differences</h2>
<h2 id=-3933333>-3.933333</h2>
<p>Which is equivalent to a one-sample t-test of the mean difference with mu = 0.</p>
<p>t.test(PrisonStress_sport$d,
mu = 0,
alternative = &ldquo;two.sided&rdquo;)</p>
<h2 id=heading-12></h2>
<h2 id=one-sample-t-test-3>One Sample t-test</h2>
<h2 id=heading-13></h2>
<h2 id=data--prisonstress_sportd>data: PrisonStress_sport$d</h2>
<h2 id=t---26842-df--14-p-value--00178-1>t = -2.6842, df = 14, p-value = 0.0178</h2>
<h2 id=alternative-hypothesis-true-mean-is-not-equal-to-0>alternative hypothesis: true mean is not equal to 0</h2>
<h2 id=95-percent-confidence-interval-5>95 percent confidence interval:</h2>
<h2 id=-70762338--07904329-1>-7.0762338 -0.7904329</h2>
<h2 id=sample-estimates-6>sample estimates:</h2>
<h2 id=mean-of-x-3>mean of x</h2>
<h2 id=-3933333-1>-3.933333</h2>
<p>The paired samples t-test is a one sample t-test of the differences, d, and where the hypothesized population mean = 0. R reports t=−2.68.</p>
<p>Degrees of freedom are:</p>
<p>df=nΔ−1
In this example, df=15−1=14.</p>
<p>The critical value, t∗ for the paired-sample t-test, assuming a two-tailed test with α=0.05, is calculated as:</p>
<p>qt(p = 0.025, df = 14)</p>
<h2 id=1--2144787>[1] -2.144787</h2>
<p>The t∗ values are ±2.14. As t=−2.68 is more extreme than −2.14, H0 should be rejected. There was a statistically significant mean difference between the stress before and after exercise.</p>
<p>The two-tailed p-value can be calculated as:</p>
<p>2*pt(q = -2.68, df = 14)</p>
<h2 id=1-001794553>[1] 0.01794553</h2>
<p>which rounds to p&lt;.018 reported in the paired samples t-test. As p&lt;.05, we reject H0. There was a statistically significant mean difference.</p>
<p>A 95% CI of the mean difference can be calculated as:
[d¯−tnΔ,1−α2sΔnΔ−−−√,d¯+tnΔ,1−α2sΔnΔ−−−√]</p>
<p>The 95% CI of the mean difference is found to be [-7.08 -0.79]. As the 95% CI does not capture H0, we reject it. There was a statistically significant mean difference between pain ratings.</p>
<h5 id=paired-samples-t-test-visualisation>Paired Samples t-test Visualisation</h5>
<p>Visualising the results of a paired samples t-test can be tricky. There are a few approaches that can be used in R. The first involves a side-by-side boxplot of the scores. However, the plot does not show the dependency between the paired data.</p>
<p>boxplot(
PrisonStress_sport$PSSbefore,
PrisonStress_sport$PSSafter,
ylab = &ldquo;Stress Ratings&rdquo;,
xlab = &ldquo;Time&rdquo;
)
axis(1, at = 1:2, labels = c(&ldquo;Before&rdquo;, &ldquo;After&rdquo;))</p>
<p>Another approach is to use a line plot where each line represents the paired scores. However, this is only suited to small datasets.</p>
<p>matplot(t(data.frame(PrisonStress_sport$PSSbefore, PrisonStress_sport$PSSafter)),
type = &ldquo;b&rdquo;,
pch = 19,
col = 1,
lty = 1,
xlab = &ldquo;Time&rdquo;,
ylab = &ldquo;Stress Ratings&rdquo;,
xaxt = &ldquo;n&rdquo;
)
axis(1, at = 1:2, labels = c(&ldquo;Before&rdquo;, &ldquo;After&rdquo;))</p>
<p>Alternatively, we can use the very fancy granova.ds() function from the granova package. This plot visualises the mean difference using a scatter plot. The plot reports the mean difference and confidence intervals from the paired samples t-test, which is very helpful. However, the plot takes some time to be able to interpret. But I think it’s worth it. You can read all about this visualisation here.</p>
<p>library(granova)
granova.ds(
data.frame(PrisonStress_sport$PSSbefore, PrisonStress_sport$PSSafter),
xlab = &ldquo;Prison Stress - Before&rdquo;,
ylab = &ldquo;Prison Stress - After&rdquo;
)</p>
<h2 id=summary-stats>Summary Stats</h2>
<h2 id=n------------------15000>n 15.000</h2>
<h2 id=meanx------------23933>mean(x) 23.933</h2>
<h2 id=meany------------20000>mean(y) 20.000</h2>
<h2 id=meandx-y---------3933>mean(D=x-y) 3.933</h2>
<h2 id=sdd---------------5675>SD(D) 5.675</h2>
<h2 id=esd---------------0693>ES(D) 0.693</h2>
<h2 id=rxy--------------0692>r(x,y) 0.692</h2>
<h2 id=rxyd------------0111>r(x+y,d) 0.111</h2>
<h2 id=ll-95ci------------0790>LL 95%CI 0.790</h2>
<h2 id=ul-95ci------------7076>UL 95%CI 7.076</h2>
<h2 id=td-bar------------2684>t(D-bar) 2.684</h2>
<h2 id=dft---------------14000>df.t 14.000</h2>
<h2 id=pvalt--------------0018>pval.t 0.018</h2>
<p>Example Write-up
A paired-samples t-test was used to test for a significant mean difference between stress levels before and after exercise. The mean difference following exercise was found to be -3.93 (SD = 5.68). Visual inspection of the Q-Q plot of the difference scores suggested that the data were approximately normally distributed. The paired-samples t-test found a statistically significant mean difference between stress levels before and after exercise, t(df=14)=−2.68, p&lt;.018, 95% [-7.08 -0.79]. Stress levels were found to be significantly reduced after prisoners engaged in one hour of exercise.</p>
</div><div class=post-footer id=post-footer>
<div class=post-info>
<div class=post-info-line>
<div class=post-info-mod>
<span>Updated on 2021-12-06</span>
</div>
<div class=post-info-license></div>
</div>
<div class=post-info-line>
<div class=post-info-md><span>
<a class=link-to-markdown href=/introductiontostatistics-appliedanalytics/index.md target=_blank rel="noopener noreferrer">Read Markdown</a>
</span></div>
<div class=post-info-share>
<span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://yanboyang.com/introductiontostatistics-appliedanalytics/ data-title="Introduction to Statistics (Applied Analytics)"><i class="fab fa-twitter fa-fw"></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://yanboyang.com/introductiontostatistics-appliedanalytics/><i class="fab fa-facebook-square fa-fw"></i></a><a href=javascript:void(0); title="Share on WhatsApp" data-sharer=whatsapp data-url=https://yanboyang.com/introductiontostatistics-appliedanalytics/ data-title="Introduction to Statistics (Applied Analytics)" data-web><i class="fab fa-whatsapp fa-fw"></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://yanboyang.com/introductiontostatistics-appliedanalytics/ data-title="Introduction to Statistics (Applied Analytics)"><i data-svg-src=/lib/simple-icons/icons/line.min.svg></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://yanboyang.com/introductiontostatistics-appliedanalytics/ data-title="Introduction to Statistics (Applied Analytics)"><i class="fab fa-weibo fa-fw"></i></a><a href=javascript:void(0); title="Share on Myspace" data-sharer=myspace data-url=https://yanboyang.com/introductiontostatistics-appliedanalytics/ data-title="Introduction to Statistics (Applied Analytics)" data-description><i data-svg-src=/lib/simple-icons/icons/myspace.min.svg></i></a><a href=javascript:void(0); title="Share on Blogger" data-sharer=blogger data-url=https://yanboyang.com/introductiontostatistics-appliedanalytics/ data-title="Introduction to Statistics (Applied Analytics)" data-description><i class="fab fa-blogger fa-fw"></i></a><a href=javascript:void(0); title="Share on Evernote" data-sharer=evernote data-url=https://yanboyang.com/introductiontostatistics-appliedanalytics/ data-title="Introduction to Statistics (Applied Analytics)"><i class="fab fa-evernote fa-fw"></i></a></span>
</div>
</div>
</div>
<div class=post-info-more>
<section class=post-tags></section>
<section>
<span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span>
</section>
</div>
<div class=post-nav><a href=/bigdataarchitectures/ class=prev rel=prev title="4 big data architectures, Data Streaming, Lambda architecture, Kappa architecture and Unifield architecture"><i class="fas fa-angle-left fa-fw"></i>4 big data architectures, Data Streaming, Lambda architecture, Kappa architecture and Unifield architecture</a>
<a href=/rlanguage/ class=next rel=next title="Getting Started with R language">Getting Started with R language<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id=comments><div id=disqus_thread class=comment></div><noscript>
Please enable JavaScript to view the comments powered by <a href=https://disqus.com/?ref_noscript>Disqus</a>.
</noscript></div></article></div>
</main><footer class=footer>
<div class=footer-container><div class=footer-line>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreferrer" title="Hugo 0.89.4">Hugo</a> | Theme - <a href=https://github.com/sunt-programator/CodeIT target=_blank rel="noopener noreferrer" title="CodeIT 0.2.10"><i class="fas fa-laptop-code fa-fw"></i> CodeIT</a>
</div><div class=footer-line><i class="far fa-copyright fa-fw"></i><span itemprop=copyrightYear>2019 - 2021</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank rel="noopener noreferrer">Boyang Yan</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div>
</div>
</footer></div>
<div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top">
<i class="fas fa-arrow-up fa-fw"></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments">
<i class="fas fa-comment fa-fw"></i>
</a>
</div><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/katex/copy-tex.min.css><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><script type=text/javascript src=https://boyang-blog.disqus.com/embed.js defer></script><script type=text/javascript src=/lib/smooth-scroll/smooth-scroll.min.js></script><script type=text/javascript src=/lib/autocomplete/autocomplete.min.js></script><script type=text/javascript src=/lib/lunr/lunr.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/sharer/sharer.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js></script><script type=text/javascript src=/lib/katex/auto-render.min.js></script><script type=text/javascript src=/lib/katex/copy-tex.min.js></script><script type=text/javascript src=/lib/katex/mhchem.min.js></script><script type=text/javascript src=/lib/cookieconsent/cookieconsent.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:1e3},comment:{},cookieconsent:{content:{dismiss:"Got it!",link:"Learn more",message:"This website uses Cookies to improve your experience."},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:30,type:"lunr"}}</script><script type=text/javascript src=/js/theme.min.js></script></body>
</html>